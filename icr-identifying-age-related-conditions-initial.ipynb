{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kcwong5/icr-identifying-age-related-conditions-initial?scriptVersionId=138399436\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"adb2e805","metadata":{"papermill":{"duration":0.022247,"end_time":"2023-07-30T19:54:50.902914","exception":false,"start_time":"2023-07-30T19:54:50.880667","status":"completed"},"tags":[]},"source":["# Import libraries"]},{"cell_type":"code","execution_count":1,"id":"6c3ee871","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:50.947946Z","iopub.status.busy":"2023-07-30T19:54:50.947545Z","iopub.status.idle":"2023-07-30T19:54:56.276183Z","shell.execute_reply":"2023-07-30T19:54:56.274375Z"},"papermill":{"duration":5.355268,"end_time":"2023-07-30T19:54:56.279383","exception":false,"start_time":"2023-07-30T19:54:50.924115","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","import seaborn as sns\n","import matplotlib.ticker as ticker\n","import plotly.graph_objects as go\n","from matplotlib.ticker import MaxNLocator\n","\n","import time\n","from sklearn.preprocessing import LabelEncoder\n","\n","import numpy as np\n","import optuna\n","from optuna.samplers import TPESampler\n","\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","\n","import lightgbm as lgb\n","import sklearn.datasets\n","import sklearn.metrics\n","from sklearn.model_selection import train_test_split, StratifiedKFold"]},{"cell_type":"markdown","id":"cd897d03","metadata":{"papermill":{"duration":0.021919,"end_time":"2023-07-30T19:54:56.324378","exception":false,"start_time":"2023-07-30T19:54:56.302459","status":"completed"},"tags":[]},"source":["# Set notebook environment"]},{"cell_type":"code","execution_count":2,"id":"fdb1d854","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:56.372038Z","iopub.status.busy":"2023-07-30T19:54:56.371607Z","iopub.status.idle":"2023-07-30T19:54:56.3805Z","shell.execute_reply":"2023-07-30T19:54:56.379023Z"},"papermill":{"duration":0.036136,"end_time":"2023-07-30T19:54:56.383269","exception":false,"start_time":"2023-07-30T19:54:56.347133","status":"completed"},"tags":[]},"outputs":[],"source":["# Change notebook environment\n","\n","# https://ipython.readthedocs.io/en/stable/api/generated/IPython.core.interactiveshell.html\n","# https://stackoverflow.com/questions/36786722/how-to-display-full-output-in-jupyter-not-only-last-result\n","# Display full output in output cell, not only last result\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = 'all'\n","\n","# https://www.kaggle.com/questions-and-answers/118932\n","# Max rows and columns of pandas dataframe \n","pd.options.display.max_rows,pd.options.display.max_columns\n","\n","# https://thispointer.com/python-pandas-how-to-display-full-dataframe-i-e-print-all-rows-columns-without-truncation/\n","# Print all the contents of a pandas dataframe\n","pd.set_option('display.max_rows', None) # Print unlimited number of rows by setting to None, default is 10\n","pd.set_option('display.max_columns', None) # Do not truncate columns to display all of them by setting to None\n","pd.set_option('display.width', None) # Auto-detect the width of dataframe to display all columns in single line by setting to None\n","pd.set_option('display.max_colwidth', None) # Auto detect the max size of column and print contents of that column without truncation\n","\n","# https://stackoverflow.com/questions/8924173/how-to-print-bold-text-in-python\n","start = \"\\033[1m\" # Bold text\n","end = \"\\033[0;0m\" # Reset \n","\n","import gc"]},{"cell_type":"code","execution_count":3,"id":"a1782858","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:56.430305Z","iopub.status.busy":"2023-07-30T19:54:56.429894Z","iopub.status.idle":"2023-07-30T19:54:56.635106Z","shell.execute_reply":"2023-07-30T19:54:56.633967Z"},"papermill":{"duration":0.231533,"end_time":"2023-07-30T19:54:56.637698","exception":false,"start_time":"2023-07-30T19:54:56.406165","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Free up memory that is no longer being used\n","gc.collect()"]},{"cell_type":"markdown","id":"134099ee","metadata":{"papermill":{"duration":0.021298,"end_time":"2023-07-30T19:54:56.681367","exception":false,"start_time":"2023-07-30T19:54:56.660069","status":"completed"},"tags":[]},"source":["# Load datasets"]},{"cell_type":"code","execution_count":4,"id":"6a4d1b88","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:56.72859Z","iopub.status.busy":"2023-07-30T19:54:56.726854Z","iopub.status.idle":"2023-07-30T19:54:56.798546Z","shell.execute_reply":"2023-07-30T19:54:56.797114Z"},"papermill":{"duration":0.098999,"end_time":"2023-07-30T19:54:56.801824","exception":false,"start_time":"2023-07-30T19:54:56.702825","status":"completed"},"tags":[]},"outputs":[],"source":["train_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/train.csv\")\n","greeks_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/greeks.csv\")\n","test_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/test.csv\")\n","sample_submission_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\")"]},{"cell_type":"markdown","id":"76010d94","metadata":{"papermill":{"duration":0.024143,"end_time":"2023-07-30T19:54:56.853709","exception":false,"start_time":"2023-07-30T19:54:56.829566","status":"completed"},"tags":[]},"source":["# Data glance"]},{"cell_type":"code","execution_count":5,"id":"38710ae2","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:56.90084Z","iopub.status.busy":"2023-07-30T19:54:56.899766Z","iopub.status.idle":"2023-07-30T19:54:57.063591Z","shell.execute_reply":"2023-07-30T19:54:57.061821Z"},"papermill":{"duration":0.189597,"end_time":"2023-07-30T19:54:57.066277","exception":false,"start_time":"2023-07-30T19:54:56.87668","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mtrain.csv:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EJ</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>0.209377</td>\n","      <td>3109.03329</td>\n","      <td>85.200147</td>\n","      <td>22.394407</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>9.812214</td>\n","      <td>5.555634</td>\n","      <td>4126.58731</td>\n","      <td>22.5984</td>\n","      <td>175.638726</td>\n","      <td>152.707705</td>\n","      <td>823.928241</td>\n","      <td>257.432377</td>\n","      <td>47.223358</td>\n","      <td>0.563481</td>\n","      <td>23.387600</td>\n","      <td>4.851915</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.069225</td>\n","      <td>13.784111</td>\n","      <td>1.302012</td>\n","      <td>36.205956</td>\n","      <td>69.08340</td>\n","      <td>295.570575</td>\n","      <td>0.23868</td>\n","      <td>0.284232</td>\n","      <td>89.245560</td>\n","      <td>84.31664</td>\n","      <td>29.657104</td>\n","      <td>5.310690</td>\n","      <td>1.74307</td>\n","      <td>23.187704</td>\n","      <td>7.294176</td>\n","      <td>1.987283</td>\n","      <td>1433.166750</td>\n","      <td>0.949104</td>\n","      <td>B</td>\n","      <td>30.879420</td>\n","      <td>78.526968</td>\n","      <td>3.828384</td>\n","      <td>13.394640</td>\n","      <td>10.265073</td>\n","      <td>9028.291921</td>\n","      <td>3.583450</td>\n","      <td>7.298162</td>\n","      <td>1.73855</td>\n","      <td>0.094822</td>\n","      <td>11.339138</td>\n","      <td>72.611063</td>\n","      <td>2003.810319</td>\n","      <td>22.136229</td>\n","      <td>69.834944</td>\n","      <td>0.120343</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>5496.92824</td>\n","      <td>19.4205</td>\n","      <td>155.868030</td>\n","      <td>14.754720</td>\n","      <td>51.216883</td>\n","      <td>257.432377</td>\n","      <td>30.284345</td>\n","      <td>0.484710</td>\n","      <td>50.628208</td>\n","      <td>6.085041</td>\n","      <td>0.031442</td>\n","      <td>1.113875</td>\n","      <td>1.117800</td>\n","      <td>28.310953</td>\n","      <td>1.357182</td>\n","      <td>37.476568</td>\n","      <td>70.79836</td>\n","      <td>178.553100</td>\n","      <td>0.23868</td>\n","      <td>0.363489</td>\n","      <td>110.581815</td>\n","      <td>75.74548</td>\n","      <td>37.532000</td>\n","      <td>0.005518</td>\n","      <td>1.74307</td>\n","      <td>17.222328</td>\n","      <td>4.926396</td>\n","      <td>0.858603</td>\n","      <td>1111.287150</td>\n","      <td>0.003042</td>\n","      <td>A</td>\n","      <td>109.125159</td>\n","      <td>95.415086</td>\n","      <td>52.260480</td>\n","      <td>17.175984</td>\n","      <td>0.296850</td>\n","      <td>6785.003474</td>\n","      <td>10.358927</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>0.470030</td>\n","      <td>2635.10654</td>\n","      <td>85.200147</td>\n","      <td>32.360553</td>\n","      <td>8.138688</td>\n","      <td>6.732840</td>\n","      <td>0.025578</td>\n","      <td>12.824570</td>\n","      <td>1.229900</td>\n","      <td>5135.78024</td>\n","      <td>26.4825</td>\n","      <td>128.988531</td>\n","      <td>219.320160</td>\n","      <td>482.141594</td>\n","      <td>257.432377</td>\n","      <td>32.563713</td>\n","      <td>0.495852</td>\n","      <td>85.955376</td>\n","      <td>5.376488</td>\n","      <td>0.036218</td>\n","      <td>1.050225</td>\n","      <td>0.700350</td>\n","      <td>39.364743</td>\n","      <td>1.009611</td>\n","      <td>21.459644</td>\n","      <td>70.81970</td>\n","      <td>321.426625</td>\n","      <td>0.23868</td>\n","      <td>0.210441</td>\n","      <td>120.056438</td>\n","      <td>65.46984</td>\n","      <td>28.053464</td>\n","      <td>1.289739</td>\n","      <td>1.74307</td>\n","      <td>36.861352</td>\n","      <td>7.813674</td>\n","      <td>8.146651</td>\n","      <td>1494.076488</td>\n","      <td>0.377208</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>78.526968</td>\n","      <td>5.390628</td>\n","      <td>224.207424</td>\n","      <td>8.745201</td>\n","      <td>8338.906181</td>\n","      <td>11.626917</td>\n","      <td>7.709560</td>\n","      <td>0.97556</td>\n","      <td>1.198821</td>\n","      <td>37.077772</td>\n","      <td>88.609437</td>\n","      <td>13676.957810</td>\n","      <td>28.022851</td>\n","      <td>35.192676</td>\n","      <td>0.196941</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>0.252107</td>\n","      <td>3819.65177</td>\n","      <td>120.201618</td>\n","      <td>77.112203</td>\n","      <td>8.138688</td>\n","      <td>3.685344</td>\n","      <td>0.025578</td>\n","      <td>11.053708</td>\n","      <td>1.229900</td>\n","      <td>4169.67738</td>\n","      <td>23.6577</td>\n","      <td>237.282264</td>\n","      <td>11.050410</td>\n","      <td>661.518640</td>\n","      <td>257.432377</td>\n","      <td>15.201914</td>\n","      <td>0.717882</td>\n","      <td>88.159360</td>\n","      <td>2.347652</td>\n","      <td>0.029054</td>\n","      <td>1.400300</td>\n","      <td>0.636075</td>\n","      <td>41.116960</td>\n","      <td>0.722727</td>\n","      <td>21.530392</td>\n","      <td>47.27586</td>\n","      <td>196.607985</td>\n","      <td>0.23868</td>\n","      <td>0.292431</td>\n","      <td>139.824570</td>\n","      <td>71.57120</td>\n","      <td>24.354856</td>\n","      <td>2.655345</td>\n","      <td>1.74307</td>\n","      <td>52.003884</td>\n","      <td>7.386060</td>\n","      <td>3.813326</td>\n","      <td>15691.552180</td>\n","      <td>0.614484</td>\n","      <td>B</td>\n","      <td>31.674357</td>\n","      <td>78.526968</td>\n","      <td>31.323372</td>\n","      <td>59.301984</td>\n","      <td>7.884336</td>\n","      <td>10965.766040</td>\n","      <td>14.852022</td>\n","      <td>6.122162</td>\n","      <td>0.49706</td>\n","      <td>0.284466</td>\n","      <td>18.529584</td>\n","      <td>82.416803</td>\n","      <td>2094.262452</td>\n","      <td>39.948656</td>\n","      <td>90.493248</td>\n","      <td>0.155829</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>0.380297</td>\n","      <td>3733.04844</td>\n","      <td>85.200147</td>\n","      <td>14.103738</td>\n","      <td>8.138688</td>\n","      <td>3.942255</td>\n","      <td>0.054810</td>\n","      <td>3.396778</td>\n","      <td>102.151980</td>\n","      <td>5728.73412</td>\n","      <td>24.0108</td>\n","      <td>324.546318</td>\n","      <td>149.717165</td>\n","      <td>6074.859475</td>\n","      <td>257.432377</td>\n","      <td>82.213495</td>\n","      <td>0.536467</td>\n","      <td>72.644264</td>\n","      <td>30.537722</td>\n","      <td>0.025472</td>\n","      <td>1.050225</td>\n","      <td>0.693150</td>\n","      <td>31.724726</td>\n","      <td>0.827550</td>\n","      <td>34.415360</td>\n","      <td>74.06532</td>\n","      <td>200.178160</td>\n","      <td>0.23868</td>\n","      <td>0.207708</td>\n","      <td>97.920120</td>\n","      <td>52.83888</td>\n","      <td>26.019912</td>\n","      <td>1.144902</td>\n","      <td>1.74307</td>\n","      <td>9.064856</td>\n","      <td>7.350720</td>\n","      <td>3.490846</td>\n","      <td>1403.656300</td>\n","      <td>0.164268</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>91.994825</td>\n","      <td>51.141336</td>\n","      <td>29.102640</td>\n","      <td>4.274640</td>\n","      <td>16198.049590</td>\n","      <td>13.666727</td>\n","      <td>8.153058</td>\n","      <td>48.50134</td>\n","      <td>0.121914</td>\n","      <td>16.408728</td>\n","      <td>146.109943</td>\n","      <td>8524.370502</td>\n","      <td>45.381316</td>\n","      <td>36.262628</td>\n","      <td>0.096614</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id        AB          AF          AH         AM        AR  \\\n","0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n","1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n","2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n","3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n","4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n","\n","         AX        AY         AZ          BC         BD        BN          BP  \\\n","0  0.699861  0.025578   9.812214    5.555634  4126.58731  22.5984  175.638726   \n","1  3.632190  0.025578  13.517790    1.229900  5496.92824  19.4205  155.868030   \n","2  6.732840  0.025578  12.824570    1.229900  5135.78024  26.4825  128.988531   \n","3  3.685344  0.025578  11.053708    1.229900  4169.67738  23.6577  237.282264   \n","4  3.942255  0.054810   3.396778  102.151980  5728.73412  24.0108  324.546318   \n","\n","           BQ           BR          BZ         CB        CC        CD   \\\n","0  152.707705   823.928241  257.432377  47.223358  0.563481  23.387600   \n","1   14.754720    51.216883  257.432377  30.284345  0.484710  50.628208   \n","2  219.320160   482.141594  257.432377  32.563713  0.495852  85.955376   \n","3   11.050410   661.518640  257.432377  15.201914  0.717882  88.159360   \n","4  149.717165  6074.859475  257.432377  82.213495  0.536467  72.644264   \n","\n","          CF        CH        CL        CR         CS        CU        CW   \\\n","0   4.851915  0.023482  1.050225  0.069225  13.784111  1.302012  36.205956   \n","1   6.085041  0.031442  1.113875  1.117800  28.310953  1.357182  37.476568   \n","2   5.376488  0.036218  1.050225  0.700350  39.364743  1.009611  21.459644   \n","3   2.347652  0.029054  1.400300  0.636075  41.116960  0.722727  21.530392   \n","4  30.537722  0.025472  1.050225  0.693150  31.724726  0.827550  34.415360   \n","\n","         DA          DE       DF        DH          DI        DL         DN  \\\n","0  69.08340  295.570575  0.23868  0.284232   89.245560  84.31664  29.657104   \n","1  70.79836  178.553100  0.23868  0.363489  110.581815  75.74548  37.532000   \n","2  70.81970  321.426625  0.23868  0.210441  120.056438  65.46984  28.053464   \n","3  47.27586  196.607985  0.23868  0.292431  139.824570  71.57120  24.354856   \n","4  74.06532  200.178160  0.23868  0.207708   97.920120  52.83888  26.019912   \n","\n","         DU       DV         DY        EB        EE            EG        EH  \\\n","0  5.310690  1.74307  23.187704  7.294176  1.987283   1433.166750  0.949104   \n","1  0.005518  1.74307  17.222328  4.926396  0.858603   1111.287150  0.003042   \n","2  1.289739  1.74307  36.861352  7.813674  8.146651   1494.076488  0.377208   \n","3  2.655345  1.74307  52.003884  7.386060  3.813326  15691.552180  0.614484   \n","4  1.144902  1.74307   9.064856  7.350720  3.490846   1403.656300  0.164268   \n","\n","  EJ          EL         EP         EU          FC        FD             FE  \\\n","0  B   30.879420  78.526968   3.828384   13.394640  10.265073   9028.291921   \n","1  A  109.125159  95.415086  52.260480   17.175984   0.296850   6785.003474   \n","2  B  109.125159  78.526968   5.390628  224.207424   8.745201   8338.906181   \n","3  B   31.674357  78.526968  31.323372   59.301984   7.884336  10965.766040   \n","4  B  109.125159  91.994825  51.141336   29.102640   4.274640  16198.049590   \n","\n","          FI        FL        FR        FS         GB          GE  \\\n","0   3.583450  7.298162   1.73855  0.094822  11.339138   72.611063   \n","1  10.358927  0.173229   0.49706  0.568932   9.292698   72.611063   \n","2  11.626917  7.709560   0.97556  1.198821  37.077772   88.609437   \n","3  14.852022  6.122162   0.49706  0.284466  18.529584   82.416803   \n","4  13.666727  8.153058  48.50134  0.121914  16.408728  146.109943   \n","\n","             GF         GH         GI         GL  Class  \n","0   2003.810319  22.136229  69.834944   0.120343      1  \n","1  27981.562750  29.135430  32.131996  21.978000      0  \n","2  13676.957810  28.022851  35.192676   0.196941      0  \n","3   2094.262452  39.948656  90.493248   0.155829      0  \n","4   8524.370502  45.381316  36.262628   0.096614      1  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","greeks.csv:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Alpha</th>\n","      <th>Beta</th>\n","      <th>Gamma</th>\n","      <th>Delta</th>\n","      <th>Epsilon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>G</td>\n","      <td>D</td>\n","      <td>3/19/2019</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>3/25/2020</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id Alpha Beta Gamma Delta    Epsilon\n","0  000ff2bfdfe9     B    C     G     D  3/19/2019\n","1  007255e47698     A    C     M     B    Unknown\n","2  013f2bd269f5     A    C     M     B    Unknown\n","3  043ac50845d5     A    C     M     B    Unknown\n","4  044fb8a146ec     D    B     F     B  3/25/2020"]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","test.csv:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EJ</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00eed32682bb</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>A</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>010ebe33f668</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>A</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>02fa521e1838</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>A</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>040e15f562a2</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>A</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>046e85c7cc7f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>A</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id   AB   AF   AH   AM   AR   AX   AY   AZ   BC  BD    BN   BP  \\\n","0  00eed32682bb  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  010ebe33f668  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  02fa521e1838  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","3  040e15f562a2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","4  046e85c7cc7f  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","    BQ   BR   BZ   CB   CC  CD    CF   CH   CL   CR   CS   CU  CW    DA   DE  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","    DF   DH   DI   DL   DN   DU   DV   DY   EB   EE   EG   EH EJ   EL   EP  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  A  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  A  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  A  0.0  0.0   \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  A  0.0  0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  A  0.0  0.0   \n","\n","    EU   FC  FD    FE   FI   FL   FR   FS   GB   GE   GF   GH   GI   GL  \n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","sample_submission_df.csv:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>class_0</th>\n","      <th>class_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00eed32682bb</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>010ebe33f668</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>02fa521e1838</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>040e15f562a2</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>046e85c7cc7f</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id  class_0  class_1\n","0  00eed32682bb      0.5      0.5\n","1  010ebe33f668      0.5      0.5\n","2  02fa521e1838      0.5      0.5\n","3  040e15f562a2      0.5      0.5\n","4  046e85c7cc7f      0.5      0.5"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["print(start+\"train.csv:\"+end)\n","train_df.head()\n","print(start+\"\\ngreeks.csv:\"+end)\n","greeks_df.head()\n","print(start+\"\\ntest.csv:\"+end)\n","test_df.head()\n","print(start+\"\\nsample_submission_df.csv:\"+end)\n","sample_submission_df.head()"]},{"cell_type":"markdown","id":"c38c3239","metadata":{"papermill":{"duration":0.024699,"end_time":"2023-07-30T19:54:57.116294","exception":false,"start_time":"2023-07-30T19:54:57.091595","status":"completed"},"tags":[]},"source":["# Check column names"]},{"cell_type":"code","execution_count":6,"id":"dc17d307","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:57.166126Z","iopub.status.busy":"2023-07-30T19:54:57.165653Z","iopub.status.idle":"2023-07-30T19:54:57.190431Z","shell.execute_reply":"2023-07-30T19:54:57.189057Z"},"papermill":{"duration":0.052658,"end_time":"2023-07-30T19:54:57.192895","exception":false,"start_time":"2023-07-30T19:54:57.140237","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mtrain.csv:\u001b[0;0m\n"]},{"data":{"text/plain":["Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n","       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n","       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n","       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n","       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'],\n","      dtype='object')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","greeks.csv:\u001b[0;0m\n"]},{"data":{"text/plain":["Index(['Id', 'Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon'], dtype='object')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","test.csv:\u001b[0;0m\n"]},{"data":{"text/plain":["Index(['Id', 'AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n","       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n","       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n","       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n","       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","      dtype='object')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","sample_submission_df.csv:\u001b[0;0m\n"]},{"data":{"text/plain":["Index(['Id', 'class_0', 'class_1'], dtype='object')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["print(start+\"train.csv:\"+end)\n","train_df.columns\n","print(start+\"\\ngreeks.csv:\"+end)\n","greeks_df.columns\n","print(start+\"\\ntest.csv:\"+end)\n","test_df.columns\n","print(start+\"\\nsample_submission_df.csv:\"+end)\n","sample_submission_df.columns"]},{"cell_type":"markdown","id":"13bc37eb","metadata":{"papermill":{"duration":0.024513,"end_time":"2023-07-30T19:54:57.242473","exception":false,"start_time":"2023-07-30T19:54:57.21796","status":"completed"},"tags":[]},"source":["# Assess data\n","- Attribute\n","- Summary statistics"]},{"cell_type":"code","execution_count":7,"id":"574d4bde","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:57.294502Z","iopub.status.busy":"2023-07-30T19:54:57.294008Z","iopub.status.idle":"2023-07-30T19:54:57.300824Z","shell.execute_reply":"2023-07-30T19:54:57.299891Z"},"papermill":{"duration":0.036211,"end_time":"2023-07-30T19:54:57.303564","exception":false,"start_time":"2023-07-30T19:54:57.267353","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mtrain: (617, 58) \u001b[0;0m\n","\u001b[1mgreeks: (617, 6) \u001b[0;0m\n","\u001b[1mtest: (5, 57) \u001b[0;0m\n","\u001b[1msample submission: (5, 3) \u001b[0;0m\n"]}],"source":["print(start+\"train:\", train_df.shape,end)\n","print(start+\"greeks:\", greeks_df.shape,end)\n","print(start+\"test:\", test_df.shape,end)\n","print(start+\"sample submission:\", sample_submission_df.shape,end)"]},{"cell_type":"code","execution_count":8,"id":"06713769","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:57.355481Z","iopub.status.busy":"2023-07-30T19:54:57.35495Z","iopub.status.idle":"2023-07-30T19:54:57.415427Z","shell.execute_reply":"2023-07-30T19:54:57.414093Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.089999,"end_time":"2023-07-30T19:54:57.418414","exception":false,"start_time":"2023-07-30T19:54:57.328415","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mtrain.csv:\u001b[0;0m\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 617 entries, 0 to 616\n","Data columns (total 58 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   Id      617 non-null    object \n"," 1   AB      617 non-null    float64\n"," 2   AF      617 non-null    float64\n"," 3   AH      617 non-null    float64\n"," 4   AM      617 non-null    float64\n"," 5   AR      617 non-null    float64\n"," 6   AX      617 non-null    float64\n"," 7   AY      617 non-null    float64\n"," 8   AZ      617 non-null    float64\n"," 9   BC      617 non-null    float64\n"," 10  BD      617 non-null    float64\n"," 11  BN      617 non-null    float64\n"," 12  BP      617 non-null    float64\n"," 13  BQ      557 non-null    float64\n"," 14  BR      617 non-null    float64\n"," 15  BZ      617 non-null    float64\n"," 16  CB      615 non-null    float64\n"," 17  CC      614 non-null    float64\n"," 18  CD      617 non-null    float64\n"," 19  CF      617 non-null    float64\n"," 20  CH      617 non-null    float64\n"," 21  CL      617 non-null    float64\n"," 22  CR      617 non-null    float64\n"," 23  CS      617 non-null    float64\n"," 24  CU      617 non-null    float64\n"," 25  CW      617 non-null    float64\n"," 26  DA      617 non-null    float64\n"," 27  DE      617 non-null    float64\n"," 28  DF      617 non-null    float64\n"," 29  DH      617 non-null    float64\n"," 30  DI      617 non-null    float64\n"," 31  DL      617 non-null    float64\n"," 32  DN      617 non-null    float64\n"," 33  DU      616 non-null    float64\n"," 34  DV      617 non-null    float64\n"," 35  DY      617 non-null    float64\n"," 36  EB      617 non-null    float64\n"," 37  EE      617 non-null    float64\n"," 38  EG      617 non-null    float64\n"," 39  EH      617 non-null    float64\n"," 40  EJ      617 non-null    object \n"," 41  EL      557 non-null    float64\n"," 42  EP      617 non-null    float64\n"," 43  EU      617 non-null    float64\n"," 44  FC      616 non-null    float64\n"," 45  FD      617 non-null    float64\n"," 46  FE      617 non-null    float64\n"," 47  FI      617 non-null    float64\n"," 48  FL      616 non-null    float64\n"," 49  FR      617 non-null    float64\n"," 50  FS      615 non-null    float64\n"," 51  GB      617 non-null    float64\n"," 52  GE      617 non-null    float64\n"," 53  GF      617 non-null    float64\n"," 54  GH      617 non-null    float64\n"," 55  GI      617 non-null    float64\n"," 56  GL      616 non-null    float64\n"," 57  Class   617 non-null    int64  \n","dtypes: float64(55), int64(1), object(2)\n","memory usage: 279.7+ KB\n","\u001b[1m\n","greeks_df:\u001b[0;0m\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 617 entries, 0 to 616\n","Data columns (total 6 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   Id       617 non-null    object\n"," 1   Alpha    617 non-null    object\n"," 2   Beta     617 non-null    object\n"," 3   Gamma    617 non-null    object\n"," 4   Delta    617 non-null    object\n"," 5   Epsilon  617 non-null    object\n","dtypes: object(6)\n","memory usage: 29.0+ KB\n","\u001b[1m\n","test_df:\u001b[0;0m\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5 entries, 0 to 4\n","Data columns (total 57 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   Id      5 non-null      object \n"," 1   AB      5 non-null      float64\n"," 2   AF      5 non-null      float64\n"," 3   AH      5 non-null      float64\n"," 4   AM      5 non-null      float64\n"," 5   AR      5 non-null      float64\n"," 6   AX      5 non-null      float64\n"," 7   AY      5 non-null      float64\n"," 8   AZ      5 non-null      float64\n"," 9   BC      5 non-null      float64\n"," 10  BD      5 non-null      float64\n"," 11  BN      5 non-null      float64\n"," 12  BP      5 non-null      float64\n"," 13  BQ      5 non-null      float64\n"," 14  BR      5 non-null      float64\n"," 15  BZ      5 non-null      float64\n"," 16  CB      5 non-null      float64\n"," 17  CC      5 non-null      float64\n"," 18  CD      5 non-null      float64\n"," 19  CF      5 non-null      float64\n"," 20  CH      5 non-null      float64\n"," 21  CL      5 non-null      float64\n"," 22  CR      5 non-null      float64\n"," 23  CS      5 non-null      float64\n"," 24  CU      5 non-null      float64\n"," 25  CW      5 non-null      float64\n"," 26  DA      5 non-null      float64\n"," 27  DE      5 non-null      float64\n"," 28  DF      5 non-null      float64\n"," 29  DH      5 non-null      float64\n"," 30  DI      5 non-null      float64\n"," 31  DL      5 non-null      float64\n"," 32  DN      5 non-null      float64\n"," 33  DU      5 non-null      float64\n"," 34  DV      5 non-null      float64\n"," 35  DY      5 non-null      float64\n"," 36  EB      5 non-null      float64\n"," 37  EE      5 non-null      float64\n"," 38  EG      5 non-null      float64\n"," 39  EH      5 non-null      float64\n"," 40  EJ      5 non-null      object \n"," 41  EL      5 non-null      float64\n"," 42  EP      5 non-null      float64\n"," 43  EU      5 non-null      float64\n"," 44  FC      5 non-null      float64\n"," 45  FD      5 non-null      float64\n"," 46  FE      5 non-null      float64\n"," 47  FI      5 non-null      float64\n"," 48  FL      5 non-null      float64\n"," 49  FR      5 non-null      float64\n"," 50  FS      5 non-null      float64\n"," 51  GB      5 non-null      float64\n"," 52  GE      5 non-null      float64\n"," 53  GF      5 non-null      float64\n"," 54  GH      5 non-null      float64\n"," 55  GI      5 non-null      float64\n"," 56  GL      5 non-null      float64\n","dtypes: float64(55), object(2)\n","memory usage: 2.4+ KB\n","\u001b[1m\n","sample_submission_df:\u001b[0;0m\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5 entries, 0 to 4\n","Data columns (total 3 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   Id       5 non-null      object \n"," 1   class_0  5 non-null      float64\n"," 2   class_1  5 non-null      float64\n","dtypes: float64(2), object(1)\n","memory usage: 248.0+ bytes\n"]}],"source":["print(start+\"train.csv:\"+end)\n","train_df.info()\n","print(start+\"\\ngreeks_df:\"+end)\n","greeks_df.info()\n","print(start+\"\\ntest_df:\"+end)\n","test_df.info()\n","print(start+\"\\nsample_submission_df:\"+end)\n","sample_submission_df.info()"]},{"cell_type":"code","execution_count":9,"id":"e1b76ab8","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:57.472305Z","iopub.status.busy":"2023-07-30T19:54:57.471351Z","iopub.status.idle":"2023-07-30T19:54:57.938266Z","shell.execute_reply":"2023-07-30T19:54:57.936973Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.496704,"end_time":"2023-07-30T19:54:57.940802","exception":false,"start_time":"2023-07-30T19:54:57.444098","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mtrain_df:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>557.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>615.000000</td>\n","      <td>614.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>616.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>557.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>616.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>616.000000</td>\n","      <td>617.000000</td>\n","      <td>615.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>617.000000</td>\n","      <td>616.000000</td>\n","      <td>617.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.477149</td>\n","      <td>3502.013221</td>\n","      <td>118.624513</td>\n","      <td>38.968552</td>\n","      <td>10.128242</td>\n","      <td>5.545576</td>\n","      <td>0.060320</td>\n","      <td>10.566447</td>\n","      <td>8.053012</td>\n","      <td>5350.388655</td>\n","      <td>21.419492</td>\n","      <td>231.322223</td>\n","      <td>98.328737</td>\n","      <td>1218.133238</td>\n","      <td>550.632525</td>\n","      <td>77.104151</td>\n","      <td>0.688801</td>\n","      <td>90.251735</td>\n","      <td>11.241064</td>\n","      <td>0.030615</td>\n","      <td>1.403761</td>\n","      <td>0.742262</td>\n","      <td>36.917590</td>\n","      <td>1.383792</td>\n","      <td>27.165653</td>\n","      <td>51.128326</td>\n","      <td>401.901299</td>\n","      <td>0.633884</td>\n","      <td>0.367002</td>\n","      <td>146.972099</td>\n","      <td>94.795377</td>\n","      <td>26.370568</td>\n","      <td>1.802900</td>\n","      <td>1.924830</td>\n","      <td>26.388989</td>\n","      <td>9.072700</td>\n","      <td>3.064778</td>\n","      <td>1731.248215</td>\n","      <td>0.305107</td>\n","      <td>69.582596</td>\n","      <td>105.060712</td>\n","      <td>69.117005</td>\n","      <td>71.341526</td>\n","      <td>6.930086</td>\n","      <td>10306.810737</td>\n","      <td>10.111079</td>\n","      <td>5.433199</td>\n","      <td>3.533905</td>\n","      <td>0.421501</td>\n","      <td>20.724856</td>\n","      <td>131.714987</td>\n","      <td>14679.595398</td>\n","      <td>31.489716</td>\n","      <td>50.584437</td>\n","      <td>8.530961</td>\n","      <td>0.175041</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.468388</td>\n","      <td>2300.322717</td>\n","      <td>127.838950</td>\n","      <td>69.728226</td>\n","      <td>10.518877</td>\n","      <td>2.551696</td>\n","      <td>0.416817</td>\n","      <td>4.350645</td>\n","      <td>65.166943</td>\n","      <td>3021.326641</td>\n","      <td>3.478278</td>\n","      <td>183.992505</td>\n","      <td>96.479371</td>\n","      <td>7575.293707</td>\n","      <td>2076.371275</td>\n","      <td>159.049302</td>\n","      <td>0.263994</td>\n","      <td>51.585130</td>\n","      <td>13.571133</td>\n","      <td>0.014808</td>\n","      <td>1.922210</td>\n","      <td>0.281195</td>\n","      <td>17.266347</td>\n","      <td>0.538717</td>\n","      <td>14.645993</td>\n","      <td>21.210888</td>\n","      <td>317.745623</td>\n","      <td>1.912384</td>\n","      <td>0.112989</td>\n","      <td>86.084419</td>\n","      <td>28.243187</td>\n","      <td>8.038825</td>\n","      <td>9.034721</td>\n","      <td>1.484555</td>\n","      <td>18.116679</td>\n","      <td>6.200281</td>\n","      <td>2.058344</td>\n","      <td>1790.227476</td>\n","      <td>1.847499</td>\n","      <td>38.555707</td>\n","      <td>68.445620</td>\n","      <td>390.187057</td>\n","      <td>165.551545</td>\n","      <td>64.754262</td>\n","      <td>11331.294051</td>\n","      <td>2.934025</td>\n","      <td>11.496257</td>\n","      <td>50.181948</td>\n","      <td>1.305365</td>\n","      <td>9.991907</td>\n","      <td>144.181524</td>\n","      <td>19352.959387</td>\n","      <td>9.864239</td>\n","      <td>36.266251</td>\n","      <td>10.327010</td>\n","      <td>0.380310</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.081187</td>\n","      <td>192.593280</td>\n","      <td>85.200147</td>\n","      <td>3.177522</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>1693.624320</td>\n","      <td>9.886800</td>\n","      <td>72.948951</td>\n","      <td>1.331155</td>\n","      <td>51.216883</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.176874</td>\n","      <td>23.387600</td>\n","      <td>0.510888</td>\n","      <td>0.003184</td>\n","      <td>1.050225</td>\n","      <td>0.069225</td>\n","      <td>13.784111</td>\n","      <td>0.137925</td>\n","      <td>7.030640</td>\n","      <td>6.906400</td>\n","      <td>35.998895</td>\n","      <td>0.238680</td>\n","      <td>0.040995</td>\n","      <td>60.232470</td>\n","      <td>10.345600</td>\n","      <td>6.339496</td>\n","      <td>0.005518</td>\n","      <td>1.743070</td>\n","      <td>0.804068</td>\n","      <td>4.926396</td>\n","      <td>0.286201</td>\n","      <td>185.594100</td>\n","      <td>0.003042</td>\n","      <td>5.394675</td>\n","      <td>78.526968</td>\n","      <td>3.828384</td>\n","      <td>7.534128</td>\n","      <td>0.296850</td>\n","      <td>1563.136688</td>\n","      <td>3.583450</td>\n","      <td>0.173229</td>\n","      <td>0.497060</td>\n","      <td>0.067730</td>\n","      <td>4.102182</td>\n","      <td>72.611063</td>\n","      <td>13.038894</td>\n","      <td>9.432735</td>\n","      <td>0.897628</td>\n","      <td>0.001129</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.252107</td>\n","      <td>2197.345480</td>\n","      <td>85.200147</td>\n","      <td>12.270314</td>\n","      <td>8.138688</td>\n","      <td>4.128294</td>\n","      <td>0.025578</td>\n","      <td>8.129580</td>\n","      <td>1.229900</td>\n","      <td>4155.702870</td>\n","      <td>19.420500</td>\n","      <td>156.847239</td>\n","      <td>27.834425</td>\n","      <td>424.990642</td>\n","      <td>257.432377</td>\n","      <td>23.317567</td>\n","      <td>0.563688</td>\n","      <td>64.724192</td>\n","      <td>5.066306</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.589575</td>\n","      <td>29.782467</td>\n","      <td>1.070298</td>\n","      <td>7.030640</td>\n","      <td>37.942520</td>\n","      <td>188.815690</td>\n","      <td>0.238680</td>\n","      <td>0.295164</td>\n","      <td>102.703553</td>\n","      <td>78.232240</td>\n","      <td>20.888264</td>\n","      <td>0.005518</td>\n","      <td>1.743070</td>\n","      <td>14.715792</td>\n","      <td>5.965392</td>\n","      <td>1.648679</td>\n","      <td>1111.160625</td>\n","      <td>0.003042</td>\n","      <td>30.927468</td>\n","      <td>78.526968</td>\n","      <td>4.324656</td>\n","      <td>25.815384</td>\n","      <td>0.296850</td>\n","      <td>5164.666260</td>\n","      <td>8.523098</td>\n","      <td>0.173229</td>\n","      <td>0.497060</td>\n","      <td>0.067730</td>\n","      <td>14.036718</td>\n","      <td>72.611063</td>\n","      <td>2798.992584</td>\n","      <td>25.034888</td>\n","      <td>23.011684</td>\n","      <td>0.124392</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.354659</td>\n","      <td>3120.318960</td>\n","      <td>85.200147</td>\n","      <td>20.533110</td>\n","      <td>8.138688</td>\n","      <td>5.031912</td>\n","      <td>0.025578</td>\n","      <td>10.461320</td>\n","      <td>1.229900</td>\n","      <td>4997.960730</td>\n","      <td>21.186000</td>\n","      <td>193.908816</td>\n","      <td>61.642115</td>\n","      <td>627.417402</td>\n","      <td>257.432377</td>\n","      <td>42.554330</td>\n","      <td>0.658715</td>\n","      <td>79.819104</td>\n","      <td>9.123000</td>\n","      <td>0.027860</td>\n","      <td>1.050225</td>\n","      <td>0.730800</td>\n","      <td>34.835130</td>\n","      <td>1.351665</td>\n","      <td>36.019104</td>\n","      <td>49.180940</td>\n","      <td>307.509595</td>\n","      <td>0.238680</td>\n","      <td>0.358023</td>\n","      <td>130.050630</td>\n","      <td>96.264960</td>\n","      <td>25.248800</td>\n","      <td>0.251741</td>\n","      <td>1.743070</td>\n","      <td>21.642456</td>\n","      <td>8.149404</td>\n","      <td>2.616119</td>\n","      <td>1493.817413</td>\n","      <td>0.085176</td>\n","      <td>71.949306</td>\n","      <td>78.526968</td>\n","      <td>22.641144</td>\n","      <td>36.394008</td>\n","      <td>1.870155</td>\n","      <td>7345.143424</td>\n","      <td>9.945452</td>\n","      <td>3.028141</td>\n","      <td>1.131000</td>\n","      <td>0.250601</td>\n","      <td>18.771436</td>\n","      <td>72.611063</td>\n","      <td>7838.273610</td>\n","      <td>30.608946</td>\n","      <td>41.007968</td>\n","      <td>0.337827</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.559763</td>\n","      <td>4361.637390</td>\n","      <td>113.739540</td>\n","      <td>39.139886</td>\n","      <td>8.138688</td>\n","      <td>6.431634</td>\n","      <td>0.036845</td>\n","      <td>12.969516</td>\n","      <td>5.081244</td>\n","      <td>6035.885700</td>\n","      <td>23.657700</td>\n","      <td>247.803462</td>\n","      <td>134.009015</td>\n","      <td>975.649259</td>\n","      <td>257.432377</td>\n","      <td>77.310097</td>\n","      <td>0.772206</td>\n","      <td>99.813520</td>\n","      <td>13.565901</td>\n","      <td>0.034427</td>\n","      <td>1.228445</td>\n","      <td>0.859350</td>\n","      <td>40.529401</td>\n","      <td>1.660617</td>\n","      <td>37.935832</td>\n","      <td>61.408760</td>\n","      <td>507.896200</td>\n","      <td>0.238680</td>\n","      <td>0.426348</td>\n","      <td>165.836955</td>\n","      <td>110.640680</td>\n","      <td>30.544224</td>\n","      <td>1.058690</td>\n","      <td>1.743070</td>\n","      <td>34.058344</td>\n","      <td>10.503048</td>\n","      <td>3.910070</td>\n","      <td>1905.701475</td>\n","      <td>0.237276</td>\n","      <td>109.125159</td>\n","      <td>112.766654</td>\n","      <td>49.085352</td>\n","      <td>56.714448</td>\n","      <td>4.880214</td>\n","      <td>10647.951650</td>\n","      <td>11.516657</td>\n","      <td>6.238814</td>\n","      <td>1.512060</td>\n","      <td>0.535067</td>\n","      <td>25.608406</td>\n","      <td>127.591671</td>\n","      <td>19035.709240</td>\n","      <td>36.863947</td>\n","      <td>67.931664</td>\n","      <td>21.978000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>6.161666</td>\n","      <td>28688.187660</td>\n","      <td>1910.123198</td>\n","      <td>630.518230</td>\n","      <td>178.943634</td>\n","      <td>38.270880</td>\n","      <td>10.315851</td>\n","      <td>38.971568</td>\n","      <td>1463.693448</td>\n","      <td>53060.599240</td>\n","      <td>29.307300</td>\n","      <td>2447.810550</td>\n","      <td>344.644105</td>\n","      <td>179250.252900</td>\n","      <td>50092.459300</td>\n","      <td>2271.436167</td>\n","      <td>4.103032</td>\n","      <td>633.534408</td>\n","      <td>200.967526</td>\n","      <td>0.224074</td>\n","      <td>31.688153</td>\n","      <td>3.039675</td>\n","      <td>267.942823</td>\n","      <td>4.951507</td>\n","      <td>64.521624</td>\n","      <td>210.330920</td>\n","      <td>2103.405190</td>\n","      <td>37.895013</td>\n","      <td>1.060404</td>\n","      <td>1049.168078</td>\n","      <td>326.236200</td>\n","      <td>62.808096</td>\n","      <td>161.355315</td>\n","      <td>25.192930</td>\n","      <td>152.355164</td>\n","      <td>94.958580</td>\n","      <td>18.324926</td>\n","      <td>30243.758780</td>\n","      <td>42.569748</td>\n","      <td>109.125159</td>\n","      <td>1063.594578</td>\n","      <td>6501.264480</td>\n","      <td>3030.655824</td>\n","      <td>1578.654237</td>\n","      <td>143224.682300</td>\n","      <td>35.851039</td>\n","      <td>137.932739</td>\n","      <td>1244.227020</td>\n","      <td>31.365763</td>\n","      <td>135.781294</td>\n","      <td>1497.351958</td>\n","      <td>143790.071200</td>\n","      <td>81.210825</td>\n","      <td>191.194764</td>\n","      <td>21.978000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               AB            AF           AH          AM          AR  \\\n","count  617.000000    617.000000   617.000000  617.000000  617.000000   \n","mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n","std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n","min      0.081187    192.593280    85.200147    3.177522    8.138688   \n","25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n","50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n","75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n","max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n","\n","               AX          AY          AZ           BC           BD   \\\n","count  617.000000  617.000000  617.000000   617.000000    617.000000   \n","mean     5.545576    0.060320   10.566447     8.053012   5350.388655   \n","std      2.551696    0.416817    4.350645    65.166943   3021.326641   \n","min      0.699861    0.025578    3.396778     1.229900   1693.624320   \n","25%      4.128294    0.025578    8.129580     1.229900   4155.702870   \n","50%      5.031912    0.025578   10.461320     1.229900   4997.960730   \n","75%      6.431634    0.036845   12.969516     5.081244   6035.885700   \n","max     38.270880   10.315851   38.971568  1463.693448  53060.599240   \n","\n","               BN           BP          BQ             BR            BZ  \\\n","count  617.000000   617.000000  557.000000     617.000000    617.000000   \n","mean    21.419492   231.322223   98.328737    1218.133238    550.632525   \n","std      3.478278   183.992505   96.479371    7575.293707   2076.371275   \n","min      9.886800    72.948951    1.331155      51.216883    257.432377   \n","25%     19.420500   156.847239   27.834425     424.990642    257.432377   \n","50%     21.186000   193.908816   61.642115     627.417402    257.432377   \n","75%     23.657700   247.803462  134.009015     975.649259    257.432377   \n","max     29.307300  2447.810550  344.644105  179250.252900  50092.459300   \n","\n","                CB          CC         CD           CF          CH  \\\n","count   615.000000  614.000000  617.000000  617.000000  617.000000   \n","mean     77.104151    0.688801   90.251735   11.241064    0.030615   \n","std     159.049302    0.263994   51.585130   13.571133    0.014808   \n","min      12.499760    0.176874   23.387600    0.510888    0.003184   \n","25%      23.317567    0.563688   64.724192    5.066306    0.023482   \n","50%      42.554330    0.658715   79.819104    9.123000    0.027860   \n","75%      77.310097    0.772206   99.813520   13.565901    0.034427   \n","max    2271.436167    4.103032  633.534408  200.967526    0.224074   \n","\n","               CL          CR          CS          CU         CW           DA  \\\n","count  617.000000  617.000000  617.000000  617.000000  617.000000  617.000000   \n","mean     1.403761    0.742262   36.917590    1.383792   27.165653   51.128326   \n","std      1.922210    0.281195   17.266347    0.538717   14.645993   21.210888   \n","min      1.050225    0.069225   13.784111    0.137925    7.030640    6.906400   \n","25%      1.050225    0.589575   29.782467    1.070298    7.030640   37.942520   \n","50%      1.050225    0.730800   34.835130    1.351665   36.019104   49.180940   \n","75%      1.228445    0.859350   40.529401    1.660617   37.935832   61.408760   \n","max     31.688153    3.039675  267.942823    4.951507   64.521624  210.330920   \n","\n","                DE          DF          DH           DI          DL  \\\n","count   617.000000  617.000000  617.000000   617.000000  617.000000   \n","mean    401.901299    0.633884    0.367002   146.972099   94.795377   \n","std     317.745623    1.912384    0.112989    86.084419   28.243187   \n","min      35.998895    0.238680    0.040995    60.232470   10.345600   \n","25%     188.815690    0.238680    0.295164   102.703553   78.232240   \n","50%     307.509595    0.238680    0.358023   130.050630   96.264960   \n","75%     507.896200    0.238680    0.426348   165.836955  110.640680   \n","max    2103.405190   37.895013    1.060404  1049.168078  326.236200   \n","\n","               DN          DU          DV          DY          EB          EE  \\\n","count  617.000000  616.000000  617.000000  617.000000  617.000000  617.000000   \n","mean    26.370568    1.802900    1.924830   26.388989    9.072700    3.064778   \n","std      8.038825    9.034721    1.484555   18.116679    6.200281    2.058344   \n","min      6.339496    0.005518    1.743070    0.804068    4.926396    0.286201   \n","25%     20.888264    0.005518    1.743070   14.715792    5.965392    1.648679   \n","50%     25.248800    0.251741    1.743070   21.642456    8.149404    2.616119   \n","75%     30.544224    1.058690    1.743070   34.058344   10.503048    3.910070   \n","max     62.808096  161.355315   25.192930  152.355164   94.958580   18.324926   \n","\n","                 EG          EH          EL           EP           EU  \\\n","count    617.000000  617.000000  557.000000   617.000000   617.000000   \n","mean    1731.248215    0.305107   69.582596   105.060712    69.117005   \n","std     1790.227476    1.847499   38.555707    68.445620   390.187057   \n","min      185.594100    0.003042    5.394675    78.526968     3.828384   \n","25%     1111.160625    0.003042   30.927468    78.526968     4.324656   \n","50%     1493.817413    0.085176   71.949306    78.526968    22.641144   \n","75%     1905.701475    0.237276  109.125159   112.766654    49.085352   \n","max    30243.758780   42.569748  109.125159  1063.594578  6501.264480   \n","\n","                FC          FD              FE          FI          FL  \\\n","count   616.000000   617.000000     617.000000  617.000000  616.000000   \n","mean     71.341526     6.930086   10306.810737   10.111079    5.433199   \n","std     165.551545    64.754262   11331.294051    2.934025   11.496257   \n","min       7.534128     0.296850    1563.136688    3.583450    0.173229   \n","25%      25.815384     0.296850    5164.666260    8.523098    0.173229   \n","50%      36.394008     1.870155    7345.143424    9.945452    3.028141   \n","75%      56.714448     4.880214   10647.951650   11.516657    6.238814   \n","max    3030.655824  1578.654237  143224.682300   35.851039  137.932739   \n","\n","                FR          FS          GB           GE             GF  \\\n","count   617.000000  615.000000  617.000000   617.000000     617.000000   \n","mean      3.533905    0.421501   20.724856   131.714987   14679.595398   \n","std      50.181948    1.305365    9.991907   144.181524   19352.959387   \n","min       0.497060    0.067730    4.102182    72.611063      13.038894   \n","25%       0.497060    0.067730   14.036718    72.611063    2798.992584   \n","50%       1.131000    0.250601   18.771436    72.611063    7838.273610   \n","75%       1.512060    0.535067   25.608406   127.591671   19035.709240   \n","max    1244.227020   31.365763  135.781294  1497.351958  143790.071200   \n","\n","               GH          GI          GL       Class  \n","count  617.000000  617.000000  616.000000  617.000000  \n","mean    31.489716   50.584437    8.530961    0.175041  \n","std      9.864239   36.266251   10.327010    0.380310  \n","min      9.432735    0.897628    0.001129    0.000000  \n","25%     25.034888   23.011684    0.124392    0.000000  \n","50%     30.608946   41.007968    0.337827    0.000000  \n","75%     36.863947   67.931664   21.978000    0.000000  \n","max     81.210825  191.194764   21.978000    1.000000  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","greeks_df:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Alpha</th>\n","      <th>Beta</th>\n","      <th>Gamma</th>\n","      <th>Delta</th>\n","      <th>Epsilon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>617</td>\n","      <td>617</td>\n","      <td>617</td>\n","      <td>617</td>\n","      <td>617</td>\n","      <td>617</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>617</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>198</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>509</td>\n","      <td>407</td>\n","      <td>445</td>\n","      <td>456</td>\n","      <td>144</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Id Alpha Beta Gamma Delta  Epsilon\n","count            617   617  617   617   617      617\n","unique           617     4    3     8     4      198\n","top     000ff2bfdfe9     A    C     M     B  Unknown\n","freq               1   509  407   445   456      144"]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","test_df:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        AB   AF   AH   AM   AR   AX   AY   AZ   BC  BD    BN   BP   BQ   BR  \\\n","count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0   \n","mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","        BZ   CB   CC  CD    CF   CH   CL   CR   CS   CU  CW    DA   DE   DF  \\\n","count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0   \n","mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","        DH   DI   DL   DN   DU   DV   DY   EB   EE   EG   EH   EL   EP   EU  \\\n","count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0   \n","mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n","\n","        FC  FD    FE   FI   FL   FR   FS   GB   GE   GF   GH   GI   GL  \n","count  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  \n","mean   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","std    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","min    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","25%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","50%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","75%    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n","max    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\u001b[1m\n","sample_submission_df:\u001b[0;0m\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class_0</th>\n","      <th>class_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       class_0  class_1\n","count      5.0      5.0\n","mean       0.5      0.5\n","std        0.0      0.0\n","min        0.5      0.5\n","25%        0.5      0.5\n","50%        0.5      0.5\n","75%        0.5      0.5\n","max        0.5      0.5"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["print(start+\"train_df:\"+end)\n","train_df.describe()\n","print(start+\"\\ngreeks_df:\"+end)\n","greeks_df.describe()\n","print(start+\"\\ntest_df:\"+end)\n","test_df.describe()\n","print(start+\"\\nsample_submission_df:\"+end)\n","sample_submission_df.describe()"]},{"cell_type":"markdown","id":"c672f626","metadata":{"papermill":{"duration":0.02823,"end_time":"2023-07-30T19:54:57.997992","exception":false,"start_time":"2023-07-30T19:54:57.969762","status":"completed"},"tags":[]},"source":["# Check missing data"]},{"cell_type":"code","execution_count":10,"id":"97e6c936","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:58.058165Z","iopub.status.busy":"2023-07-30T19:54:58.0577Z","iopub.status.idle":"2023-07-30T19:54:58.075644Z","shell.execute_reply":"2023-07-30T19:54:58.073944Z"},"papermill":{"duration":0.05189,"end_time":"2023-07-30T19:54:58.079104","exception":false,"start_time":"2023-07-30T19:54:58.027214","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mCheck missing values:\u001b[0;0m\n","\u001b[1m\n","greeks_df:\u001b[0;0m\n","Id         0\n","Alpha      0\n","Beta       0\n","Gamma      0\n","Delta      0\n","Epsilon    0\n","dtype: int64\n","\u001b[1m\n","train_df:\u001b[0;0m\n","Id        0\n","AB        0\n","AF        0\n","AH        0\n","AM        0\n","AR        0\n","AX        0\n","AY        0\n","AZ        0\n","BC        0\n","BD        0\n","BN        0\n","BP        0\n","BQ       60\n","BR        0\n","BZ        0\n","CB        2\n","CC        3\n","CD        0\n","CF        0\n","CH        0\n","CL        0\n","CR        0\n","CS        0\n","CU        0\n","CW        0\n","DA        0\n","DE        0\n","DF        0\n","DH        0\n","DI        0\n","DL        0\n","DN        0\n","DU        1\n","DV        0\n","DY        0\n","EB        0\n","EE        0\n","EG        0\n","EH        0\n","EJ        0\n","EL       60\n","EP        0\n","EU        0\n","FC        1\n","FD        0\n","FE        0\n","FI        0\n","FL        1\n","FR        0\n","FS        2\n","GB        0\n","GE        0\n","GF        0\n","GH        0\n","GI        0\n","GL        1\n","Class     0\n","dtype: int64\n","\u001b[1m\n","test_df:\u001b[0;0m\n","Id     0\n","AB     0\n","AF     0\n","AH     0\n","AM     0\n","AR     0\n","AX     0\n","AY     0\n","AZ     0\n","BC     0\n","BD     0\n","BN     0\n","BP     0\n","BQ     0\n","BR     0\n","BZ     0\n","CB     0\n","CC     0\n","CD     0\n","CF     0\n","CH     0\n","CL     0\n","CR     0\n","CS     0\n","CU     0\n","CW     0\n","DA     0\n","DE     0\n","DF     0\n","DH     0\n","DI     0\n","DL     0\n","DN     0\n","DU     0\n","DV     0\n","DY     0\n","EB     0\n","EE     0\n","EG     0\n","EH     0\n","EJ     0\n","EL     0\n","EP     0\n","EU     0\n","FC     0\n","FD     0\n","FE     0\n","FI     0\n","FL     0\n","FR     0\n","FS     0\n","GB     0\n","GE     0\n","GF     0\n","GH     0\n","GI     0\n","GL     0\n","dtype: int64\n","\u001b[1m\n","sample_submission_df:\u001b[0;0m\n","Id         0\n","class_0    0\n","class_1    0\n","dtype: int64\n"]}],"source":["# Check for missing values\n","\n","print(start+'Check missing values:'+end)\n","\n","print(start+\"\\ngreeks_df:\"+end)\n","print(greeks_df.isnull().sum())\n","print(start+\"\\ntrain_df:\"+end)\n","print(train_df.isnull().sum())\n","print(start+\"\\ntest_df:\"+end)\n","print(test_df.isnull().sum())\n","print(start+\"\\nsample_submission_df:\"+end)\n","print(sample_submission_df.isnull().sum())"]},{"cell_type":"code","execution_count":11,"id":"159b3624","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:58.139796Z","iopub.status.busy":"2023-07-30T19:54:58.139369Z","iopub.status.idle":"2023-07-30T19:54:58.35423Z","shell.execute_reply":"2023-07-30T19:54:58.353078Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.253391,"end_time":"2023-07-30T19:54:58.36077","exception":false,"start_time":"2023-07-30T19:54:58.107379","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EJ</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>0594b00fb30a</td>\n","      <td>0.346113</td>\n","      <td>3238.43674</td>\n","      <td>85.200147</td>\n","      <td>28.888816</td>\n","      <td>8.138688</td>\n","      <td>4.021986</td>\n","      <td>0.025578</td>\n","      <td>8.243016</td>\n","      <td>3.626448</td>\n","      <td>6569.370010</td>\n","      <td>20.4798</td>\n","      <td>135.881145</td>\n","      <td>NaN</td>\n","      <td>601.802912</td>\n","      <td>257.432377</td>\n","      <td>116.100712</td>\n","      <td>0.855496</td>\n","      <td>93.225352</td>\n","      <td>14.566390</td>\n","      <td>0.033830</td>\n","      <td>1.050225</td>\n","      <td>1.050375</td>\n","      <td>29.914973</td>\n","      <td>1.473039</td>\n","      <td>43.015704</td>\n","      <td>76.77356</td>\n","      <td>231.134460</td>\n","      <td>0.238680</td>\n","      <td>0.330693</td>\n","      <td>131.349555</td>\n","      <td>98.16872</td>\n","      <td>29.466032</td>\n","      <td>0.613833</td>\n","      <td>1.74307</td>\n","      <td>7.200676</td>\n","      <td>10.771632</td>\n","      <td>1.342323</td>\n","      <td>3004.926575</td>\n","      <td>0.066924</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>56.610456</td>\n","      <td>35.300160</td>\n","      <td>1.389258</td>\n","      <td>3380.026318</td>\n","      <td>11.450501</td>\n","      <td>4.762291</td>\n","      <td>1.18262</td>\n","      <td>0.067730</td>\n","      <td>17.245908</td>\n","      <td>147.218610</td>\n","      <td>4589.611956</td>\n","      <td>29.771721</td>\n","      <td>54.675576</td>\n","      <td>0.073416</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>07760b4cf3f8</td>\n","      <td>0.666588</td>\n","      <td>3657.78160</td>\n","      <td>304.283751</td>\n","      <td>75.418144</td>\n","      <td>8.138688</td>\n","      <td>12.818973</td>\n","      <td>0.025578</td>\n","      <td>8.167392</td>\n","      <td>1.229900</td>\n","      <td>3597.873030</td>\n","      <td>17.6550</td>\n","      <td>227.744514</td>\n","      <td>NaN</td>\n","      <td>842.371642</td>\n","      <td>257.432377</td>\n","      <td>20.578649</td>\n","      <td>0.651609</td>\n","      <td>373.115464</td>\n","      <td>6.925878</td>\n","      <td>0.051342</td>\n","      <td>1.050225</td>\n","      <td>0.768900</td>\n","      <td>13.784111</td>\n","      <td>1.953018</td>\n","      <td>7.030640</td>\n","      <td>24.32760</td>\n","      <td>647.221725</td>\n","      <td>0.238680</td>\n","      <td>0.333426</td>\n","      <td>117.818145</td>\n","      <td>75.31724</td>\n","      <td>15.927216</td>\n","      <td>0.268983</td>\n","      <td>1.74307</td>\n","      <td>6.446020</td>\n","      <td>4.926396</td>\n","      <td>3.115963</td>\n","      <td>185.594100</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>41.357688</td>\n","      <td>41.566224</td>\n","      <td>2.719146</td>\n","      <td>4143.635748</td>\n","      <td>7.723713</td>\n","      <td>67.872762</td>\n","      <td>0.77720</td>\n","      <td>0.582478</td>\n","      <td>4.102182</td>\n","      <td>72.611063</td>\n","      <td>2218.449060</td>\n","      <td>23.806958</td>\n","      <td>35.843392</td>\n","      <td>0.015231</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0b2cc0b0e6c5</td>\n","      <td>0.269199</td>\n","      <td>1586.67784</td>\n","      <td>85.200147</td>\n","      <td>14.459893</td>\n","      <td>8.138688</td>\n","      <td>4.907886</td>\n","      <td>0.032886</td>\n","      <td>7.007824</td>\n","      <td>3.521028</td>\n","      <td>7125.170390</td>\n","      <td>19.7736</td>\n","      <td>176.541633</td>\n","      <td>NaN</td>\n","      <td>700.704062</td>\n","      <td>257.432377</td>\n","      <td>23.317567</td>\n","      <td>0.574937</td>\n","      <td>67.094664</td>\n","      <td>35.649643</td>\n","      <td>0.033432</td>\n","      <td>1.050225</td>\n","      <td>0.621375</td>\n","      <td>33.660011</td>\n","      <td>1.903365</td>\n","      <td>36.658872</td>\n","      <td>57.58308</td>\n","      <td>176.650485</td>\n","      <td>0.238680</td>\n","      <td>0.475542</td>\n","      <td>129.756960</td>\n","      <td>85.36710</td>\n","      <td>21.386416</td>\n","      <td>0.372438</td>\n","      <td>1.74307</td>\n","      <td>17.932064</td>\n","      <td>6.241044</td>\n","      <td>3.970535</td>\n","      <td>1389.371025</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>102.487333</td>\n","      <td>36.673488</td>\n","      <td>32.329920</td>\n","      <td>3.312846</td>\n","      <td>4170.630264</td>\n","      <td>13.727370</td>\n","      <td>97.303580</td>\n","      <td>2.73702</td>\n","      <td>0.711165</td>\n","      <td>16.362218</td>\n","      <td>72.611063</td>\n","      <td>3597.877440</td>\n","      <td>31.330820</td>\n","      <td>25.444796</td>\n","      <td>0.011000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0cf6c827b8bb</td>\n","      <td>0.371751</td>\n","      <td>2354.54142</td>\n","      <td>105.030540</td>\n","      <td>5.150311</td>\n","      <td>8.138688</td>\n","      <td>10.409325</td>\n","      <td>0.025578</td>\n","      <td>11.526358</td>\n","      <td>2.754976</td>\n","      <td>5435.445190</td>\n","      <td>19.7736</td>\n","      <td>114.529302</td>\n","      <td>NaN</td>\n","      <td>220.658446</td>\n","      <td>257.432377</td>\n","      <td>134.694105</td>\n","      <td>0.780432</td>\n","      <td>56.891328</td>\n","      <td>6.659790</td>\n","      <td>0.023880</td>\n","      <td>1.050225</td>\n","      <td>0.571237</td>\n","      <td>33.109065</td>\n","      <td>1.125468</td>\n","      <td>42.228736</td>\n","      <td>30.65394</td>\n","      <td>149.521590</td>\n","      <td>0.238680</td>\n","      <td>0.409950</td>\n","      <td>96.227752</td>\n","      <td>95.75828</td>\n","      <td>21.270408</td>\n","      <td>0.600039</td>\n","      <td>1.74307</td>\n","      <td>27.686442</td>\n","      <td>4.926396</td>\n","      <td>6.735801</td>\n","      <td>8012.394450</td>\n","      <td>0.121680</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>21.775200</td>\n","      <td>35.808528</td>\n","      <td>2.493540</td>\n","      <td>5709.501083</td>\n","      <td>8.481751</td>\n","      <td>4.648113</td>\n","      <td>0.49706</td>\n","      <td>0.866944</td>\n","      <td>21.664358</td>\n","      <td>198.469061</td>\n","      <td>5987.708568</td>\n","      <td>32.610844</td>\n","      <td>15.019194</td>\n","      <td>0.136552</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0d1b855c7635</td>\n","      <td>0.158101</td>\n","      <td>3257.64549</td>\n","      <td>138.368592</td>\n","      <td>8.640630</td>\n","      <td>18.385464</td>\n","      <td>4.146012</td>\n","      <td>0.182700</td>\n","      <td>4.099451</td>\n","      <td>7.836220</td>\n","      <td>3633.584335</td>\n","      <td>22.2453</td>\n","      <td>170.308184</td>\n","      <td>30.010903</td>\n","      <td>355.723543</td>\n","      <td>2568.243295</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>49.688740</td>\n","      <td>11.840134</td>\n","      <td>0.026069</td>\n","      <td>1.050225</td>\n","      <td>0.731025</td>\n","      <td>57.192031</td>\n","      <td>1.299254</td>\n","      <td>36.817848</td>\n","      <td>42.31334</td>\n","      <td>356.052887</td>\n","      <td>0.901017</td>\n","      <td>0.379887</td>\n","      <td>137.799000</td>\n","      <td>77.89940</td>\n","      <td>15.988632</td>\n","      <td>0.005518</td>\n","      <td>1.74307</td>\n","      <td>23.394336</td>\n","      <td>15.429444</td>\n","      <td>1.130696</td>\n","      <td>559.246525</td>\n","      <td>0.003042</td>\n","      <td>A</td>\n","      <td>87.303431</td>\n","      <td>304.176138</td>\n","      <td>47.280036</td>\n","      <td>117.815712</td>\n","      <td>0.296850</td>\n","      <td>13173.694370</td>\n","      <td>10.358927</td>\n","      <td>0.173229</td>\n","      <td>1.82323</td>\n","      <td>0.433472</td>\n","      <td>8.311337</td>\n","      <td>72.611063</td>\n","      <td>1884.728169</td>\n","      <td>48.039971</td>\n","      <td>37.160256</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>12d002d52230</td>\n","      <td>1.491277</td>\n","      <td>2434.32640</td>\n","      <td>137.149332</td>\n","      <td>124.242349</td>\n","      <td>8.138688</td>\n","      <td>4.730706</td>\n","      <td>0.025578</td>\n","      <td>4.487024</td>\n","      <td>1.229900</td>\n","      <td>2734.489610</td>\n","      <td>20.4798</td>\n","      <td>129.378519</td>\n","      <td>NaN</td>\n","      <td>2148.501967</td>\n","      <td>257.432377</td>\n","      <td>94.262896</td>\n","      <td>0.715257</td>\n","      <td>210.837232</td>\n","      <td>10.924793</td>\n","      <td>0.044974</td>\n","      <td>1.196620</td>\n","      <td>3.039675</td>\n","      <td>22.717805</td>\n","      <td>1.081332</td>\n","      <td>39.496704</td>\n","      <td>32.13804</td>\n","      <td>556.277615</td>\n","      <td>0.238680</td>\n","      <td>0.308829</td>\n","      <td>264.318060</td>\n","      <td>102.47868</td>\n","      <td>18.820592</td>\n","      <td>0.151734</td>\n","      <td>1.74307</td>\n","      <td>39.264572</td>\n","      <td>7.089204</td>\n","      <td>5.865105</td>\n","      <td>1000.589825</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>102.199994</td>\n","      <td>41.383008</td>\n","      <td>17.867136</td>\n","      <td>0.486834</td>\n","      <td>6448.462858</td>\n","      <td>4.917596</td>\n","      <td>9.126892</td>\n","      <td>2.44238</td>\n","      <td>0.067730</td>\n","      <td>30.919848</td>\n","      <td>72.611063</td>\n","      <td>819.350802</td>\n","      <td>20.156657</td>\n","      <td>31.537864</td>\n","      <td>0.027000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>1319c3883fff</td>\n","      <td>0.243561</td>\n","      <td>3316.81570</td>\n","      <td>85.200147</td>\n","      <td>13.406913</td>\n","      <td>8.138688</td>\n","      <td>3.809370</td>\n","      <td>0.025578</td>\n","      <td>10.505434</td>\n","      <td>4.258968</td>\n","      <td>3042.040690</td>\n","      <td>18.3612</td>\n","      <td>122.748723</td>\n","      <td>NaN</td>\n","      <td>366.787164</td>\n","      <td>257.432377</td>\n","      <td>38.234560</td>\n","      <td>0.650385</td>\n","      <td>85.471768</td>\n","      <td>15.300792</td>\n","      <td>0.018308</td>\n","      <td>1.050225</td>\n","      <td>0.895950</td>\n","      <td>32.474431</td>\n","      <td>1.130985</td>\n","      <td>34.569920</td>\n","      <td>51.10348</td>\n","      <td>802.970055</td>\n","      <td>0.238680</td>\n","      <td>0.396285</td>\n","      <td>129.113145</td>\n","      <td>71.35708</td>\n","      <td>29.186248</td>\n","      <td>0.558657</td>\n","      <td>1.74307</td>\n","      <td>12.977388</td>\n","      <td>4.926396</td>\n","      <td>6.497972</td>\n","      <td>1470.425350</td>\n","      <td>0.042588</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>3.828384</td>\n","      <td>18.901008</td>\n","      <td>3.449397</td>\n","      <td>6946.192026</td>\n","      <td>9.162606</td>\n","      <td>17.726310</td>\n","      <td>0.99586</td>\n","      <td>0.291239</td>\n","      <td>14.585536</td>\n","      <td>160.164837</td>\n","      <td>6209.544726</td>\n","      <td>36.942088</td>\n","      <td>33.093924</td>\n","      <td>0.051333</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>135f1d1da85e</td>\n","      <td>0.820416</td>\n","      <td>3594.95356</td>\n","      <td>134.214399</td>\n","      <td>54.129366</td>\n","      <td>8.138688</td>\n","      <td>7.565586</td>\n","      <td>0.025578</td>\n","      <td>6.428040</td>\n","      <td>1.229900</td>\n","      <td>5910.131090</td>\n","      <td>21.1860</td>\n","      <td>154.960884</td>\n","      <td>NaN</td>\n","      <td>1144.743005</td>\n","      <td>257.432377</td>\n","      <td>14.007084</td>\n","      <td>0.669528</td>\n","      <td>137.867920</td>\n","      <td>2.721695</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.944475</td>\n","      <td>34.552683</td>\n","      <td>1.037196</td>\n","      <td>36.179552</td>\n","      <td>35.39336</td>\n","      <td>554.867285</td>\n","      <td>0.238680</td>\n","      <td>0.276033</td>\n","      <td>125.378265</td>\n","      <td>99.68664</td>\n","      <td>27.296000</td>\n","      <td>0.834537</td>\n","      <td>1.74307</td>\n","      <td>46.096904</td>\n","      <td>9.442848</td>\n","      <td>2.793483</td>\n","      <td>1611.404325</td>\n","      <td>0.097344</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>10.274856</td>\n","      <td>44.673552</td>\n","      <td>1.525809</td>\n","      <td>3060.890652</td>\n","      <td>6.769964</td>\n","      <td>4.192794</td>\n","      <td>0.78474</td>\n","      <td>0.209963</td>\n","      <td>18.557490</td>\n","      <td>118.296094</td>\n","      <td>952.591590</td>\n","      <td>29.634044</td>\n","      <td>19.863556</td>\n","      <td>0.078545</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>1899e6e0d7d9</td>\n","      <td>0.512760</td>\n","      <td>3756.02392</td>\n","      <td>85.200147</td>\n","      <td>25.674130</td>\n","      <td>8.138688</td>\n","      <td>7.973100</td>\n","      <td>0.025578</td>\n","      <td>7.310320</td>\n","      <td>1.229900</td>\n","      <td>6323.086250</td>\n","      <td>18.0081</td>\n","      <td>143.854704</td>\n","      <td>NaN</td>\n","      <td>910.350304</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.924166</td>\n","      <td>87.984944</td>\n","      <td>20.713772</td>\n","      <td>0.026666</td>\n","      <td>1.050225</td>\n","      <td>0.921150</td>\n","      <td>39.096244</td>\n","      <td>3.210894</td>\n","      <td>7.030640</td>\n","      <td>22.03840</td>\n","      <td>740.605085</td>\n","      <td>0.890838</td>\n","      <td>0.445479</td>\n","      <td>131.646990</td>\n","      <td>84.63676</td>\n","      <td>26.477120</td>\n","      <td>1.069035</td>\n","      <td>1.74307</td>\n","      <td>22.549840</td>\n","      <td>4.926396</td>\n","      <td>3.196583</td>\n","      <td>1692.073050</td>\n","      <td>0.200772</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>79.815359</td>\n","      <td>10.836960</td>\n","      <td>51.282336</td>\n","      <td>3.271287</td>\n","      <td>5845.233492</td>\n","      <td>9.829679</td>\n","      <td>4.932888</td>\n","      <td>0.86014</td>\n","      <td>0.711165</td>\n","      <td>12.036788</td>\n","      <td>72.611063</td>\n","      <td>2418.052176</td>\n","      <td>43.892916</td>\n","      <td>33.003904</td>\n","      <td>0.126465</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>1a6d2336590f</td>\n","      <td>0.602493</td>\n","      <td>5557.12344</td>\n","      <td>100.797966</td>\n","      <td>46.904065</td>\n","      <td>8.138688</td>\n","      <td>5.767209</td>\n","      <td>0.025578</td>\n","      <td>12.389732</td>\n","      <td>9.347240</td>\n","      <td>7900.152450</td>\n","      <td>18.7143</td>\n","      <td>136.741662</td>\n","      <td>NaN</td>\n","      <td>974.971771</td>\n","      <td>257.432377</td>\n","      <td>12.646816</td>\n","      <td>0.629668</td>\n","      <td>83.759320</td>\n","      <td>18.995607</td>\n","      <td>0.027064</td>\n","      <td>1.304825</td>\n","      <td>0.673875</td>\n","      <td>38.946303</td>\n","      <td>1.837161</td>\n","      <td>7.030640</td>\n","      <td>48.38748</td>\n","      <td>379.117105</td>\n","      <td>0.632502</td>\n","      <td>0.519270</td>\n","      <td>158.856645</td>\n","      <td>94.98448</td>\n","      <td>13.668472</td>\n","      <td>0.524172</td>\n","      <td>1.74307</td>\n","      <td>47.610708</td>\n","      <td>6.149160</td>\n","      <td>5.155649</td>\n","      <td>1212.940950</td>\n","      <td>0.048672</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>81.307668</td>\n","      <td>8.391048</td>\n","      <td>42.354480</td>\n","      <td>4.316199</td>\n","      <td>5136.721022</td>\n","      <td>9.625698</td>\n","      <td>18.799615</td>\n","      <td>0.49706</td>\n","      <td>0.237055</td>\n","      <td>26.733948</td>\n","      <td>103.216456</td>\n","      <td>642.540600</td>\n","      <td>32.149440</td>\n","      <td>39.436476</td>\n","      <td>0.062526</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>228524bde6a3</td>\n","      <td>0.346113</td>\n","      <td>4088.28992</td>\n","      <td>85.200147</td>\n","      <td>44.401689</td>\n","      <td>8.138688</td>\n","      <td>4.526949</td>\n","      <td>0.025578</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>5677.414350</td>\n","      <td>20.8329</td>\n","      <td>446.659191</td>\n","      <td>87.791105</td>\n","      <td>790.961191</td>\n","      <td>257.432377</td>\n","      <td>34.484632</td>\n","      <td>0.708965</td>\n","      <td>70.884248</td>\n","      <td>4.268044</td>\n","      <td>0.025870</td>\n","      <td>1.050225</td>\n","      <td>0.634725</td>\n","      <td>49.860613</td>\n","      <td>1.164087</td>\n","      <td>42.802632</td>\n","      <td>44.87996</td>\n","      <td>278.615570</td>\n","      <td>0.238680</td>\n","      <td>0.174912</td>\n","      <td>126.163268</td>\n","      <td>50.68072</td>\n","      <td>20.806376</td>\n","      <td>17.083869</td>\n","      <td>1.74307</td>\n","      <td>64.707260</td>\n","      <td>9.403974</td>\n","      <td>0.286201</td>\n","      <td>1091.675775</td>\n","      <td>0.723996</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>20.942172</td>\n","      <td>98.086464</td>\n","      <td>12.301464</td>\n","      <td>3740.069231</td>\n","      <td>14.559833</td>\n","      <td>20.563808</td>\n","      <td>0.78909</td>\n","      <td>0.074503</td>\n","      <td>42.454328</td>\n","      <td>81.681372</td>\n","      <td>2307.938913</td>\n","      <td>35.077867</td>\n","      <td>33.731780</td>\n","      <td>0.028537</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>2e4e80b95e24</td>\n","      <td>0.170920</td>\n","      <td>1963.64850</td>\n","      <td>85.200147</td>\n","      <td>22.574033</td>\n","      <td>8.138688</td>\n","      <td>2.595687</td>\n","      <td>0.029232</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>7958.583320</td>\n","      <td>20.1267</td>\n","      <td>337.068324</td>\n","      <td>71.384815</td>\n","      <td>366.357685</td>\n","      <td>257.432377</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>60.783976</td>\n","      <td>20.943367</td>\n","      <td>0.031442</td>\n","      <td>1.050225</td>\n","      <td>0.841800</td>\n","      <td>36.679753</td>\n","      <td>1.655100</td>\n","      <td>37.531400</td>\n","      <td>32.63856</td>\n","      <td>162.458485</td>\n","      <td>0.238680</td>\n","      <td>0.385353</td>\n","      <td>157.260285</td>\n","      <td>128.93628</td>\n","      <td>18.847888</td>\n","      <td>0.005518</td>\n","      <td>1.74307</td>\n","      <td>29.166556</td>\n","      <td>9.032904</td>\n","      <td>3.321544</td>\n","      <td>1895.308350</td>\n","      <td>0.003042</td>\n","      <td>A</td>\n","      <td>109.125159</td>\n","      <td>78.526968</td>\n","      <td>61.244016</td>\n","      <td>22.379616</td>\n","      <td>0.296850</td>\n","      <td>6342.797968</td>\n","      <td>12.007314</td>\n","      <td>0.173229</td>\n","      <td>1.09620</td>\n","      <td>0.067730</td>\n","      <td>25.636312</td>\n","      <td>198.146620</td>\n","      <td>6926.005926</td>\n","      <td>25.287916</td>\n","      <td>73.265992</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>2fd659800f75</td>\n","      <td>0.405935</td>\n","      <td>1011.87218</td>\n","      <td>91.122267</td>\n","      <td>69.840447</td>\n","      <td>8.138688</td>\n","      <td>6.573378</td>\n","      <td>0.025578</td>\n","      <td>7.398548</td>\n","      <td>1.229900</td>\n","      <td>3204.013970</td>\n","      <td>18.0081</td>\n","      <td>186.299811</td>\n","      <td>NaN</td>\n","      <td>1520.766992</td>\n","      <td>257.432377</td>\n","      <td>14.650454</td>\n","      <td>0.707478</td>\n","      <td>385.388008</td>\n","      <td>30.986269</td>\n","      <td>0.029850</td>\n","      <td>1.050225</td>\n","      <td>1.360200</td>\n","      <td>13.784111</td>\n","      <td>1.826127</td>\n","      <td>36.216168</td>\n","      <td>39.31992</td>\n","      <td>332.766920</td>\n","      <td>0.238680</td>\n","      <td>0.374421</td>\n","      <td>115.190175</td>\n","      <td>98.16872</td>\n","      <td>22.580616</td>\n","      <td>0.289674</td>\n","      <td>1.74307</td>\n","      <td>23.556048</td>\n","      <td>6.824154</td>\n","      <td>3.236893</td>\n","      <td>1035.950550</td>\n","      <td>0.060840</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>7.160496</td>\n","      <td>35.305872</td>\n","      <td>1.674234</td>\n","      <td>2842.486602</td>\n","      <td>9.504412</td>\n","      <td>4.336821</td>\n","      <td>1.59732</td>\n","      <td>0.392834</td>\n","      <td>14.725066</td>\n","      <td>72.611063</td>\n","      <td>13055.309620</td>\n","      <td>31.795945</td>\n","      <td>29.781188</td>\n","      <td>0.141429</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>321f58c2e5d1</td>\n","      <td>0.499941</td>\n","      <td>4402.36962</td>\n","      <td>149.925435</td>\n","      <td>24.107048</td>\n","      <td>8.138688</td>\n","      <td>6.046267</td>\n","      <td>0.025578</td>\n","      <td>10.297468</td>\n","      <td>1.229900</td>\n","      <td>3237.763730</td>\n","      <td>20.1267</td>\n","      <td>195.625611</td>\n","      <td>NaN</td>\n","      <td>1623.705850</td>\n","      <td>257.432377</td>\n","      <td>19.301100</td>\n","      <td>0.715342</td>\n","      <td>68.307648</td>\n","      <td>9.585232</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.537150</td>\n","      <td>19.516739</td>\n","      <td>0.982026</td>\n","      <td>37.575192</td>\n","      <td>38.00072</td>\n","      <td>1030.960100</td>\n","      <td>0.238680</td>\n","      <td>0.440013</td>\n","      <td>125.847008</td>\n","      <td>99.13544</td>\n","      <td>22.280360</td>\n","      <td>0.434511</td>\n","      <td>1.74307</td>\n","      <td>62.494950</td>\n","      <td>4.926396</td>\n","      <td>8.424790</td>\n","      <td>1268.379988</td>\n","      <td>0.066924</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>21.620748</td>\n","      <td>44.702112</td>\n","      <td>1.128030</td>\n","      <td>8145.464198</td>\n","      <td>7.935963</td>\n","      <td>3.253336</td>\n","      <td>0.49706</td>\n","      <td>0.338650</td>\n","      <td>15.180864</td>\n","      <td>208.879930</td>\n","      <td>272.340549</td>\n","      <td>48.968360</td>\n","      <td>23.073412</td>\n","      <td>0.103714</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>332a3850302f</td>\n","      <td>0.529852</td>\n","      <td>3287.77933</td>\n","      <td>85.200147</td>\n","      <td>22.632876</td>\n","      <td>8.138688</td>\n","      <td>8.726115</td>\n","      <td>0.025578</td>\n","      <td>15.238236</td>\n","      <td>1.229900</td>\n","      <td>3956.416290</td>\n","      <td>19.0674</td>\n","      <td>203.118043</td>\n","      <td>NaN</td>\n","      <td>846.826731</td>\n","      <td>257.432377</td>\n","      <td>32.981904</td>\n","      <td>0.952232</td>\n","      <td>126.475384</td>\n","      <td>8.484390</td>\n","      <td>0.026666</td>\n","      <td>1.050225</td>\n","      <td>0.620625</td>\n","      <td>37.532325</td>\n","      <td>2.124045</td>\n","      <td>36.686472</td>\n","      <td>57.00302</td>\n","      <td>507.896200</td>\n","      <td>0.238680</td>\n","      <td>0.478275</td>\n","      <td>130.468545</td>\n","      <td>125.68632</td>\n","      <td>23.222072</td>\n","      <td>0.800052</td>\n","      <td>1.74307</td>\n","      <td>79.279308</td>\n","      <td>10.665612</td>\n","      <td>3.315498</td>\n","      <td>1849.937088</td>\n","      <td>0.182520</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>116.891359</td>\n","      <td>12.637212</td>\n","      <td>43.354080</td>\n","      <td>3.449397</td>\n","      <td>3613.990019</td>\n","      <td>9.973017</td>\n","      <td>4.949731</td>\n","      <td>0.49706</td>\n","      <td>0.501202</td>\n","      <td>38.645159</td>\n","      <td>117.233806</td>\n","      <td>1577.712735</td>\n","      <td>32.223860</td>\n","      <td>40.028036</td>\n","      <td>0.153621</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>3d4109150b32</td>\n","      <td>0.564036</td>\n","      <td>4535.53254</td>\n","      <td>95.424513</td>\n","      <td>42.016999</td>\n","      <td>8.138688</td>\n","      <td>5.253387</td>\n","      <td>0.038367</td>\n","      <td>7.953124</td>\n","      <td>1.229900</td>\n","      <td>5120.543310</td>\n","      <td>20.4798</td>\n","      <td>177.999849</td>\n","      <td>NaN</td>\n","      <td>1002.984690</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.853483</td>\n","      <td>76.013664</td>\n","      <td>9.077385</td>\n","      <td>0.029850</td>\n","      <td>1.050225</td>\n","      <td>0.616275</td>\n","      <td>34.594527</td>\n","      <td>1.368216</td>\n","      <td>36.122328</td>\n","      <td>44.28632</td>\n","      <td>258.489540</td>\n","      <td>0.238680</td>\n","      <td>0.303363</td>\n","      <td>156.349155</td>\n","      <td>88.92976</td>\n","      <td>13.047488</td>\n","      <td>0.262086</td>\n","      <td>1.74307</td>\n","      <td>38.487456</td>\n","      <td>8.580552</td>\n","      <td>2.914413</td>\n","      <td>16845.249300</td>\n","      <td>0.030420</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>106.528617</td>\n","      <td>45.707664</td>\n","      <td>130.867632</td>\n","      <td>1.110219</td>\n","      <td>6157.759020</td>\n","      <td>11.218955</td>\n","      <td>5.470930</td>\n","      <td>1.56078</td>\n","      <td>1.178502</td>\n","      <td>25.217722</td>\n","      <td>72.611063</td>\n","      <td>410.058126</td>\n","      <td>30.575457</td>\n","      <td>27.944780</td>\n","      <td>0.078158</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>166</th>\n","      <td>41475fa34ab3</td>\n","      <td>0.269199</td>\n","      <td>2045.32350</td>\n","      <td>93.473697</td>\n","      <td>23.143881</td>\n","      <td>8.138688</td>\n","      <td>9.009603</td>\n","      <td>0.025578</td>\n","      <td>10.971782</td>\n","      <td>1.229900</td>\n","      <td>4136.207270</td>\n","      <td>20.4798</td>\n","      <td>148.424346</td>\n","      <td>NaN</td>\n","      <td>333.538836</td>\n","      <td>257.432377</td>\n","      <td>60.908757</td>\n","      <td>0.781478</td>\n","      <td>52.190024</td>\n","      <td>13.140161</td>\n","      <td>0.027462</td>\n","      <td>1.050225</td>\n","      <td>0.470288</td>\n","      <td>18.543866</td>\n","      <td>1.164087</td>\n","      <td>41.793760</td>\n","      <td>42.00294</td>\n","      <td>220.707775</td>\n","      <td>0.238680</td>\n","      <td>0.251436</td>\n","      <td>119.952900</td>\n","      <td>100.42652</td>\n","      <td>22.846752</td>\n","      <td>0.689700</td>\n","      <td>1.74307</td>\n","      <td>18.727148</td>\n","      <td>4.926396</td>\n","      <td>1.467284</td>\n","      <td>2135.901663</td>\n","      <td>0.054756</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>13.305660</td>\n","      <td>45.593184</td>\n","      <td>0.902424</td>\n","      <td>3455.444025</td>\n","      <td>7.908398</td>\n","      <td>4.007733</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>15.673870</td>\n","      <td>229.023659</td>\n","      <td>2850.852915</td>\n","      <td>32.934571</td>\n","      <td>28.299716</td>\n","      <td>0.053460</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>177</th>\n","      <td>4537a9a3ecde</td>\n","      <td>0.452938</td>\n","      <td>2379.68401</td>\n","      <td>92.472162</td>\n","      <td>41.992223</td>\n","      <td>8.138688</td>\n","      <td>7.220085</td>\n","      <td>0.025578</td>\n","      <td>6.302000</td>\n","      <td>1.229900</td>\n","      <td>2211.528130</td>\n","      <td>19.7736</td>\n","      <td>105.559578</td>\n","      <td>NaN</td>\n","      <td>3466.745415</td>\n","      <td>257.432377</td>\n","      <td>20.165054</td>\n","      <td>0.558321</td>\n","      <td>96.237992</td>\n","      <td>10.500573</td>\n","      <td>0.033034</td>\n","      <td>1.050225</td>\n","      <td>0.867975</td>\n","      <td>13.784111</td>\n","      <td>0.976509</td>\n","      <td>7.030640</td>\n","      <td>25.15016</td>\n","      <td>696.312740</td>\n","      <td>0.238680</td>\n","      <td>0.295164</td>\n","      <td>93.140452</td>\n","      <td>92.08008</td>\n","      <td>24.914424</td>\n","      <td>0.662112</td>\n","      <td>1.74307</td>\n","      <td>36.533436</td>\n","      <td>4.926396</td>\n","      <td>4.172085</td>\n","      <td>185.594100</td>\n","      <td>0.066924</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>14.483040</td>\n","      <td>19.592160</td>\n","      <td>0.789621</td>\n","      <td>3353.604481</td>\n","      <td>6.951893</td>\n","      <td>2.811204</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>11.599594</td>\n","      <td>72.611063</td>\n","      <td>762.097329</td>\n","      <td>52.670755</td>\n","      <td>10.840980</td>\n","      <td>0.068062</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>178</th>\n","      <td>4572189340c4</td>\n","      <td>0.397389</td>\n","      <td>2306.39794</td>\n","      <td>85.200147</td>\n","      <td>75.247809</td>\n","      <td>8.138688</td>\n","      <td>6.281031</td>\n","      <td>0.025578</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>3872.641140</td>\n","      <td>22.2453</td>\n","      <td>206.918307</td>\n","      <td>344.644105</td>\n","      <td>450.015355</td>\n","      <td>257.432377</td>\n","      <td>768.900678</td>\n","      <td>0.578083</td>\n","      <td>139.794424</td>\n","      <td>30.714100</td>\n","      <td>0.035024</td>\n","      <td>1.050225</td>\n","      <td>0.913275</td>\n","      <td>27.829747</td>\n","      <td>1.340631</td>\n","      <td>36.162256</td>\n","      <td>36.34396</td>\n","      <td>136.930625</td>\n","      <td>0.238680</td>\n","      <td>0.254169</td>\n","      <td>139.007565</td>\n","      <td>67.77852</td>\n","      <td>31.233448</td>\n","      <td>0.737979</td>\n","      <td>1.74307</td>\n","      <td>12.087972</td>\n","      <td>10.135512</td>\n","      <td>2.636274</td>\n","      <td>2023.472150</td>\n","      <td>0.279864</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>96.267834</td>\n","      <td>36.663360</td>\n","      <td>14.131488</td>\n","      <td>6.049803</td>\n","      <td>4688.721352</td>\n","      <td>10.215589</td>\n","      <td>5.437584</td>\n","      <td>1.51496</td>\n","      <td>0.067730</td>\n","      <td>10.185690</td>\n","      <td>78.459171</td>\n","      <td>10032.175780</td>\n","      <td>19.847814</td>\n","      <td>41.756420</td>\n","      <td>0.255364</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>196</th>\n","      <td>4bc8f3ea493a</td>\n","      <td>0.611039</td>\n","      <td>1614.33602</td>\n","      <td>92.419908</td>\n","      <td>35.751768</td>\n","      <td>8.138688</td>\n","      <td>6.679686</td>\n","      <td>0.025578</td>\n","      <td>8.129580</td>\n","      <td>28.287700</td>\n","      <td>7027.852190</td>\n","      <td>20.1267</td>\n","      <td>199.631466</td>\n","      <td>NaN</td>\n","      <td>1642.784396</td>\n","      <td>257.432377</td>\n","      <td>15.054858</td>\n","      <td>0.674647</td>\n","      <td>140.745784</td>\n","      <td>10.573557</td>\n","      <td>0.020298</td>\n","      <td>1.457585</td>\n","      <td>0.675300</td>\n","      <td>31.388230</td>\n","      <td>1.688202</td>\n","      <td>7.030640</td>\n","      <td>69.72166</td>\n","      <td>287.352520</td>\n","      <td>0.238680</td>\n","      <td>0.245970</td>\n","      <td>100.734458</td>\n","      <td>148.88972</td>\n","      <td>17.155536</td>\n","      <td>3.489882</td>\n","      <td>1.74307</td>\n","      <td>16.557512</td>\n","      <td>5.756886</td>\n","      <td>3.027281</td>\n","      <td>2355.305050</td>\n","      <td>0.894348</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>78.526968</td>\n","      <td>6.517368</td>\n","      <td>40.263888</td>\n","      <td>8.489910</td>\n","      <td>5401.684249</td>\n","      <td>12.271938</td>\n","      <td>5.192682</td>\n","      <td>2.51111</td>\n","      <td>0.711165</td>\n","      <td>27.636242</td>\n","      <td>120.939668</td>\n","      <td>5159.734425</td>\n","      <td>18.218016</td>\n","      <td>18.276632</td>\n","      <td>0.172565</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>231</th>\n","      <td>5d547eb551a9</td>\n","      <td>0.358932</td>\n","      <td>2975.21818</td>\n","      <td>132.881922</td>\n","      <td>23.335895</td>\n","      <td>8.364180</td>\n","      <td>7.760484</td>\n","      <td>0.067599</td>\n","      <td>11.526358</td>\n","      <td>3.767008</td>\n","      <td>8027.792700</td>\n","      <td>19.0674</td>\n","      <td>715.606785</td>\n","      <td>NaN</td>\n","      <td>747.940703</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.637967</td>\n","      <td>91.933088</td>\n","      <td>2.441923</td>\n","      <td>0.023482</td>\n","      <td>1.763105</td>\n","      <td>0.774075</td>\n","      <td>74.077828</td>\n","      <td>2.223351</td>\n","      <td>45.734856</td>\n","      <td>70.10384</td>\n","      <td>1590.643795</td>\n","      <td>0.656370</td>\n","      <td>0.418149</td>\n","      <td>100.427610</td>\n","      <td>87.41396</td>\n","      <td>28.824576</td>\n","      <td>3.462294</td>\n","      <td>1.74307</td>\n","      <td>34.592892</td>\n","      <td>8.969292</td>\n","      <td>6.373011</td>\n","      <td>1697.037650</td>\n","      <td>0.352872</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>125.011003</td>\n","      <td>15.541416</td>\n","      <td>54.326832</td>\n","      <td>6.584133</td>\n","      <td>5809.502814</td>\n","      <td>6.643165</td>\n","      <td>10.166071</td>\n","      <td>1.57412</td>\n","      <td>0.067730</td>\n","      <td>30.901244</td>\n","      <td>72.611063</td>\n","      <td>862.299108</td>\n","      <td>28.670305</td>\n","      <td>34.181880</td>\n","      <td>0.068629</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>5d8a1a0fb062</td>\n","      <td>0.341840</td>\n","      <td>5198.94892</td>\n","      <td>85.200147</td>\n","      <td>89.209085</td>\n","      <td>8.138688</td>\n","      <td>9.487989</td>\n","      <td>0.025578</td>\n","      <td>5.098318</td>\n","      <td>6.486844</td>\n","      <td>3306.142150</td>\n","      <td>18.3612</td>\n","      <td>156.597138</td>\n","      <td>NaN</td>\n","      <td>849.684883</td>\n","      <td>257.432377</td>\n","      <td>42.186690</td>\n","      <td>0.801463</td>\n","      <td>116.319616</td>\n","      <td>14.976925</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.647175</td>\n","      <td>31.491097</td>\n","      <td>0.926856</td>\n","      <td>7.030640</td>\n","      <td>37.13936</td>\n","      <td>571.303395</td>\n","      <td>0.238680</td>\n","      <td>0.235038</td>\n","      <td>101.549580</td>\n","      <td>80.39252</td>\n","      <td>19.775952</td>\n","      <td>2.034615</td>\n","      <td>1.74307</td>\n","      <td>8.606672</td>\n","      <td>4.926396</td>\n","      <td>5.425726</td>\n","      <td>1078.264125</td>\n","      <td>0.298116</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>90.808393</td>\n","      <td>4.486704</td>\n","      <td>64.791216</td>\n","      <td>5.378922</td>\n","      <td>1563.136688</td>\n","      <td>6.847146</td>\n","      <td>7.536000</td>\n","      <td>0.98194</td>\n","      <td>0.426699</td>\n","      <td>13.422786</td>\n","      <td>72.611063</td>\n","      <td>6844.557672</td>\n","      <td>21.124117</td>\n","      <td>17.026640</td>\n","      <td>0.098664</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>235</th>\n","      <td>5e27b0147126</td>\n","      <td>0.354659</td>\n","      <td>4825.98336</td>\n","      <td>132.350673</td>\n","      <td>14.741720</td>\n","      <td>8.138688</td>\n","      <td>4.225743</td>\n","      <td>0.025578</td>\n","      <td>9.944556</td>\n","      <td>1.229900</td>\n","      <td>4397.887760</td>\n","      <td>20.4798</td>\n","      <td>161.260038</td>\n","      <td>NaN</td>\n","      <td>946.214825</td>\n","      <td>257.432377</td>\n","      <td>21.626423</td>\n","      <td>0.567021</td>\n","      <td>48.947472</td>\n","      <td>1.783546</td>\n","      <td>0.023880</td>\n","      <td>1.228445</td>\n","      <td>0.720600</td>\n","      <td>13.784111</td>\n","      <td>1.186155</td>\n","      <td>7.030640</td>\n","      <td>42.38512</td>\n","      <td>390.306610</td>\n","      <td>0.238680</td>\n","      <td>0.420882</td>\n","      <td>108.876270</td>\n","      <td>91.17696</td>\n","      <td>12.221784</td>\n","      <td>1.082829</td>\n","      <td>1.74307</td>\n","      <td>49.861200</td>\n","      <td>10.637340</td>\n","      <td>4.567123</td>\n","      <td>1300.466125</td>\n","      <td>0.212940</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>122.044923</td>\n","      <td>7.449144</td>\n","      <td>50.431248</td>\n","      <td>2.903193</td>\n","      <td>4209.198136</td>\n","      <td>9.592620</td>\n","      <td>4.154209</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>41.914812</td>\n","      <td>126.767900</td>\n","      <td>407.989224</td>\n","      <td>21.261794</td>\n","      <td>34.495664</td>\n","      <td>0.132420</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>236</th>\n","      <td>5ee622a3e3be</td>\n","      <td>0.401662</td>\n","      <td>2667.06869</td>\n","      <td>85.200147</td>\n","      <td>21.369300</td>\n","      <td>8.138688</td>\n","      <td>5.900094</td>\n","      <td>0.025578</td>\n","      <td>9.367923</td>\n","      <td>1.229900</td>\n","      <td>2261.889100</td>\n","      <td>19.0674</td>\n","      <td>169.089471</td>\n","      <td>NaN</td>\n","      <td>684.770996</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.456729</td>\n","      <td>92.234352</td>\n","      <td>13.663213</td>\n","      <td>0.020298</td>\n","      <td>1.050225</td>\n","      <td>0.747975</td>\n","      <td>13.784111</td>\n","      <td>2.267487</td>\n","      <td>7.030640</td>\n","      <td>27.16194</td>\n","      <td>248.005200</td>\n","      <td>0.238680</td>\n","      <td>0.472809</td>\n","      <td>134.169540</td>\n","      <td>123.91188</td>\n","      <td>28.606208</td>\n","      <td>0.496584</td>\n","      <td>1.74307</td>\n","      <td>57.821024</td>\n","      <td>4.926396</td>\n","      <td>2.809607</td>\n","      <td>685.413037</td>\n","      <td>0.048672</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>42.730032</td>\n","      <td>23.476320</td>\n","      <td>0.884613</td>\n","      <td>3160.705233</td>\n","      <td>8.920034</td>\n","      <td>3.750250</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>22.989893</td>\n","      <td>258.259781</td>\n","      <td>13.038894</td>\n","      <td>55.000101</td>\n","      <td>66.347312</td>\n","      <td>0.066000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>244</th>\n","      <td>619aac34f423</td>\n","      <td>0.658042</td>\n","      <td>3283.64718</td>\n","      <td>85.200147</td>\n","      <td>56.331333</td>\n","      <td>8.526744</td>\n","      <td>6.068415</td>\n","      <td>0.025578</td>\n","      <td>9.872083</td>\n","      <td>1.229900</td>\n","      <td>5111.015235</td>\n","      <td>21.1860</td>\n","      <td>255.921147</td>\n","      <td>NaN</td>\n","      <td>528.398297</td>\n","      <td>257.432377</td>\n","      <td>14.581521</td>\n","      <td>0.612092</td>\n","      <td>128.235400</td>\n","      <td>19.383334</td>\n","      <td>0.039402</td>\n","      <td>1.050225</td>\n","      <td>1.348275</td>\n","      <td>29.571503</td>\n","      <td>1.875780</td>\n","      <td>35.728200</td>\n","      <td>26.80304</td>\n","      <td>444.732930</td>\n","      <td>0.238680</td>\n","      <td>0.554799</td>\n","      <td>152.902298</td>\n","      <td>113.72528</td>\n","      <td>34.379312</td>\n","      <td>0.800052</td>\n","      <td>1.74307</td>\n","      <td>47.278300</td>\n","      <td>8.326104</td>\n","      <td>2.966816</td>\n","      <td>2079.131100</td>\n","      <td>0.103428</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>45.553212</td>\n","      <td>37.784880</td>\n","      <td>1.199274</td>\n","      <td>4224.993596</td>\n","      <td>8.578228</td>\n","      <td>3.036891</td>\n","      <td>2.11816</td>\n","      <td>1.639066</td>\n","      <td>25.013078</td>\n","      <td>175.772307</td>\n","      <td>2112.316137</td>\n","      <td>54.702421</td>\n","      <td>42.713204</td>\n","      <td>0.087052</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>253</th>\n","      <td>65c5772a4afa</td>\n","      <td>0.307656</td>\n","      <td>4054.55754</td>\n","      <td>129.145761</td>\n","      <td>56.408758</td>\n","      <td>8.138688</td>\n","      <td>4.934463</td>\n","      <td>0.025578</td>\n","      <td>6.642308</td>\n","      <td>1.229900</td>\n","      <td>6417.591970</td>\n","      <td>18.3612</td>\n","      <td>168.864804</td>\n","      <td>NaN</td>\n","      <td>1185.960891</td>\n","      <td>257.432377</td>\n","      <td>32.003062</td>\n","      <td>0.642823</td>\n","      <td>100.122712</td>\n","      <td>6.034865</td>\n","      <td>0.030646</td>\n","      <td>1.050225</td>\n","      <td>1.259100</td>\n","      <td>29.175729</td>\n","      <td>1.020645</td>\n","      <td>37.820464</td>\n","      <td>54.74292</td>\n","      <td>369.688295</td>\n","      <td>0.238680</td>\n","      <td>0.265101</td>\n","      <td>150.765660</td>\n","      <td>66.73972</td>\n","      <td>29.506976</td>\n","      <td>0.531069</td>\n","      <td>1.74307</td>\n","      <td>27.239488</td>\n","      <td>8.743116</td>\n","      <td>2.781390</td>\n","      <td>2298.356750</td>\n","      <td>0.121680</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>86.924682</td>\n","      <td>6.380640</td>\n","      <td>22.688064</td>\n","      <td>2.167005</td>\n","      <td>2036.483954</td>\n","      <td>9.416204</td>\n","      <td>3.800196</td>\n","      <td>1.05328</td>\n","      <td>0.494429</td>\n","      <td>19.041194</td>\n","      <td>72.611063</td>\n","      <td>3494.694780</td>\n","      <td>36.417427</td>\n","      <td>28.006508</td>\n","      <td>0.154286</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>263</th>\n","      <td>684d62aeae9e</td>\n","      <td>0.282018</td>\n","      <td>4374.06530</td>\n","      <td>116.326113</td>\n","      <td>46.993878</td>\n","      <td>8.138688</td>\n","      <td>7.104918</td>\n","      <td>0.057246</td>\n","      <td>8.602230</td>\n","      <td>1.229900</td>\n","      <td>3577.442600</td>\n","      <td>18.7143</td>\n","      <td>130.141539</td>\n","      <td>NaN</td>\n","      <td>682.599405</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.863973</td>\n","      <td>109.231984</td>\n","      <td>0.510888</td>\n","      <td>0.029054</td>\n","      <td>1.132970</td>\n","      <td>0.812325</td>\n","      <td>37.126089</td>\n","      <td>3.503295</td>\n","      <td>7.030640</td>\n","      <td>49.43508</td>\n","      <td>291.752040</td>\n","      <td>0.238680</td>\n","      <td>0.308829</td>\n","      <td>142.102395</td>\n","      <td>102.64828</td>\n","      <td>13.368216</td>\n","      <td>0.337953</td>\n","      <td>1.74307</td>\n","      <td>28.416392</td>\n","      <td>11.549112</td>\n","      <td>1.039998</td>\n","      <td>1432.479900</td>\n","      <td>0.085176</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>147.071223</td>\n","      <td>58.458816</td>\n","      <td>73.005072</td>\n","      <td>3.900609</td>\n","      <td>12440.489320</td>\n","      <td>8.594767</td>\n","      <td>7.795305</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>27.589732</td>\n","      <td>72.611063</td>\n","      <td>7069.258800</td>\n","      <td>34.315062</td>\n","      <td>34.930332</td>\n","      <td>0.169714</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>264</th>\n","      <td>6850ef5b0092</td>\n","      <td>0.461484</td>\n","      <td>2184.24239</td>\n","      <td>128.170353</td>\n","      <td>12.790610</td>\n","      <td>8.138688</td>\n","      <td>7.671894</td>\n","      <td>0.031973</td>\n","      <td>6.755744</td>\n","      <td>2.540622</td>\n","      <td>4180.511820</td>\n","      <td>20.8329</td>\n","      <td>166.050108</td>\n","      <td>NaN</td>\n","      <td>1043.918273</td>\n","      <td>743.648493</td>\n","      <td>43.602104</td>\n","      <td>0.471727</td>\n","      <td>69.068736</td>\n","      <td>32.900579</td>\n","      <td>0.029850</td>\n","      <td>1.050225</td>\n","      <td>0.538613</td>\n","      <td>29.384949</td>\n","      <td>1.649583</td>\n","      <td>7.030640</td>\n","      <td>64.03552</td>\n","      <td>162.023855</td>\n","      <td>0.238680</td>\n","      <td>0.587595</td>\n","      <td>72.641910</td>\n","      <td>115.42552</td>\n","      <td>24.743824</td>\n","      <td>0.744876</td>\n","      <td>1.74307</td>\n","      <td>34.476100</td>\n","      <td>6.643920</td>\n","      <td>1.636586</td>\n","      <td>1306.054313</td>\n","      <td>0.109512</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>4.382892</td>\n","      <td>96.435696</td>\n","      <td>3.841239</td>\n","      <td>4661.397452</td>\n","      <td>8.542393</td>\n","      <td>8.864238</td>\n","      <td>1.24352</td>\n","      <td>0.182871</td>\n","      <td>27.087424</td>\n","      <td>215.072564</td>\n","      <td>2368.894977</td>\n","      <td>36.052769</td>\n","      <td>5.546518</td>\n","      <td>0.099000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>266</th>\n","      <td>6860e7cbccad</td>\n","      <td>0.499941</td>\n","      <td>4714.33666</td>\n","      <td>103.454211</td>\n","      <td>17.882078</td>\n","      <td>8.138688</td>\n","      <td>11.250930</td>\n","      <td>0.025578</td>\n","      <td>14.513506</td>\n","      <td>1.229900</td>\n","      <td>7849.080370</td>\n","      <td>19.7736</td>\n","      <td>154.820997</td>\n","      <td>NaN</td>\n","      <td>2796.473872</td>\n","      <td>257.432377</td>\n","      <td>14.774532</td>\n","      <td>1.538831</td>\n","      <td>89.911448</td>\n","      <td>14.937392</td>\n","      <td>0.032636</td>\n","      <td>1.225262</td>\n","      <td>0.627075</td>\n","      <td>44.087885</td>\n","      <td>1.616481</td>\n","      <td>7.030640</td>\n","      <td>45.04874</td>\n","      <td>217.008985</td>\n","      <td>0.866619</td>\n","      <td>0.459144</td>\n","      <td>169.489005</td>\n","      <td>145.55708</td>\n","      <td>26.238280</td>\n","      <td>0.372438</td>\n","      <td>1.74307</td>\n","      <td>44.659464</td>\n","      <td>7.767732</td>\n","      <td>4.694100</td>\n","      <td>921.550862</td>\n","      <td>0.060840</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>31.558848</td>\n","      <td>44.713536</td>\n","      <td>1.175526</td>\n","      <td>5446.749969</td>\n","      <td>9.950965</td>\n","      <td>3.452708</td>\n","      <td>0.49706</td>\n","      <td>0.582478</td>\n","      <td>22.264337</td>\n","      <td>268.959964</td>\n","      <td>13.038894</td>\n","      <td>39.710512</td>\n","      <td>70.796872</td>\n","      <td>0.110000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>272</th>\n","      <td>69de76778344</td>\n","      <td>0.572582</td>\n","      <td>4098.12238</td>\n","      <td>139.283037</td>\n","      <td>9.414880</td>\n","      <td>8.138688</td>\n","      <td>4.881309</td>\n","      <td>0.025578</td>\n","      <td>10.833138</td>\n","      <td>1.229900</td>\n","      <td>5208.481250</td>\n","      <td>20.8329</td>\n","      <td>160.047684</td>\n","      <td>NaN</td>\n","      <td>1108.993415</td>\n","      <td>257.432377</td>\n","      <td>13.336141</td>\n","      <td>0.736025</td>\n","      <td>118.904144</td>\n","      <td>1.540266</td>\n","      <td>0.021094</td>\n","      <td>1.432125</td>\n","      <td>0.725850</td>\n","      <td>37.457354</td>\n","      <td>1.815093</td>\n","      <td>7.030640</td>\n","      <td>54.51012</td>\n","      <td>729.539760</td>\n","      <td>0.238680</td>\n","      <td>0.429081</td>\n","      <td>136.586670</td>\n","      <td>88.92764</td>\n","      <td>17.271544</td>\n","      <td>0.786258</td>\n","      <td>1.74307</td>\n","      <td>24.211880</td>\n","      <td>7.513284</td>\n","      <td>3.176428</td>\n","      <td>1051.248025</td>\n","      <td>0.176436</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>3.828384</td>\n","      <td>88.827312</td>\n","      <td>6.103236</td>\n","      <td>4229.155812</td>\n","      <td>10.733811</td>\n","      <td>8.981426</td>\n","      <td>1.03472</td>\n","      <td>0.284466</td>\n","      <td>29.673380</td>\n","      <td>126.405706</td>\n","      <td>2425.619196</td>\n","      <td>32.212697</td>\n","      <td>52.944620</td>\n","      <td>0.151105</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>279</th>\n","      <td>6c6db7987cd5</td>\n","      <td>0.354659</td>\n","      <td>1821.33072</td>\n","      <td>114.183699</td>\n","      <td>108.692312</td>\n","      <td>8.138688</td>\n","      <td>4.296615</td>\n","      <td>0.025578</td>\n","      <td>7.486776</td>\n","      <td>1.229900</td>\n","      <td>4556.401370</td>\n","      <td>19.4205</td>\n","      <td>130.251753</td>\n","      <td>NaN</td>\n","      <td>730.652661</td>\n","      <td>257.432377</td>\n","      <td>16.672474</td>\n","      <td>0.583065</td>\n","      <td>275.759624</td>\n","      <td>2.055716</td>\n","      <td>0.024278</td>\n","      <td>1.514870</td>\n","      <td>0.862200</td>\n","      <td>35.961431</td>\n","      <td>1.445454</td>\n","      <td>36.476528</td>\n","      <td>28.30848</td>\n","      <td>134.553465</td>\n","      <td>0.238680</td>\n","      <td>0.418149</td>\n","      <td>189.582810</td>\n","      <td>91.72180</td>\n","      <td>23.979536</td>\n","      <td>0.296571</td>\n","      <td>1.74307</td>\n","      <td>30.752232</td>\n","      <td>9.075312</td>\n","      <td>3.853636</td>\n","      <td>1386.894750</td>\n","      <td>0.048672</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>104.563589</td>\n","      <td>48.067488</td>\n","      <td>37.356480</td>\n","      <td>0.374031</td>\n","      <td>5073.352032</td>\n","      <td>11.307163</td>\n","      <td>1.225413</td>\n","      <td>1.00398</td>\n","      <td>0.067730</td>\n","      <td>17.831934</td>\n","      <td>103.918759</td>\n","      <td>23672.744100</td>\n","      <td>26.586545</td>\n","      <td>51.882384</td>\n","      <td>0.110512</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>281</th>\n","      <td>6ef1fe86ad00</td>\n","      <td>0.585401</td>\n","      <td>2487.50590</td>\n","      <td>113.121201</td>\n","      <td>149.318758</td>\n","      <td>8.138688</td>\n","      <td>8.017395</td>\n","      <td>0.055419</td>\n","      <td>6.295698</td>\n","      <td>1.229900</td>\n","      <td>5102.046460</td>\n","      <td>20.4798</td>\n","      <td>145.639323</td>\n","      <td>NaN</td>\n","      <td>2128.364846</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.587263</td>\n","      <td>87.699536</td>\n","      <td>13.752923</td>\n","      <td>0.032238</td>\n","      <td>1.050225</td>\n","      <td>0.753150</td>\n","      <td>38.451149</td>\n","      <td>1.279944</td>\n","      <td>7.030640</td>\n","      <td>45.19424</td>\n","      <td>257.039295</td>\n","      <td>0.238680</td>\n","      <td>0.467343</td>\n","      <td>144.203265</td>\n","      <td>97.14900</td>\n","      <td>23.556448</td>\n","      <td>1.655280</td>\n","      <td>1.74307</td>\n","      <td>35.221772</td>\n","      <td>7.675848</td>\n","      <td>3.382009</td>\n","      <td>1723.595850</td>\n","      <td>0.304200</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>110.560632</td>\n","      <td>38.344608</td>\n","      <td>43.691088</td>\n","      <td>4.791159</td>\n","      <td>5781.445286</td>\n","      <td>9.829679</td>\n","      <td>5.933445</td>\n","      <td>1.29804</td>\n","      <td>0.555386</td>\n","      <td>37.319624</td>\n","      <td>72.611063</td>\n","      <td>3586.155120</td>\n","      <td>40.666809</td>\n","      <td>35.509032</td>\n","      <td>0.123750</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>283</th>\n","      <td>7017fab77607</td>\n","      <td>0.235015</td>\n","      <td>3572.32172</td>\n","      <td>85.200147</td>\n","      <td>32.258352</td>\n","      <td>8.138688</td>\n","      <td>4.704129</td>\n","      <td>0.073385</td>\n","      <td>6.232678</td>\n","      <td>1.229900</td>\n","      <td>5828.585150</td>\n","      <td>18.0081</td>\n","      <td>115.644159</td>\n","      <td>NaN</td>\n","      <td>587.566590</td>\n","      <td>1387.831083</td>\n","      <td>12.499760</td>\n","      <td>0.691389</td>\n","      <td>99.615320</td>\n","      <td>16.117300</td>\n","      <td>0.028258</td>\n","      <td>1.050225</td>\n","      <td>0.730875</td>\n","      <td>35.101886</td>\n","      <td>1.776474</td>\n","      <td>38.886560</td>\n","      <td>45.40764</td>\n","      <td>120.330420</td>\n","      <td>0.238680</td>\n","      <td>0.456411</td>\n","      <td>126.647070</td>\n","      <td>120.20188</td>\n","      <td>17.135064</td>\n","      <td>0.841434</td>\n","      <td>1.74307</td>\n","      <td>28.645484</td>\n","      <td>6.827688</td>\n","      <td>1.822012</td>\n","      <td>1301.005363</td>\n","      <td>0.225108</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>127.689744</td>\n","      <td>3.828384</td>\n","      <td>113.503152</td>\n","      <td>5.076135</td>\n","      <td>5016.031730</td>\n","      <td>9.973017</td>\n","      <td>6.056783</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>19.459784</td>\n","      <td>72.611063</td>\n","      <td>2742.701391</td>\n","      <td>31.129886</td>\n","      <td>32.178292</td>\n","      <td>0.180148</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>285</th>\n","      <td>70926a82d4e1</td>\n","      <td>0.282018</td>\n","      <td>2670.85115</td>\n","      <td>113.896302</td>\n","      <td>121.510795</td>\n","      <td>8.138688</td>\n","      <td>6.661968</td>\n","      <td>0.025578</td>\n","      <td>8.706213</td>\n","      <td>1.229900</td>\n","      <td>4367.541740</td>\n","      <td>21.1860</td>\n","      <td>177.853603</td>\n","      <td>NaN</td>\n","      <td>429.182599</td>\n","      <td>257.432377</td>\n","      <td>19.052943</td>\n","      <td>0.506868</td>\n","      <td>189.415776</td>\n","      <td>4.144883</td>\n","      <td>0.046566</td>\n","      <td>1.050225</td>\n","      <td>0.652050</td>\n","      <td>18.488074</td>\n","      <td>1.406835</td>\n","      <td>7.030640</td>\n","      <td>23.50310</td>\n","      <td>314.006870</td>\n","      <td>0.238680</td>\n","      <td>0.399018</td>\n","      <td>102.411765</td>\n","      <td>122.97484</td>\n","      <td>15.019624</td>\n","      <td>0.696597</td>\n","      <td>1.74307</td>\n","      <td>15.757936</td>\n","      <td>4.926396</td>\n","      <td>3.944333</td>\n","      <td>988.738650</td>\n","      <td>0.152100</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>12.771408</td>\n","      <td>27.406176</td>\n","      <td>3.811554</td>\n","      <td>4230.574409</td>\n","      <td>8.390786</td>\n","      <td>6.124258</td>\n","      <td>0.49706</td>\n","      <td>0.243828</td>\n","      <td>11.906560</td>\n","      <td>154.749595</td>\n","      <td>578.244987</td>\n","      <td>38.188623</td>\n","      <td>31.488996</td>\n","      <td>0.147030</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>289</th>\n","      <td>73468ffe1cb5</td>\n","      <td>0.196558</td>\n","      <td>3807.68971</td>\n","      <td>85.200147</td>\n","      <td>11.353602</td>\n","      <td>8.138688</td>\n","      <td>7.525721</td>\n","      <td>0.042630</td>\n","      <td>8.992954</td>\n","      <td>1.229900</td>\n","      <td>3643.559850</td>\n","      <td>18.3612</td>\n","      <td>125.440488</td>\n","      <td>NaN</td>\n","      <td>330.753271</td>\n","      <td>257.432377</td>\n","      <td>19.668740</td>\n","      <td>1.087353</td>\n","      <td>51.809480</td>\n","      <td>10.923272</td>\n","      <td>0.017114</td>\n","      <td>1.050225</td>\n","      <td>0.552937</td>\n","      <td>35.882973</td>\n","      <td>1.048230</td>\n","      <td>7.030640</td>\n","      <td>41.57614</td>\n","      <td>219.040215</td>\n","      <td>0.238680</td>\n","      <td>0.330693</td>\n","      <td>112.972590</td>\n","      <td>112.22008</td>\n","      <td>14.384992</td>\n","      <td>0.834537</td>\n","      <td>1.74307</td>\n","      <td>20.355498</td>\n","      <td>6.802950</td>\n","      <td>2.571778</td>\n","      <td>1621.074450</td>\n","      <td>0.146016</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>80.695914</td>\n","      <td>3.828384</td>\n","      <td>22.213968</td>\n","      <td>3.663129</td>\n","      <td>7925.319653</td>\n","      <td>7.781599</td>\n","      <td>6.710646</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>12.446076</td>\n","      <td>260.053084</td>\n","      <td>4316.090427</td>\n","      <td>39.677023</td>\n","      <td>13.694614</td>\n","      <td>0.117818</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>304</th>\n","      <td>79b44ed25c29</td>\n","      <td>0.948606</td>\n","      <td>6192.61907</td>\n","      <td>99.857394</td>\n","      <td>29.179934</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>7.404850</td>\n","      <td>7.920556</td>\n","      <td>5663.431850</td>\n","      <td>23.6577</td>\n","      <td>203.141358</td>\n","      <td>55.832965</td>\n","      <td>2083.027591</td>\n","      <td>738.131262</td>\n","      <td>19.135662</td>\n","      <td>0.280565</td>\n","      <td>100.550824</td>\n","      <td>4.188978</td>\n","      <td>0.038208</td>\n","      <td>1.521235</td>\n","      <td>0.445875</td>\n","      <td>31.876410</td>\n","      <td>1.605447</td>\n","      <td>38.942772</td>\n","      <td>24.13554</td>\n","      <td>66.014975</td>\n","      <td>0.378729</td>\n","      <td>0.196776</td>\n","      <td>178.688783</td>\n","      <td>93.19944</td>\n","      <td>34.986648</td>\n","      <td>0.779361</td>\n","      <td>1.74307</td>\n","      <td>17.190884</td>\n","      <td>11.163906</td>\n","      <td>1.334261</td>\n","      <td>3114.186938</td>\n","      <td>0.152100</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>102.751499</td>\n","      <td>11.280060</td>\n","      <td>41.880384</td>\n","      <td>2.950689</td>\n","      <td>13797.341800</td>\n","      <td>7.988337</td>\n","      <td>5.014797</td>\n","      <td>1.04371</td>\n","      <td>1.666158</td>\n","      <td>17.264512</td>\n","      <td>72.611063</td>\n","      <td>3595.331772</td>\n","      <td>35.583923</td>\n","      <td>36.584128</td>\n","      <td>0.131416</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>305</th>\n","      <td>7a5c4b008308</td>\n","      <td>0.414481</td>\n","      <td>2028.57468</td>\n","      <td>100.127373</td>\n","      <td>9.798908</td>\n","      <td>8.138688</td>\n","      <td>8.500210</td>\n","      <td>0.060595</td>\n","      <td>7.719950</td>\n","      <td>2.712808</td>\n","      <td>5748.972790</td>\n","      <td>17.6550</td>\n","      <td>160.018011</td>\n","      <td>NaN</td>\n","      <td>690.538717</td>\n","      <td>840.323779</td>\n","      <td>12.499760</td>\n","      <td>0.675740</td>\n","      <td>79.287928</td>\n","      <td>11.987622</td>\n","      <td>0.025870</td>\n","      <td>1.050225</td>\n","      <td>0.471000</td>\n","      <td>37.094706</td>\n","      <td>1.197189</td>\n","      <td>45.507248</td>\n","      <td>44.47450</td>\n","      <td>255.132245</td>\n","      <td>0.421551</td>\n","      <td>0.478275</td>\n","      <td>104.810070</td>\n","      <td>98.82592</td>\n","      <td>14.903616</td>\n","      <td>0.737979</td>\n","      <td>1.74307</td>\n","      <td>37.409376</td>\n","      <td>6.237510</td>\n","      <td>8.098279</td>\n","      <td>1817.609950</td>\n","      <td>0.121680</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>94.237923</td>\n","      <td>23.522280</td>\n","      <td>76.769280</td>\n","      <td>4.090593</td>\n","      <td>3376.320748</td>\n","      <td>8.426621</td>\n","      <td>8.456270</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>35.775492</td>\n","      <td>139.349725</td>\n","      <td>2605.661784</td>\n","      <td>34.143896</td>\n","      <td>11.847918</td>\n","      <td>0.111028</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>316</th>\n","      <td>7e4d70590a71</td>\n","      <td>0.623858</td>\n","      <td>4258.45706</td>\n","      <td>85.200147</td>\n","      <td>8.337124</td>\n","      <td>8.138688</td>\n","      <td>8.531217</td>\n","      <td>0.025578</td>\n","      <td>9.553832</td>\n","      <td>1.229900</td>\n","      <td>5667.322980</td>\n","      <td>19.4205</td>\n","      <td>146.894067</td>\n","      <td>NaN</td>\n","      <td>2026.372657</td>\n","      <td>257.432377</td>\n","      <td>32.287983</td>\n","      <td>1.002021</td>\n","      <td>65.009600</td>\n","      <td>21.144073</td>\n","      <td>0.031840</td>\n","      <td>1.050225</td>\n","      <td>0.669825</td>\n","      <td>36.432176</td>\n","      <td>1.997154</td>\n","      <td>7.030640</td>\n","      <td>53.64100</td>\n","      <td>312.760635</td>\n","      <td>0.238680</td>\n","      <td>0.538401</td>\n","      <td>121.598205</td>\n","      <td>74.61764</td>\n","      <td>34.795576</td>\n","      <td>0.344850</td>\n","      <td>1.74307</td>\n","      <td>33.389036</td>\n","      <td>9.400440</td>\n","      <td>7.445257</td>\n","      <td>2330.295275</td>\n","      <td>0.024336</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>7.702344</td>\n","      <td>71.851248</td>\n","      <td>1.151778</td>\n","      <td>6540.929930</td>\n","      <td>10.772402</td>\n","      <td>8.138127</td>\n","      <td>2.66336</td>\n","      <td>0.067730</td>\n","      <td>32.668624</td>\n","      <td>126.993167</td>\n","      <td>311.914314</td>\n","      <td>33.805285</td>\n","      <td>39.611372</td>\n","      <td>0.047520</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>330</th>\n","      <td>81015c6c3404</td>\n","      <td>6.161666</td>\n","      <td>18964.47278</td>\n","      <td>210.557493</td>\n","      <td>85.393581</td>\n","      <td>8.138688</td>\n","      <td>17.983770</td>\n","      <td>0.032886</td>\n","      <td>8.866914</td>\n","      <td>6.767964</td>\n","      <td>7259.050830</td>\n","      <td>19.0674</td>\n","      <td>1027.410669</td>\n","      <td>344.644105</td>\n","      <td>740.681903</td>\n","      <td>1510.069965</td>\n","      <td>536.221322</td>\n","      <td>NaN</td>\n","      <td>633.534408</td>\n","      <td>50.082229</td>\n","      <td>0.082386</td>\n","      <td>2.195925</td>\n","      <td>0.665475</td>\n","      <td>46.868767</td>\n","      <td>1.164087</td>\n","      <td>7.030640</td>\n","      <td>23.91632</td>\n","      <td>416.264665</td>\n","      <td>0.556686</td>\n","      <td>0.314295</td>\n","      <td>311.516100</td>\n","      <td>65.77300</td>\n","      <td>62.808096</td>\n","      <td>0.005518</td>\n","      <td>3.04325</td>\n","      <td>16.287992</td>\n","      <td>27.713628</td>\n","      <td>6.360918</td>\n","      <td>6845.912275</td>\n","      <td>0.003042</td>\n","      <td>A</td>\n","      <td>NaN</td>\n","      <td>110.708936</td>\n","      <td>132.899616</td>\n","      <td>NaN</td>\n","      <td>0.296850</td>\n","      <td>5676.738604</td>\n","      <td>12.768108</td>\n","      <td>0.173229</td>\n","      <td>54.94862</td>\n","      <td>NaN</td>\n","      <td>31.636102</td>\n","      <td>296.036174</td>\n","      <td>12261.844150</td>\n","      <td>49.586046</td>\n","      <td>39.457052</td>\n","      <td>21.978000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>341</th>\n","      <td>860833bfe713</td>\n","      <td>0.376024</td>\n","      <td>2967.65810</td>\n","      <td>85.200147</td>\n","      <td>34.262111</td>\n","      <td>8.138688</td>\n","      <td>5.643183</td>\n","      <td>0.025578</td>\n","      <td>9.200920</td>\n","      <td>1.229900</td>\n","      <td>3985.204260</td>\n","      <td>20.4798</td>\n","      <td>86.128002</td>\n","      <td>NaN</td>\n","      <td>672.152782</td>\n","      <td>257.432377</td>\n","      <td>25.312014</td>\n","      <td>0.651122</td>\n","      <td>55.543568</td>\n","      <td>19.165903</td>\n","      <td>0.039402</td>\n","      <td>1.050225</td>\n","      <td>0.571125</td>\n","      <td>29.426793</td>\n","      <td>1.026162</td>\n","      <td>7.030640</td>\n","      <td>45.34556</td>\n","      <td>263.447870</td>\n","      <td>0.238680</td>\n","      <td>0.336159</td>\n","      <td>115.882935</td>\n","      <td>63.08908</td>\n","      <td>22.375896</td>\n","      <td>1.655280</td>\n","      <td>1.74307</td>\n","      <td>19.117952</td>\n","      <td>4.926396</td>\n","      <td>1.168990</td>\n","      <td>1793.690700</td>\n","      <td>0.352872</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>89.325353</td>\n","      <td>4.927272</td>\n","      <td>26.098128</td>\n","      <td>3.312846</td>\n","      <td>4020.573394</td>\n","      <td>10.132894</td>\n","      <td>3.536792</td>\n","      <td>1.65184</td>\n","      <td>0.108368</td>\n","      <td>21.041124</td>\n","      <td>103.865755</td>\n","      <td>4255.175916</td>\n","      <td>36.796969</td>\n","      <td>69.122500</td>\n","      <td>0.143550</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>8b9d72eec14e</td>\n","      <td>4.277273</td>\n","      <td>7314.15234</td>\n","      <td>85.200147</td>\n","      <td>630.518230</td>\n","      <td>59.390922</td>\n","      <td>6.936597</td>\n","      <td>0.025578</td>\n","      <td>18.805168</td>\n","      <td>4.649022</td>\n","      <td>5287.366520</td>\n","      <td>29.3073</td>\n","      <td>173.328471</td>\n","      <td>NaN</td>\n","      <td>515.574417</td>\n","      <td>257.432377</td>\n","      <td>47.379605</td>\n","      <td>0.340140</td>\n","      <td>91.370200</td>\n","      <td>4.731796</td>\n","      <td>0.121788</td>\n","      <td>1.050225</td>\n","      <td>0.853425</td>\n","      <td>68.437606</td>\n","      <td>1.015128</td>\n","      <td>7.030640</td>\n","      <td>11.63806</td>\n","      <td>292.239890</td>\n","      <td>37.895013</td>\n","      <td>0.204975</td>\n","      <td>654.364530</td>\n","      <td>76.09104</td>\n","      <td>12.719936</td>\n","      <td>0.303468</td>\n","      <td>1.74307</td>\n","      <td>6.032756</td>\n","      <td>14.019378</td>\n","      <td>5.284641</td>\n","      <td>1233.916988</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>44.720247</td>\n","      <td>78.526968</td>\n","      <td>89.830296</td>\n","      <td>53.350080</td>\n","      <td>4.161837</td>\n","      <td>6862.199106</td>\n","      <td>7.326777</td>\n","      <td>110.342316</td>\n","      <td>0.87580</td>\n","      <td>0.975312</td>\n","      <td>36.231290</td>\n","      <td>93.993760</td>\n","      <td>14702.798590</td>\n","      <td>39.427716</td>\n","      <td>74.479976</td>\n","      <td>0.013500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>358</th>\n","      <td>8ba2487388f2</td>\n","      <td>0.568309</td>\n","      <td>3703.32116</td>\n","      <td>123.807144</td>\n","      <td>13.747583</td>\n","      <td>8.138688</td>\n","      <td>7.078341</td>\n","      <td>0.101703</td>\n","      <td>10.417206</td>\n","      <td>4.441696</td>\n","      <td>4647.798980</td>\n","      <td>19.4205</td>\n","      <td>192.671028</td>\n","      <td>NaN</td>\n","      <td>942.174093</td>\n","      <td>1215.877383</td>\n","      <td>12.499760</td>\n","      <td>0.760716</td>\n","      <td>26.820424</td>\n","      <td>1.651263</td>\n","      <td>0.032238</td>\n","      <td>1.050225</td>\n","      <td>0.808350</td>\n","      <td>45.324026</td>\n","      <td>1.119951</td>\n","      <td>7.030640</td>\n","      <td>46.88592</td>\n","      <td>137.711185</td>\n","      <td>0.791154</td>\n","      <td>0.407217</td>\n","      <td>113.672880</td>\n","      <td>84.01984</td>\n","      <td>23.147008</td>\n","      <td>0.937992</td>\n","      <td>1.74307</td>\n","      <td>37.674404</td>\n","      <td>14.086524</td>\n","      <td>2.555654</td>\n","      <td>1821.821425</td>\n","      <td>0.152100</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>159.667794</td>\n","      <td>52.630152</td>\n","      <td>137.270784</td>\n","      <td>3.502830</td>\n","      <td>5156.873334</td>\n","      <td>11.020487</td>\n","      <td>6.530993</td>\n","      <td>1.72260</td>\n","      <td>0.318331</td>\n","      <td>39.533500</td>\n","      <td>72.611063</td>\n","      <td>829.174806</td>\n","      <td>49.712560</td>\n","      <td>35.581048</td>\n","      <td>0.109191</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>8d7e1ef24fb8</td>\n","      <td>0.401662</td>\n","      <td>3863.57114</td>\n","      <td>135.546876</td>\n","      <td>9.340552</td>\n","      <td>8.138688</td>\n","      <td>5.377413</td>\n","      <td>0.025578</td>\n","      <td>10.807930</td>\n","      <td>3.745924</td>\n","      <td>3380.936540</td>\n","      <td>18.7143</td>\n","      <td>134.804439</td>\n","      <td>NaN</td>\n","      <td>1652.320644</td>\n","      <td>257.432377</td>\n","      <td>13.667017</td>\n","      <td>0.652089</td>\n","      <td>107.693952</td>\n","      <td>11.196962</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.717525</td>\n","      <td>30.507763</td>\n","      <td>1.015128</td>\n","      <td>7.030640</td>\n","      <td>60.75692</td>\n","      <td>228.371455</td>\n","      <td>0.238680</td>\n","      <td>0.374421</td>\n","      <td>150.328920</td>\n","      <td>100.68092</td>\n","      <td>14.794432</td>\n","      <td>0.931095</td>\n","      <td>1.74307</td>\n","      <td>22.114116</td>\n","      <td>10.503048</td>\n","      <td>11.101374</td>\n","      <td>1114.884075</td>\n","      <td>0.115596</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>5.438736</td>\n","      <td>74.158896</td>\n","      <td>1.692045</td>\n","      <td>8758.919440</td>\n","      <td>9.498899</td>\n","      <td>4.135765</td>\n","      <td>1.03356</td>\n","      <td>0.392834</td>\n","      <td>19.515596</td>\n","      <td>103.923176</td>\n","      <td>13.038894</td>\n","      <td>31.643384</td>\n","      <td>28.703520</td>\n","      <td>0.083600</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>364</th>\n","      <td>8d7f231c9cb7</td>\n","      <td>0.333294</td>\n","      <td>2950.68664</td>\n","      <td>153.435162</td>\n","      <td>14.221424</td>\n","      <td>8.138688</td>\n","      <td>11.995086</td>\n","      <td>0.025578</td>\n","      <td>12.200672</td>\n","      <td>1.229900</td>\n","      <td>3528.895360</td>\n","      <td>18.0081</td>\n","      <td>281.007549</td>\n","      <td>NaN</td>\n","      <td>1295.239101</td>\n","      <td>257.432377</td>\n","      <td>21.460985</td>\n","      <td>0.753109</td>\n","      <td>31.783352</td>\n","      <td>27.548419</td>\n","      <td>0.024676</td>\n","      <td>1.190255</td>\n","      <td>0.590100</td>\n","      <td>13.784111</td>\n","      <td>1.517175</td>\n","      <td>7.030640</td>\n","      <td>61.60082</td>\n","      <td>570.797805</td>\n","      <td>0.238680</td>\n","      <td>0.371688</td>\n","      <td>99.623783</td>\n","      <td>100.53040</td>\n","      <td>26.381584</td>\n","      <td>0.717288</td>\n","      <td>1.74307</td>\n","      <td>32.607428</td>\n","      <td>5.110164</td>\n","      <td>4.563092</td>\n","      <td>1462.827825</td>\n","      <td>0.188604</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>22.580376</td>\n","      <td>44.570736</td>\n","      <td>0.890550</td>\n","      <td>16122.542060</td>\n","      <td>9.984043</td>\n","      <td>1.170965</td>\n","      <td>0.49706</td>\n","      <td>0.501202</td>\n","      <td>20.724856</td>\n","      <td>127.591671</td>\n","      <td>7359.279057</td>\n","      <td>32.547587</td>\n","      <td>4.436700</td>\n","      <td>0.177058</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>369</th>\n","      <td>8eefb589a7aa</td>\n","      <td>0.405935</td>\n","      <td>192.59328</td>\n","      <td>85.200147</td>\n","      <td>12.357030</td>\n","      <td>8.138688</td>\n","      <td>6.387339</td>\n","      <td>0.025578</td>\n","      <td>6.402832</td>\n","      <td>1.229900</td>\n","      <td>6287.195170</td>\n","      <td>18.7143</td>\n","      <td>196.626015</td>\n","      <td>NaN</td>\n","      <td>939.669807</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.634650</td>\n","      <td>38.323952</td>\n","      <td>12.715941</td>\n","      <td>0.024278</td>\n","      <td>1.050225</td>\n","      <td>0.718575</td>\n","      <td>26.647654</td>\n","      <td>2.046807</td>\n","      <td>7.030640</td>\n","      <td>65.60692</td>\n","      <td>768.079910</td>\n","      <td>0.238680</td>\n","      <td>0.513804</td>\n","      <td>180.674820</td>\n","      <td>87.33976</td>\n","      <td>19.830544</td>\n","      <td>0.206910</td>\n","      <td>1.74307</td>\n","      <td>24.840760</td>\n","      <td>8.382648</td>\n","      <td>3.277203</td>\n","      <td>1040.324700</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>3.828384</td>\n","      <td>32.775456</td>\n","      <td>2.499477</td>\n","      <td>3683.179374</td>\n","      <td>11.213442</td>\n","      <td>54.719291</td>\n","      <td>0.87696</td>\n","      <td>1.219140</td>\n","      <td>9.525248</td>\n","      <td>73.207358</td>\n","      <td>2322.462780</td>\n","      <td>26.221887</td>\n","      <td>95.251448</td>\n","      <td>0.019800</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>375</th>\n","      <td>91275f6ae0a2</td>\n","      <td>0.474303</td>\n","      <td>2465.48390</td>\n","      <td>160.306563</td>\n","      <td>14.608549</td>\n","      <td>11.636436</td>\n","      <td>4.128294</td>\n","      <td>0.112056</td>\n","      <td>6.144450</td>\n","      <td>6.290060</td>\n","      <td>4251.654780</td>\n","      <td>20.8329</td>\n","      <td>134.376300</td>\n","      <td>NaN</td>\n","      <td>1805.239364</td>\n","      <td>1146.389288</td>\n","      <td>17.692675</td>\n","      <td>0.649601</td>\n","      <td>112.807512</td>\n","      <td>7.190444</td>\n","      <td>0.031840</td>\n","      <td>1.177525</td>\n","      <td>0.679575</td>\n","      <td>41.572014</td>\n","      <td>1.693719</td>\n","      <td>7.030640</td>\n","      <td>51.63892</td>\n","      <td>167.669610</td>\n","      <td>0.455598</td>\n","      <td>0.557532</td>\n","      <td>161.518500</td>\n","      <td>109.47468</td>\n","      <td>19.332392</td>\n","      <td>1.282842</td>\n","      <td>1.74307</td>\n","      <td>19.315600</td>\n","      <td>12.573972</td>\n","      <td>1.777671</td>\n","      <td>1497.610150</td>\n","      <td>0.249444</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>170.086150</td>\n","      <td>50.103216</td>\n","      <td>53.829888</td>\n","      <td>3.888735</td>\n","      <td>3841.777770</td>\n","      <td>9.327996</td>\n","      <td>5.170251</td>\n","      <td>1.19712</td>\n","      <td>0.629889</td>\n","      <td>14.697160</td>\n","      <td>72.611063</td>\n","      <td>3754.632852</td>\n","      <td>26.705617</td>\n","      <td>49.400404</td>\n","      <td>0.130935</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>422</th>\n","      <td>a7b1c7b83f53</td>\n","      <td>0.636677</td>\n","      <td>562.28579</td>\n","      <td>291.368304</td>\n","      <td>99.410603</td>\n","      <td>8.138688</td>\n","      <td>7.082770</td>\n","      <td>0.068513</td>\n","      <td>4.783218</td>\n","      <td>1.229900</td>\n","      <td>4463.301890</td>\n","      <td>18.0081</td>\n","      <td>237.087270</td>\n","      <td>NaN</td>\n","      <td>51.216883</td>\n","      <td>1296.856509</td>\n","      <td>235.611285</td>\n","      <td>0.344036</td>\n","      <td>135.370600</td>\n","      <td>4.512844</td>\n","      <td>0.047362</td>\n","      <td>1.050225</td>\n","      <td>0.699975</td>\n","      <td>34.897896</td>\n","      <td>0.739278</td>\n","      <td>45.362440</td>\n","      <td>46.22438</td>\n","      <td>437.911900</td>\n","      <td>0.441909</td>\n","      <td>0.349824</td>\n","      <td>60.232470</td>\n","      <td>86.20556</td>\n","      <td>18.561280</td>\n","      <td>0.806949</td>\n","      <td>1.74307</td>\n","      <td>18.432922</td>\n","      <td>6.163296</td>\n","      <td>3.611776</td>\n","      <td>796.794200</td>\n","      <td>0.176436</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>115.607602</td>\n","      <td>5.737512</td>\n","      <td>18.969552</td>\n","      <td>2.778516</td>\n","      <td>3963.342924</td>\n","      <td>5.196002</td>\n","      <td>4.142271</td>\n","      <td>0.49706</td>\n","      <td>0.799214</td>\n","      <td>6.018394</td>\n","      <td>72.611063</td>\n","      <td>1773.175860</td>\n","      <td>24.610694</td>\n","      <td>3.598228</td>\n","      <td>0.147231</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>449</th>\n","      <td>b10bae274dfc</td>\n","      <td>0.470030</td>\n","      <td>192.59328</td>\n","      <td>139.378836</td>\n","      <td>85.523655</td>\n","      <td>8.138688</td>\n","      <td>6.369621</td>\n","      <td>0.031364</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>6605.133250</td>\n","      <td>18.0081</td>\n","      <td>280.405611</td>\n","      <td>NaN</td>\n","      <td>1889.783213</td>\n","      <td>257.432377</td>\n","      <td>1467.150139</td>\n","      <td>0.512770</td>\n","      <td>179.038024</td>\n","      <td>12.553248</td>\n","      <td>0.045372</td>\n","      <td>1.050225</td>\n","      <td>1.275000</td>\n","      <td>19.483612</td>\n","      <td>0.706176</td>\n","      <td>41.185088</td>\n","      <td>31.42218</td>\n","      <td>340.696700</td>\n","      <td>0.238680</td>\n","      <td>0.172179</td>\n","      <td>68.080613</td>\n","      <td>108.27476</td>\n","      <td>23.870352</td>\n","      <td>0.620730</td>\n","      <td>1.74307</td>\n","      <td>49.021196</td>\n","      <td>4.926396</td>\n","      <td>4.252705</td>\n","      <td>1021.002525</td>\n","      <td>0.170352</td>\n","      <td>B</td>\n","      <td>41.658903</td>\n","      <td>78.526968</td>\n","      <td>11.928252</td>\n","      <td>23.190720</td>\n","      <td>4.043097</td>\n","      <td>6308.160246</td>\n","      <td>7.249595</td>\n","      <td>5.475302</td>\n","      <td>0.49706</td>\n","      <td>0.379288</td>\n","      <td>12.966988</td>\n","      <td>72.611063</td>\n","      <td>975.316707</td>\n","      <td>20.506431</td>\n","      <td>9.364652</td>\n","      <td>0.184800</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>458</th>\n","      <td>b358f0fdb95b</td>\n","      <td>0.081187</td>\n","      <td>1365.55760</td>\n","      <td>85.200147</td>\n","      <td>7.408024</td>\n","      <td>8.138688</td>\n","      <td>3.003201</td>\n","      <td>0.025578</td>\n","      <td>6.840821</td>\n","      <td>2.255988</td>\n","      <td>4394.356180</td>\n","      <td>18.3612</td>\n","      <td>118.797975</td>\n","      <td>NaN</td>\n","      <td>555.113706</td>\n","      <td>257.432377</td>\n","      <td>15.353566</td>\n","      <td>0.532565</td>\n","      <td>44.373016</td>\n","      <td>7.842739</td>\n","      <td>0.012338</td>\n","      <td>1.050225</td>\n","      <td>0.447150</td>\n","      <td>17.121170</td>\n","      <td>0.777897</td>\n","      <td>7.030640</td>\n","      <td>16.56372</td>\n","      <td>213.684953</td>\n","      <td>0.238680</td>\n","      <td>0.180378</td>\n","      <td>132.951562</td>\n","      <td>42.11804</td>\n","      <td>6.339496</td>\n","      <td>0.006897</td>\n","      <td>1.74307</td>\n","      <td>63.013776</td>\n","      <td>4.926396</td>\n","      <td>1.223408</td>\n","      <td>442.885700</td>\n","      <td>0.024336</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>428.566320</td>\n","      <td>18.187008</td>\n","      <td>0.296850</td>\n","      <td>8267.998789</td>\n","      <td>7.133822</td>\n","      <td>0.296625</td>\n","      <td>2.08916</td>\n","      <td>0.067730</td>\n","      <td>12.734438</td>\n","      <td>103.874589</td>\n","      <td>3266.415720</td>\n","      <td>19.918513</td>\n","      <td>66.949160</td>\n","      <td>2.376000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>469</th>\n","      <td>ba0c42e12f1f</td>\n","      <td>0.730683</td>\n","      <td>2591.80911</td>\n","      <td>191.380275</td>\n","      <td>16.553465</td>\n","      <td>8.138688</td>\n","      <td>7.042905</td>\n","      <td>0.119059</td>\n","      <td>10.650380</td>\n","      <td>1.229900</td>\n","      <td>4611.963830</td>\n","      <td>20.8329</td>\n","      <td>327.471228</td>\n","      <td>NaN</td>\n","      <td>2458.132130</td>\n","      <td>257.432377</td>\n","      <td>46.662707</td>\n","      <td>0.855799</td>\n","      <td>85.773032</td>\n","      <td>19.568835</td>\n","      <td>0.043382</td>\n","      <td>1.145700</td>\n","      <td>0.637200</td>\n","      <td>28.556787</td>\n","      <td>1.268910</td>\n","      <td>40.887744</td>\n","      <td>10.68358</td>\n","      <td>128.379945</td>\n","      <td>0.434889</td>\n","      <td>0.248703</td>\n","      <td>74.225093</td>\n","      <td>91.03280</td>\n","      <td>13.047488</td>\n","      <td>4.565814</td>\n","      <td>1.74307</td>\n","      <td>43.473576</td>\n","      <td>5.873508</td>\n","      <td>4.651774</td>\n","      <td>2918.702800</td>\n","      <td>0.456300</td>\n","      <td>B</td>\n","      <td>34.320000</td>\n","      <td>78.526968</td>\n","      <td>6.216060</td>\n","      <td>61.746720</td>\n","      <td>7.563738</td>\n","      <td>4993.562501</td>\n","      <td>12.001801</td>\n","      <td>10.371341</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>23.896838</td>\n","      <td>144.616997</td>\n","      <td>1753.748739</td>\n","      <td>20.324102</td>\n","      <td>3.150700</td>\n","      <td>0.067296</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>bbb1066a9afd</td>\n","      <td>0.264926</td>\n","      <td>1390.03590</td>\n","      <td>85.200147</td>\n","      <td>11.601362</td>\n","      <td>10.217934</td>\n","      <td>5.660901</td>\n","      <td>0.074907</td>\n","      <td>3.396778</td>\n","      <td>3.113404</td>\n","      <td>4906.738900</td>\n","      <td>24.3639</td>\n","      <td>381.861837</td>\n","      <td>9.492620</td>\n","      <td>198.310416</td>\n","      <td>595.886550</td>\n","      <td>70.853419</td>\n","      <td>0.289390</td>\n","      <td>99.789736</td>\n","      <td>2.423677</td>\n","      <td>0.025870</td>\n","      <td>1.050225</td>\n","      <td>0.576450</td>\n","      <td>38.686521</td>\n","      <td>1.456488</td>\n","      <td>7.030640</td>\n","      <td>57.63352</td>\n","      <td>267.661120</td>\n","      <td>0.238680</td>\n","      <td>0.338892</td>\n","      <td>140.918303</td>\n","      <td>75.60556</td>\n","      <td>27.275528</td>\n","      <td>5.641746</td>\n","      <td>1.74307</td>\n","      <td>22.837328</td>\n","      <td>8.951622</td>\n","      <td>2.108213</td>\n","      <td>1337.128250</td>\n","      <td>0.523224</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>169.604162</td>\n","      <td>20.055972</td>\n","      <td>28.868448</td>\n","      <td>23.510520</td>\n","      <td>6302.762840</td>\n","      <td>7.800895</td>\n","      <td>31.251519</td>\n","      <td>1.13593</td>\n","      <td>0.067730</td>\n","      <td>22.966638</td>\n","      <td>72.611063</td>\n","      <td>4646.471769</td>\n","      <td>23.356717</td>\n","      <td>46.537768</td>\n","      <td>0.062450</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>490</th>\n","      <td>c5f4dc4ae7fb</td>\n","      <td>0.474303</td>\n","      <td>4877.54146</td>\n","      <td>85.200147</td>\n","      <td>34.996100</td>\n","      <td>8.138688</td>\n","      <td>5.864658</td>\n","      <td>0.025578</td>\n","      <td>3.396778</td>\n","      <td>5.081244</td>\n","      <td>3877.099560</td>\n","      <td>20.1267</td>\n","      <td>266.603427</td>\n","      <td>344.644105</td>\n","      <td>478.566635</td>\n","      <td>257.432377</td>\n","      <td>67.489513</td>\n","      <td>0.410217</td>\n","      <td>146.604576</td>\n","      <td>4.643607</td>\n","      <td>0.027462</td>\n","      <td>1.050225</td>\n","      <td>0.888900</td>\n","      <td>37.024966</td>\n","      <td>1.616481</td>\n","      <td>36.072648</td>\n","      <td>67.34516</td>\n","      <td>118.316930</td>\n","      <td>0.238680</td>\n","      <td>0.333426</td>\n","      <td>99.508950</td>\n","      <td>71.43340</td>\n","      <td>42.158672</td>\n","      <td>5.634849</td>\n","      <td>1.74307</td>\n","      <td>19.131428</td>\n","      <td>5.894712</td>\n","      <td>3.394102</td>\n","      <td>1740.026025</td>\n","      <td>0.407628</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>34.911216</td>\n","      <td>24.093216</td>\n","      <td>12.307401</td>\n","      <td>51958.461990</td>\n","      <td>13.490311</td>\n","      <td>20.986174</td>\n","      <td>1.07764</td>\n","      <td>0.535067</td>\n","      <td>23.106168</td>\n","      <td>72.611063</td>\n","      <td>2497.724586</td>\n","      <td>42.534751</td>\n","      <td>19.323436</td>\n","      <td>0.048712</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>492</th>\n","      <td>c6c3a77ec885</td>\n","      <td>0.589674</td>\n","      <td>5782.60210</td>\n","      <td>124.660626</td>\n","      <td>34.311663</td>\n","      <td>8.138688</td>\n","      <td>12.393741</td>\n","      <td>0.025578</td>\n","      <td>11.526358</td>\n","      <td>1.229900</td>\n","      <td>6640.848550</td>\n","      <td>19.0674</td>\n","      <td>207.575352</td>\n","      <td>NaN</td>\n","      <td>732.031833</td>\n","      <td>257.432377</td>\n","      <td>21.286356</td>\n","      <td>0.898593</td>\n","      <td>32.845704</td>\n","      <td>29.242256</td>\n","      <td>0.023482</td>\n","      <td>1.444855</td>\n","      <td>0.571200</td>\n","      <td>59.482990</td>\n","      <td>1.621998</td>\n","      <td>7.030640</td>\n","      <td>41.71970</td>\n","      <td>182.522425</td>\n","      <td>0.238680</td>\n","      <td>0.486474</td>\n","      <td>94.371607</td>\n","      <td>103.30336</td>\n","      <td>18.929776</td>\n","      <td>1.531134</td>\n","      <td>1.74307</td>\n","      <td>36.389692</td>\n","      <td>8.184744</td>\n","      <td>5.191928</td>\n","      <td>1016.676575</td>\n","      <td>0.048672</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>22.856364</td>\n","      <td>56.697312</td>\n","      <td>0.522456</td>\n","      <td>7577.827019</td>\n","      <td>11.009461</td>\n","      <td>3.889259</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>30.491956</td>\n","      <td>142.216357</td>\n","      <td>558.039294</td>\n","      <td>32.127114</td>\n","      <td>5.280316</td>\n","      <td>0.021405</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>cd5d5458c163</td>\n","      <td>0.538398</td>\n","      <td>3925.42513</td>\n","      <td>176.505303</td>\n","      <td>37.256910</td>\n","      <td>8.138688</td>\n","      <td>7.069482</td>\n","      <td>0.025578</td>\n","      <td>15.124800</td>\n","      <td>1.229900</td>\n","      <td>7006.774570</td>\n","      <td>21.1860</td>\n","      <td>196.062228</td>\n","      <td>NaN</td>\n","      <td>590.648556</td>\n","      <td>257.432377</td>\n","      <td>51.589083</td>\n","      <td>0.626385</td>\n","      <td>131.763360</td>\n","      <td>22.057893</td>\n","      <td>0.044178</td>\n","      <td>1.686725</td>\n","      <td>0.959025</td>\n","      <td>55.167827</td>\n","      <td>0.877203</td>\n","      <td>41.413156</td>\n","      <td>38.13458</td>\n","      <td>240.212905</td>\n","      <td>0.734994</td>\n","      <td>0.276033</td>\n","      <td>117.281633</td>\n","      <td>131.53328</td>\n","      <td>38.425944</td>\n","      <td>1.420782</td>\n","      <td>1.74307</td>\n","      <td>14.181244</td>\n","      <td>12.429078</td>\n","      <td>3.865729</td>\n","      <td>2383.158625</td>\n","      <td>0.450216</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>193.272553</td>\n","      <td>33.698388</td>\n","      <td>94.367952</td>\n","      <td>10.674726</td>\n","      <td>4333.121380</td>\n","      <td>12.227834</td>\n","      <td>8.275406</td>\n","      <td>0.72848</td>\n","      <td>1.022723</td>\n","      <td>32.715134</td>\n","      <td>114.890587</td>\n","      <td>31583.309000</td>\n","      <td>50.170243</td>\n","      <td>29.752896</td>\n","      <td>0.213379</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>516</th>\n","      <td>d0ecfae80796</td>\n","      <td>0.440119</td>\n","      <td>975.50805</td>\n","      <td>85.200147</td>\n","      <td>121.197998</td>\n","      <td>8.138688</td>\n","      <td>4.978758</td>\n","      <td>0.035322</td>\n","      <td>3.396778</td>\n","      <td>3.953250</td>\n","      <td>3932.869760</td>\n","      <td>21.8922</td>\n","      <td>239.219487</td>\n","      <td>178.906190</td>\n","      <td>1325.220969</td>\n","      <td>257.432377</td>\n","      <td>34.080228</td>\n","      <td>0.520555</td>\n","      <td>161.754984</td>\n","      <td>10.667828</td>\n","      <td>0.032636</td>\n","      <td>1.050225</td>\n","      <td>0.715125</td>\n","      <td>44.093115</td>\n","      <td>1.964052</td>\n","      <td>33.788656</td>\n","      <td>33.67840</td>\n","      <td>136.136760</td>\n","      <td>0.238680</td>\n","      <td>0.271933</td>\n","      <td>116.022240</td>\n","      <td>80.36178</td>\n","      <td>17.315900</td>\n","      <td>9.986856</td>\n","      <td>1.74307</td>\n","      <td>16.112804</td>\n","      <td>6.364734</td>\n","      <td>0.842479</td>\n","      <td>698.746363</td>\n","      <td>1.648764</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>98.598988</td>\n","      <td>20.972556</td>\n","      <td>67.978512</td>\n","      <td>14.397225</td>\n","      <td>8356.041635</td>\n","      <td>9.217736</td>\n","      <td>8.080244</td>\n","      <td>2.74891</td>\n","      <td>0.988858</td>\n","      <td>31.143096</td>\n","      <td>72.611063</td>\n","      <td>4999.158324</td>\n","      <td>33.403417</td>\n","      <td>8.258692</td>\n","      <td>0.111170</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>517</th>\n","      <td>d10976c44b2b</td>\n","      <td>0.316202</td>\n","      <td>1624.69362</td>\n","      <td>145.013559</td>\n","      <td>14.147096</td>\n","      <td>8.138688</td>\n","      <td>7.206797</td>\n","      <td>0.025578</td>\n","      <td>11.400318</td>\n","      <td>1.229900</td>\n","      <td>5012.662330</td>\n","      <td>19.4205</td>\n","      <td>175.748940</td>\n","      <td>NaN</td>\n","      <td>590.182783</td>\n","      <td>257.432377</td>\n","      <td>64.079652</td>\n","      <td>0.644133</td>\n","      <td>77.424848</td>\n","      <td>17.315454</td>\n","      <td>0.021890</td>\n","      <td>1.438490</td>\n","      <td>0.581400</td>\n","      <td>29.020557</td>\n","      <td>1.329597</td>\n","      <td>7.030640</td>\n","      <td>35.21682</td>\n","      <td>615.662265</td>\n","      <td>0.238680</td>\n","      <td>0.338892</td>\n","      <td>118.985295</td>\n","      <td>116.77384</td>\n","      <td>20.970152</td>\n","      <td>0.496584</td>\n","      <td>1.74307</td>\n","      <td>27.017134</td>\n","      <td>4.926396</td>\n","      <td>1.096432</td>\n","      <td>1257.056000</td>\n","      <td>0.030420</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>4.686732</td>\n","      <td>360.547152</td>\n","      <td>0.504645</td>\n","      <td>6589.558986</td>\n","      <td>9.540247</td>\n","      <td>3.423047</td>\n","      <td>0.49706</td>\n","      <td>0.257374</td>\n","      <td>27.013008</td>\n","      <td>134.912848</td>\n","      <td>2407.388364</td>\n","      <td>34.668557</td>\n","      <td>10.711094</td>\n","      <td>0.041250</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>529</th>\n","      <td>d44d3320d240</td>\n","      <td>0.529852</td>\n","      <td>2648.55448</td>\n","      <td>85.200147</td>\n","      <td>29.062248</td>\n","      <td>8.138688</td>\n","      <td>6.289890</td>\n","      <td>0.025578</td>\n","      <td>7.827084</td>\n","      <td>7.165046</td>\n","      <td>5169.545980</td>\n","      <td>18.7143</td>\n","      <td>106.619328</td>\n","      <td>NaN</td>\n","      <td>838.914639</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.600247</td>\n","      <td>102.334624</td>\n","      <td>5.309586</td>\n","      <td>0.034228</td>\n","      <td>1.050225</td>\n","      <td>0.556575</td>\n","      <td>19.070403</td>\n","      <td>1.125468</td>\n","      <td>36.343496</td>\n","      <td>18.77920</td>\n","      <td>228.974615</td>\n","      <td>0.238680</td>\n","      <td>0.401751</td>\n","      <td>97.180297</td>\n","      <td>101.50772</td>\n","      <td>17.810640</td>\n","      <td>0.344850</td>\n","      <td>1.74307</td>\n","      <td>51.361528</td>\n","      <td>4.926396</td>\n","      <td>1.688989</td>\n","      <td>964.578400</td>\n","      <td>0.036504</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>100.406442</td>\n","      <td>14.900820</td>\n","      <td>36.533952</td>\n","      <td>0.522456</td>\n","      <td>2884.329599</td>\n","      <td>12.233347</td>\n","      <td>2.461014</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>24.445656</td>\n","      <td>118.355723</td>\n","      <td>160.814484</td>\n","      <td>29.310317</td>\n","      <td>19.210268</td>\n","      <td>0.071280</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>537</th>\n","      <td>d9d5fdfa030c</td>\n","      <td>0.363205</td>\n","      <td>1258.32256</td>\n","      <td>85.200147</td>\n","      <td>24.165891</td>\n","      <td>8.138688</td>\n","      <td>5.669760</td>\n","      <td>0.025578</td>\n","      <td>10.448716</td>\n","      <td>1.229900</td>\n","      <td>6999.863220</td>\n","      <td>19.7736</td>\n","      <td>140.260032</td>\n","      <td>NaN</td>\n","      <td>1641.601816</td>\n","      <td>257.432377</td>\n","      <td>12.784681</td>\n","      <td>0.679721</td>\n","      <td>63.978960</td>\n","      <td>13.828947</td>\n","      <td>0.018308</td>\n","      <td>1.101145</td>\n","      <td>0.716625</td>\n","      <td>39.828514</td>\n","      <td>1.969569</td>\n","      <td>36.172928</td>\n","      <td>44.00696</td>\n","      <td>155.420140</td>\n","      <td>0.238680</td>\n","      <td>0.401751</td>\n","      <td>146.752170</td>\n","      <td>109.94744</td>\n","      <td>20.199040</td>\n","      <td>1.517340</td>\n","      <td>1.74307</td>\n","      <td>13.799424</td>\n","      <td>9.803316</td>\n","      <td>2.741080</td>\n","      <td>1557.498650</td>\n","      <td>0.231192</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>5.884368</td>\n","      <td>44.302272</td>\n","      <td>3.473145</td>\n","      <td>7410.144362</td>\n","      <td>9.085424</td>\n","      <td>5.418528</td>\n","      <td>1.95112</td>\n","      <td>0.839852</td>\n","      <td>29.329206</td>\n","      <td>72.611063</td>\n","      <td>9786.129534</td>\n","      <td>24.160453</td>\n","      <td>31.712760</td>\n","      <td>0.102600</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>562</th>\n","      <td>e70b5934b571</td>\n","      <td>0.478576</td>\n","      <td>7643.98140</td>\n","      <td>116.953161</td>\n","      <td>33.645808</td>\n","      <td>8.204238</td>\n","      <td>8.876718</td>\n","      <td>0.025578</td>\n","      <td>11.828854</td>\n","      <td>1.229900</td>\n","      <td>5883.875950</td>\n","      <td>18.0081</td>\n","      <td>205.180317</td>\n","      <td>NaN</td>\n","      <td>996.999205</td>\n","      <td>257.432377</td>\n","      <td>15.165150</td>\n","      <td>0.899028</td>\n","      <td>89.435768</td>\n","      <td>28.153578</td>\n","      <td>0.047760</td>\n","      <td>1.050225</td>\n","      <td>1.012500</td>\n","      <td>31.376026</td>\n","      <td>1.704753</td>\n","      <td>7.030640</td>\n","      <td>77.31482</td>\n","      <td>573.516460</td>\n","      <td>0.238680</td>\n","      <td>0.349824</td>\n","      <td>127.814220</td>\n","      <td>144.52040</td>\n","      <td>15.592840</td>\n","      <td>0.558657</td>\n","      <td>1.74307</td>\n","      <td>50.265480</td>\n","      <td>6.806484</td>\n","      <td>9.888043</td>\n","      <td>1867.743975</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>78.526968</td>\n","      <td>7.778304</td>\n","      <td>54.429648</td>\n","      <td>2.641965</td>\n","      <td>9810.504061</td>\n","      <td>11.163825</td>\n","      <td>95.038650</td>\n","      <td>0.49706</td>\n","      <td>NaN</td>\n","      <td>25.766540</td>\n","      <td>191.971654</td>\n","      <td>4833.383724</td>\n","      <td>25.113029</td>\n","      <td>40.025464</td>\n","      <td>0.007333</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>e9417cc82b93</td>\n","      <td>0.602493</td>\n","      <td>3719.52427</td>\n","      <td>113.443434</td>\n","      <td>28.071208</td>\n","      <td>8.138688</td>\n","      <td>7.211226</td>\n","      <td>0.025578</td>\n","      <td>11.148238</td>\n","      <td>1.229900</td>\n","      <td>4290.430250</td>\n","      <td>20.4798</td>\n","      <td>278.731206</td>\n","      <td>NaN</td>\n","      <td>819.609255</td>\n","      <td>257.432377</td>\n","      <td>29.264144</td>\n","      <td>0.572220</td>\n","      <td>126.467456</td>\n","      <td>15.332722</td>\n","      <td>0.030248</td>\n","      <td>1.101145</td>\n","      <td>0.679350</td>\n","      <td>25.547505</td>\n","      <td>0.993060</td>\n","      <td>7.030640</td>\n","      <td>45.36302</td>\n","      <td>427.675920</td>\n","      <td>0.238680</td>\n","      <td>0.207708</td>\n","      <td>74.588415</td>\n","      <td>120.62800</td>\n","      <td>20.253632</td>\n","      <td>0.675906</td>\n","      <td>1.74307</td>\n","      <td>26.803764</td>\n","      <td>6.007800</td>\n","      <td>7.844326</td>\n","      <td>1863.448150</td>\n","      <td>0.121680</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>78.526968</td>\n","      <td>4.651284</td>\n","      <td>46.718448</td>\n","      <td>2.689461</td>\n","      <td>4651.223978</td>\n","      <td>10.733811</td>\n","      <td>5.320825</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>8.967128</td>\n","      <td>125.065146</td>\n","      <td>4911.188436</td>\n","      <td>21.630173</td>\n","      <td>8.299844</td>\n","      <td>0.121224</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>570</th>\n","      <td>e9c343dc7736</td>\n","      <td>0.190148</td>\n","      <td>4376.46594</td>\n","      <td>85.200147</td>\n","      <td>13.411558</td>\n","      <td>8.138688</td>\n","      <td>4.996476</td>\n","      <td>0.088305</td>\n","      <td>3.396778</td>\n","      <td>1.229900</td>\n","      <td>6326.889490</td>\n","      <td>21.5391</td>\n","      <td>174.345831</td>\n","      <td>NaN</td>\n","      <td>211.944862</td>\n","      <td>1227.771646</td>\n","      <td>12.499760</td>\n","      <td>0.632591</td>\n","      <td>66.412856</td>\n","      <td>6.696282</td>\n","      <td>0.031243</td>\n","      <td>1.050225</td>\n","      <td>0.894825</td>\n","      <td>36.027684</td>\n","      <td>1.164087</td>\n","      <td>42.731608</td>\n","      <td>58.14374</td>\n","      <td>592.555915</td>\n","      <td>0.238680</td>\n","      <td>0.274666</td>\n","      <td>93.765443</td>\n","      <td>75.57270</td>\n","      <td>19.086728</td>\n","      <td>0.006897</td>\n","      <td>1.74307</td>\n","      <td>31.255336</td>\n","      <td>6.891300</td>\n","      <td>1.830074</td>\n","      <td>1116.143300</td>\n","      <td>0.024336</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>119.027863</td>\n","      <td>22.699380</td>\n","      <td>22.351056</td>\n","      <td>0.296850</td>\n","      <td>5039.283246</td>\n","      <td>7.900129</td>\n","      <td>0.296625</td>\n","      <td>2.15064</td>\n","      <td>0.067730</td>\n","      <td>23.385228</td>\n","      <td>72.611063</td>\n","      <td>6023.124846</td>\n","      <td>47.014835</td>\n","      <td>21.422188</td>\n","      <td>2.376000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>573</th>\n","      <td>eada36b0bf31</td>\n","      <td>0.337567</td>\n","      <td>3440.63258</td>\n","      <td>99.186801</td>\n","      <td>31.000970</td>\n","      <td>19.748904</td>\n","      <td>7.849074</td>\n","      <td>0.025578</td>\n","      <td>7.801876</td>\n","      <td>1.229900</td>\n","      <td>6404.024950</td>\n","      <td>20.1267</td>\n","      <td>164.680911</td>\n","      <td>NaN</td>\n","      <td>842.190172</td>\n","      <td>257.432377</td>\n","      <td>24.622689</td>\n","      <td>0.648720</td>\n","      <td>127.799360</td>\n","      <td>1.914310</td>\n","      <td>0.025074</td>\n","      <td>1.152065</td>\n","      <td>0.706050</td>\n","      <td>38.702213</td>\n","      <td>3.122622</td>\n","      <td>36.806256</td>\n","      <td>68.30740</td>\n","      <td>909.387880</td>\n","      <td>1.239030</td>\n","      <td>0.513804</td>\n","      <td>173.570265</td>\n","      <td>79.11840</td>\n","      <td>31.629240</td>\n","      <td>0.620730</td>\n","      <td>1.74307</td>\n","      <td>19.782768</td>\n","      <td>12.467952</td>\n","      <td>3.325575</td>\n","      <td>2755.124050</td>\n","      <td>0.237276</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>95.739501</td>\n","      <td>17.475864</td>\n","      <td>35.482944</td>\n","      <td>5.242371</td>\n","      <td>8018.868452</td>\n","      <td>8.633358</td>\n","      <td>5.097005</td>\n","      <td>0.49706</td>\n","      <td>0.067730</td>\n","      <td>16.315708</td>\n","      <td>110.632599</td>\n","      <td>7444.066860</td>\n","      <td>16.111930</td>\n","      <td>76.509284</td>\n","      <td>0.257400</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>579</th>\n","      <td>efcba7fac353</td>\n","      <td>0.405935</td>\n","      <td>5576.23055</td>\n","      <td>91.723188</td>\n","      <td>19.473936</td>\n","      <td>8.138688</td>\n","      <td>10.816839</td>\n","      <td>0.066685</td>\n","      <td>10.202938</td>\n","      <td>2.920134</td>\n","      <td>4741.074240</td>\n","      <td>20.4798</td>\n","      <td>145.656279</td>\n","      <td>NaN</td>\n","      <td>524.820313</td>\n","      <td>257.432377</td>\n","      <td>17.665102</td>\n","      <td>0.732696</td>\n","      <td>56.601956</td>\n","      <td>16.266309</td>\n","      <td>0.037412</td>\n","      <td>1.050225</td>\n","      <td>0.487725</td>\n","      <td>35.773133</td>\n","      <td>1.213740</td>\n","      <td>41.239920</td>\n","      <td>77.94532</td>\n","      <td>448.946180</td>\n","      <td>0.760617</td>\n","      <td>0.327960</td>\n","      <td>149.547683</td>\n","      <td>126.81840</td>\n","      <td>24.266144</td>\n","      <td>1.000065</td>\n","      <td>1.74307</td>\n","      <td>25.905364</td>\n","      <td>9.128322</td>\n","      <td>4.434100</td>\n","      <td>811.199975</td>\n","      <td>0.255528</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>124.876603</td>\n","      <td>25.922616</td>\n","      <td>35.694288</td>\n","      <td>2.558847</td>\n","      <td>2600.344446</td>\n","      <td>7.971798</td>\n","      <td>2.932309</td>\n","      <td>0.49706</td>\n","      <td>0.250601</td>\n","      <td>13.571618</td>\n","      <td>243.025549</td>\n","      <td>4421.799072</td>\n","      <td>42.728243</td>\n","      <td>29.952226</td>\n","      <td>0.172055</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>582</th>\n","      <td>f0d7d98bfe21</td>\n","      <td>0.367478</td>\n","      <td>3077.07598</td>\n","      <td>324.349287</td>\n","      <td>37.814370</td>\n","      <td>28.689924</td>\n","      <td>6.803712</td>\n","      <td>0.025578</td>\n","      <td>10.121012</td>\n","      <td>1.229900</td>\n","      <td>5901.933350</td>\n","      <td>21.1860</td>\n","      <td>239.367852</td>\n","      <td>NaN</td>\n","      <td>1197.266472</td>\n","      <td>953.234999</td>\n","      <td>23.409477</td>\n","      <td>0.534980</td>\n","      <td>76.013664</td>\n","      <td>0.510888</td>\n","      <td>0.030248</td>\n","      <td>4.372755</td>\n","      <td>0.623775</td>\n","      <td>45.261260</td>\n","      <td>1.235808</td>\n","      <td>43.414984</td>\n","      <td>37.21696</td>\n","      <td>2052.389385</td>\n","      <td>2.681640</td>\n","      <td>0.661386</td>\n","      <td>182.094225</td>\n","      <td>84.63676</td>\n","      <td>26.531712</td>\n","      <td>2.013924</td>\n","      <td>3.18311</td>\n","      <td>13.732044</td>\n","      <td>4.926396</td>\n","      <td>3.430381</td>\n","      <td>1895.284250</td>\n","      <td>0.438048</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>149.277245</td>\n","      <td>84.194064</td>\n","      <td>37.053744</td>\n","      <td>5.663898</td>\n","      <td>33984.269060</td>\n","      <td>10.877149</td>\n","      <td>5.372854</td>\n","      <td>0.97150</td>\n","      <td>0.399607</td>\n","      <td>25.803748</td>\n","      <td>151.900630</td>\n","      <td>8899.331652</td>\n","      <td>31.929901</td>\n","      <td>42.134504</td>\n","      <td>0.146466</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>583</th>\n","      <td>f12d8570682a</td>\n","      <td>0.282018</td>\n","      <td>4226.17426</td>\n","      <td>91.392246</td>\n","      <td>13.704225</td>\n","      <td>8.138688</td>\n","      <td>4.916745</td>\n","      <td>0.025578</td>\n","      <td>9.415188</td>\n","      <td>1.229900</td>\n","      <td>6144.797390</td>\n","      <td>18.0081</td>\n","      <td>100.684728</td>\n","      <td>NaN</td>\n","      <td>2246.834511</td>\n","      <td>257.432377</td>\n","      <td>29.052751</td>\n","      <td>0.889808</td>\n","      <td>199.650824</td>\n","      <td>12.843663</td>\n","      <td>0.030646</td>\n","      <td>1.050225</td>\n","      <td>0.495225</td>\n","      <td>32.160601</td>\n","      <td>1.153053</td>\n","      <td>7.030640</td>\n","      <td>43.73924</td>\n","      <td>149.898565</td>\n","      <td>0.238680</td>\n","      <td>0.399018</td>\n","      <td>142.354650</td>\n","      <td>83.89688</td>\n","      <td>18.288320</td>\n","      <td>1.006962</td>\n","      <td>1.74307</td>\n","      <td>16.840508</td>\n","      <td>4.926396</td>\n","      <td>3.091777</td>\n","      <td>1905.701475</td>\n","      <td>0.103428</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>91.790907</td>\n","      <td>9.282312</td>\n","      <td>143.274096</td>\n","      <td>1.715793</td>\n","      <td>2503.834934</td>\n","      <td>10.744837</td>\n","      <td>4.874422</td>\n","      <td>1.76204</td>\n","      <td>0.386061</td>\n","      <td>12.660022</td>\n","      <td>72.611063</td>\n","      <td>2118.717486</td>\n","      <td>20.714807</td>\n","      <td>29.786332</td>\n","      <td>0.069164</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>594</th>\n","      <td>f46e39a96ee9</td>\n","      <td>0.670861</td>\n","      <td>5501.73569</td>\n","      <td>93.822057</td>\n","      <td>6.993026</td>\n","      <td>8.138688</td>\n","      <td>6.511365</td>\n","      <td>0.025578</td>\n","      <td>9.541228</td>\n","      <td>1.229900</td>\n","      <td>4126.619270</td>\n","      <td>20.4798</td>\n","      <td>138.076947</td>\n","      <td>NaN</td>\n","      <td>862.898924</td>\n","      <td>257.432377</td>\n","      <td>27.609764</td>\n","      <td>0.761854</td>\n","      <td>86.978088</td>\n","      <td>9.116918</td>\n","      <td>0.034626</td>\n","      <td>1.050225</td>\n","      <td>1.264050</td>\n","      <td>25.673037</td>\n","      <td>0.617904</td>\n","      <td>7.030640</td>\n","      <td>46.60656</td>\n","      <td>308.019620</td>\n","      <td>0.238680</td>\n","      <td>0.204975</td>\n","      <td>80.990797</td>\n","      <td>89.26048</td>\n","      <td>31.035552</td>\n","      <td>NaN</td>\n","      <td>1.74307</td>\n","      <td>32.652348</td>\n","      <td>5.523642</td>\n","      <td>6.119058</td>\n","      <td>4383.172438</td>\n","      <td>0.006084</td>\n","      <td>B</td>\n","      <td>41.967354</td>\n","      <td>78.526968</td>\n","      <td>4.210716</td>\n","      <td>32.187120</td>\n","      <td>2.719146</td>\n","      <td>5280.276301</td>\n","      <td>8.252961</td>\n","      <td>NaN</td>\n","      <td>0.49706</td>\n","      <td>0.731484</td>\n","      <td>37.310322</td>\n","      <td>143.490662</td>\n","      <td>1849.552461</td>\n","      <td>31.371751</td>\n","      <td>10.043660</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>602</th>\n","      <td>f955c0ed8895</td>\n","      <td>0.350386</td>\n","      <td>5431.63797</td>\n","      <td>85.200147</td>\n","      <td>11.607556</td>\n","      <td>8.138688</td>\n","      <td>7.565586</td>\n","      <td>0.025578</td>\n","      <td>10.269109</td>\n","      <td>2.393034</td>\n","      <td>6276.344750</td>\n","      <td>17.6550</td>\n","      <td>146.917382</td>\n","      <td>NaN</td>\n","      <td>51.216883</td>\n","      <td>257.432377</td>\n","      <td>52.347341</td>\n","      <td>0.651957</td>\n","      <td>90.347488</td>\n","      <td>8.092101</td>\n","      <td>0.018706</td>\n","      <td>1.050225</td>\n","      <td>0.593100</td>\n","      <td>26.370438</td>\n","      <td>1.263393</td>\n","      <td>7.030640</td>\n","      <td>48.87054</td>\n","      <td>150.224537</td>\n","      <td>0.238680</td>\n","      <td>0.418149</td>\n","      <td>127.985528</td>\n","      <td>99.96224</td>\n","      <td>12.883712</td>\n","      <td>0.931095</td>\n","      <td>1.74307</td>\n","      <td>69.778728</td>\n","      <td>4.926396</td>\n","      <td>0.955347</td>\n","      <td>1103.108213</td>\n","      <td>0.237276</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>78.526968</td>\n","      <td>36.676020</td>\n","      <td>35.734272</td>\n","      <td>4.001538</td>\n","      <td>6730.643885</td>\n","      <td>9.162606</td>\n","      <td>4.764967</td>\n","      <td>0.49706</td>\n","      <td>0.704392</td>\n","      <td>12.027486</td>\n","      <td>212.210348</td>\n","      <td>9146.473587</td>\n","      <td>17.287766</td>\n","      <td>30.712252</td>\n","      <td>0.171600</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>603</th>\n","      <td>f96e7ca4a16c</td>\n","      <td>0.662315</td>\n","      <td>1704.39874</td>\n","      <td>123.807144</td>\n","      <td>68.353887</td>\n","      <td>8.138688</td>\n","      <td>5.563452</td>\n","      <td>0.104139</td>\n","      <td>6.736838</td>\n","      <td>1.229900</td>\n","      <td>4949.693140</td>\n","      <td>19.0674</td>\n","      <td>672.424092</td>\n","      <td>NaN</td>\n","      <td>573.106456</td>\n","      <td>257.432377</td>\n","      <td>159.454659</td>\n","      <td>0.499747</td>\n","      <td>206.714672</td>\n","      <td>6.980615</td>\n","      <td>0.036616</td>\n","      <td>1.228445</td>\n","      <td>0.819225</td>\n","      <td>28.589913</td>\n","      <td>1.202706</td>\n","      <td>36.250024</td>\n","      <td>56.76052</td>\n","      <td>310.312515</td>\n","      <td>0.238680</td>\n","      <td>0.240504</td>\n","      <td>104.606760</td>\n","      <td>105.26648</td>\n","      <td>24.887128</td>\n","      <td>0.689700</td>\n","      <td>1.74307</td>\n","      <td>15.802856</td>\n","      <td>8.106996</td>\n","      <td>2.265422</td>\n","      <td>1515.781550</td>\n","      <td>0.133848</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>92.328509</td>\n","      <td>46.912896</td>\n","      <td>26.663616</td>\n","      <td>3.182232</td>\n","      <td>12454.802560</td>\n","      <td>10.006095</td>\n","      <td>5.781491</td>\n","      <td>1.56600</td>\n","      <td>0.067730</td>\n","      <td>12.073996</td>\n","      <td>72.611063</td>\n","      <td>2369.417670</td>\n","      <td>19.367805</td>\n","      <td>25.591400</td>\n","      <td>0.130680</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>fe1942975e40</td>\n","      <td>0.363205</td>\n","      <td>1263.53524</td>\n","      <td>85.200147</td>\n","      <td>23.685856</td>\n","      <td>8.138688</td>\n","      <td>7.981959</td>\n","      <td>0.025578</td>\n","      <td>7.524588</td>\n","      <td>1.229900</td>\n","      <td>4517.865600</td>\n","      <td>19.0674</td>\n","      <td>119.162529</td>\n","      <td>NaN</td>\n","      <td>722.377629</td>\n","      <td>257.432377</td>\n","      <td>12.499760</td>\n","      <td>0.602254</td>\n","      <td>122.939496</td>\n","      <td>2.964975</td>\n","      <td>0.022288</td>\n","      <td>1.050225</td>\n","      <td>0.583125</td>\n","      <td>34.367872</td>\n","      <td>1.428903</td>\n","      <td>36.699352</td>\n","      <td>51.04140</td>\n","      <td>112.196630</td>\n","      <td>0.532818</td>\n","      <td>0.549333</td>\n","      <td>113.526045</td>\n","      <td>96.97092</td>\n","      <td>27.104928</td>\n","      <td>0.510378</td>\n","      <td>1.74307</td>\n","      <td>38.271840</td>\n","      <td>10.078968</td>\n","      <td>1.628524</td>\n","      <td>1318.962875</td>\n","      <td>0.139932</td>\n","      <td>B</td>\n","      <td>NaN</td>\n","      <td>99.706633</td>\n","      <td>8.259384</td>\n","      <td>38.133312</td>\n","      <td>6.192291</td>\n","      <td>6464.250832</td>\n","      <td>8.026928</td>\n","      <td>9.256996</td>\n","      <td>0.78764</td>\n","      <td>0.670527</td>\n","      <td>24.594488</td>\n","      <td>72.611063</td>\n","      <td>1965.343176</td>\n","      <td>25.116750</td>\n","      <td>37.155112</td>\n","      <td>0.184622</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Id        AB           AF          AH          AM         AR  \\\n","8    0594b00fb30a  0.346113   3238.43674   85.200147   28.888816   8.138688   \n","15   07760b4cf3f8  0.666588   3657.78160  304.283751   75.418144   8.138688   \n","18   0b2cc0b0e6c5  0.269199   1586.67784   85.200147   14.459893   8.138688   \n","23   0cf6c827b8bb  0.371751   2354.54142  105.030540    5.150311   8.138688   \n","24   0d1b855c7635  0.158101   3257.64549  138.368592    8.640630  18.385464   \n","45   12d002d52230  1.491277   2434.32640  137.149332  124.242349   8.138688   \n","46   1319c3883fff  0.243561   3316.81570   85.200147   13.406913   8.138688   \n","48   135f1d1da85e  0.820416   3594.95356  134.214399   54.129366   8.138688   \n","64   1899e6e0d7d9  0.512760   3756.02392   85.200147   25.674130   8.138688   \n","71   1a6d2336590f  0.602493   5557.12344  100.797966   46.904065   8.138688   \n","88   228524bde6a3  0.346113   4088.28992   85.200147   44.401689   8.138688   \n","114  2e4e80b95e24  0.170920   1963.64850   85.200147   22.574033   8.138688   \n","119  2fd659800f75  0.405935   1011.87218   91.122267   69.840447   8.138688   \n","125  321f58c2e5d1  0.499941   4402.36962  149.925435   24.107048   8.138688   \n","128  332a3850302f  0.529852   3287.77933   85.200147   22.632876   8.138688   \n","153  3d4109150b32  0.564036   4535.53254   95.424513   42.016999   8.138688   \n","166  41475fa34ab3  0.269199   2045.32350   93.473697   23.143881   8.138688   \n","177  4537a9a3ecde  0.452938   2379.68401   92.472162   41.992223   8.138688   \n","178  4572189340c4  0.397389   2306.39794   85.200147   75.247809   8.138688   \n","196  4bc8f3ea493a  0.611039   1614.33602   92.419908   35.751768   8.138688   \n","231  5d547eb551a9  0.358932   2975.21818  132.881922   23.335895   8.364180   \n","233  5d8a1a0fb062  0.341840   5198.94892   85.200147   89.209085   8.138688   \n","235  5e27b0147126  0.354659   4825.98336  132.350673   14.741720   8.138688   \n","236  5ee622a3e3be  0.401662   2667.06869   85.200147   21.369300   8.138688   \n","244  619aac34f423  0.658042   3283.64718   85.200147   56.331333   8.526744   \n","253  65c5772a4afa  0.307656   4054.55754  129.145761   56.408758   8.138688   \n","263  684d62aeae9e  0.282018   4374.06530  116.326113   46.993878   8.138688   \n","264  6850ef5b0092  0.461484   2184.24239  128.170353   12.790610   8.138688   \n","266  6860e7cbccad  0.499941   4714.33666  103.454211   17.882078   8.138688   \n","272  69de76778344  0.572582   4098.12238  139.283037    9.414880   8.138688   \n","279  6c6db7987cd5  0.354659   1821.33072  114.183699  108.692312   8.138688   \n","281  6ef1fe86ad00  0.585401   2487.50590  113.121201  149.318758   8.138688   \n","283  7017fab77607  0.235015   3572.32172   85.200147   32.258352   8.138688   \n","285  70926a82d4e1  0.282018   2670.85115  113.896302  121.510795   8.138688   \n","289  73468ffe1cb5  0.196558   3807.68971   85.200147   11.353602   8.138688   \n","304  79b44ed25c29  0.948606   6192.61907   99.857394   29.179934   8.138688   \n","305  7a5c4b008308  0.414481   2028.57468  100.127373    9.798908   8.138688   \n","316  7e4d70590a71  0.623858   4258.45706   85.200147    8.337124   8.138688   \n","330  81015c6c3404  6.161666  18964.47278  210.557493   85.393581   8.138688   \n","341  860833bfe713  0.376024   2967.65810   85.200147   34.262111   8.138688   \n","356  8b9d72eec14e  4.277273   7314.15234   85.200147  630.518230  59.390922   \n","358  8ba2487388f2  0.568309   3703.32116  123.807144   13.747583   8.138688   \n","363  8d7e1ef24fb8  0.401662   3863.57114  135.546876    9.340552   8.138688   \n","364  8d7f231c9cb7  0.333294   2950.68664  153.435162   14.221424   8.138688   \n","369  8eefb589a7aa  0.405935    192.59328   85.200147   12.357030   8.138688   \n","375  91275f6ae0a2  0.474303   2465.48390  160.306563   14.608549  11.636436   \n","422  a7b1c7b83f53  0.636677    562.28579  291.368304   99.410603   8.138688   \n","449  b10bae274dfc  0.470030    192.59328  139.378836   85.523655   8.138688   \n","458  b358f0fdb95b  0.081187   1365.55760   85.200147    7.408024   8.138688   \n","469  ba0c42e12f1f  0.730683   2591.80911  191.380275   16.553465   8.138688   \n","471  bbb1066a9afd  0.264926   1390.03590   85.200147   11.601362  10.217934   \n","490  c5f4dc4ae7fb  0.474303   4877.54146   85.200147   34.996100   8.138688   \n","492  c6c3a77ec885  0.589674   5782.60210  124.660626   34.311663   8.138688   \n","507  cd5d5458c163  0.538398   3925.42513  176.505303   37.256910   8.138688   \n","516  d0ecfae80796  0.440119    975.50805   85.200147  121.197998   8.138688   \n","517  d10976c44b2b  0.316202   1624.69362  145.013559   14.147096   8.138688   \n","529  d44d3320d240  0.529852   2648.55448   85.200147   29.062248   8.138688   \n","537  d9d5fdfa030c  0.363205   1258.32256   85.200147   24.165891   8.138688   \n","562  e70b5934b571  0.478576   7643.98140  116.953161   33.645808   8.204238   \n","568  e9417cc82b93  0.602493   3719.52427  113.443434   28.071208   8.138688   \n","570  e9c343dc7736  0.190148   4376.46594   85.200147   13.411558   8.138688   \n","573  eada36b0bf31  0.337567   3440.63258   99.186801   31.000970  19.748904   \n","579  efcba7fac353  0.405935   5576.23055   91.723188   19.473936   8.138688   \n","582  f0d7d98bfe21  0.367478   3077.07598  324.349287   37.814370  28.689924   \n","583  f12d8570682a  0.282018   4226.17426   91.392246   13.704225   8.138688   \n","594  f46e39a96ee9  0.670861   5501.73569   93.822057    6.993026   8.138688   \n","602  f955c0ed8895  0.350386   5431.63797   85.200147   11.607556   8.138688   \n","603  f96e7ca4a16c  0.662315   1704.39874  123.807144   68.353887   8.138688   \n","615  fe1942975e40  0.363205   1263.53524   85.200147   23.685856   8.138688   \n","\n","            AX        AY         AZ         BC          BD        BN  \\\n","8     4.021986  0.025578   8.243016   3.626448  6569.370010  20.4798   \n","15   12.818973  0.025578   8.167392   1.229900  3597.873030  17.6550   \n","18    4.907886  0.032886   7.007824   3.521028  7125.170390  19.7736   \n","23   10.409325  0.025578  11.526358   2.754976  5435.445190  19.7736   \n","24    4.146012  0.182700   4.099451   7.836220  3633.584335  22.2453   \n","45    4.730706  0.025578   4.487024   1.229900  2734.489610  20.4798   \n","46    3.809370  0.025578  10.505434   4.258968  3042.040690  18.3612   \n","48    7.565586  0.025578   6.428040   1.229900  5910.131090  21.1860   \n","64    7.973100  0.025578   7.310320   1.229900  6323.086250  18.0081   \n","71    5.767209  0.025578  12.389732   9.347240  7900.152450  18.7143   \n","88    4.526949  0.025578   3.396778   1.229900  5677.414350  20.8329   \n","114   2.595687  0.029232   3.396778   1.229900  7958.583320  20.1267   \n","119   6.573378  0.025578   7.398548   1.229900  3204.013970  18.0081   \n","125   6.046267  0.025578  10.297468   1.229900  3237.763730  20.1267   \n","128   8.726115  0.025578  15.238236   1.229900  3956.416290  19.0674   \n","153   5.253387  0.038367   7.953124   1.229900  5120.543310  20.4798   \n","166   9.009603  0.025578  10.971782   1.229900  4136.207270  20.4798   \n","177   7.220085  0.025578   6.302000   1.229900  2211.528130  19.7736   \n","178   6.281031  0.025578   3.396778   1.229900  3872.641140  22.2453   \n","196   6.679686  0.025578   8.129580  28.287700  7027.852190  20.1267   \n","231   7.760484  0.067599  11.526358   3.767008  8027.792700  19.0674   \n","233   9.487989  0.025578   5.098318   6.486844  3306.142150  18.3612   \n","235   4.225743  0.025578   9.944556   1.229900  4397.887760  20.4798   \n","236   5.900094  0.025578   9.367923   1.229900  2261.889100  19.0674   \n","244   6.068415  0.025578   9.872083   1.229900  5111.015235  21.1860   \n","253   4.934463  0.025578   6.642308   1.229900  6417.591970  18.3612   \n","263   7.104918  0.057246   8.602230   1.229900  3577.442600  18.7143   \n","264   7.671894  0.031973   6.755744   2.540622  4180.511820  20.8329   \n","266  11.250930  0.025578  14.513506   1.229900  7849.080370  19.7736   \n","272   4.881309  0.025578  10.833138   1.229900  5208.481250  20.8329   \n","279   4.296615  0.025578   7.486776   1.229900  4556.401370  19.4205   \n","281   8.017395  0.055419   6.295698   1.229900  5102.046460  20.4798   \n","283   4.704129  0.073385   6.232678   1.229900  5828.585150  18.0081   \n","285   6.661968  0.025578   8.706213   1.229900  4367.541740  21.1860   \n","289   7.525721  0.042630   8.992954   1.229900  3643.559850  18.3612   \n","304   3.632190  0.025578   7.404850   7.920556  5663.431850  23.6577   \n","305   8.500210  0.060595   7.719950   2.712808  5748.972790  17.6550   \n","316   8.531217  0.025578   9.553832   1.229900  5667.322980  19.4205   \n","330  17.983770  0.032886   8.866914   6.767964  7259.050830  19.0674   \n","341   5.643183  0.025578   9.200920   1.229900  3985.204260  20.4798   \n","356   6.936597  0.025578  18.805168   4.649022  5287.366520  29.3073   \n","358   7.078341  0.101703  10.417206   4.441696  4647.798980  19.4205   \n","363   5.377413  0.025578  10.807930   3.745924  3380.936540  18.7143   \n","364  11.995086  0.025578  12.200672   1.229900  3528.895360  18.0081   \n","369   6.387339  0.025578   6.402832   1.229900  6287.195170  18.7143   \n","375   4.128294  0.112056   6.144450   6.290060  4251.654780  20.8329   \n","422   7.082770  0.068513   4.783218   1.229900  4463.301890  18.0081   \n","449   6.369621  0.031364   3.396778   1.229900  6605.133250  18.0081   \n","458   3.003201  0.025578   6.840821   2.255988  4394.356180  18.3612   \n","469   7.042905  0.119059  10.650380   1.229900  4611.963830  20.8329   \n","471   5.660901  0.074907   3.396778   3.113404  4906.738900  24.3639   \n","490   5.864658  0.025578   3.396778   5.081244  3877.099560  20.1267   \n","492  12.393741  0.025578  11.526358   1.229900  6640.848550  19.0674   \n","507   7.069482  0.025578  15.124800   1.229900  7006.774570  21.1860   \n","516   4.978758  0.035322   3.396778   3.953250  3932.869760  21.8922   \n","517   7.206797  0.025578  11.400318   1.229900  5012.662330  19.4205   \n","529   6.289890  0.025578   7.827084   7.165046  5169.545980  18.7143   \n","537   5.669760  0.025578  10.448716   1.229900  6999.863220  19.7736   \n","562   8.876718  0.025578  11.828854   1.229900  5883.875950  18.0081   \n","568   7.211226  0.025578  11.148238   1.229900  4290.430250  20.4798   \n","570   4.996476  0.088305   3.396778   1.229900  6326.889490  21.5391   \n","573   7.849074  0.025578   7.801876   1.229900  6404.024950  20.1267   \n","579  10.816839  0.066685  10.202938   2.920134  4741.074240  20.4798   \n","582   6.803712  0.025578  10.121012   1.229900  5901.933350  21.1860   \n","583   4.916745  0.025578   9.415188   1.229900  6144.797390  18.0081   \n","594   6.511365  0.025578   9.541228   1.229900  4126.619270  20.4798   \n","602   7.565586  0.025578  10.269109   2.393034  6276.344750  17.6550   \n","603   5.563452  0.104139   6.736838   1.229900  4949.693140  19.0674   \n","615   7.981959  0.025578   7.524588   1.229900  4517.865600  19.0674   \n","\n","              BP          BQ           BR           BZ           CB        CC  \\\n","8     135.881145         NaN   601.802912   257.432377   116.100712  0.855496   \n","15    227.744514         NaN   842.371642   257.432377    20.578649  0.651609   \n","18    176.541633         NaN   700.704062   257.432377    23.317567  0.574937   \n","23    114.529302         NaN   220.658446   257.432377   134.694105  0.780432   \n","24    170.308184   30.010903   355.723543  2568.243295          NaN       NaN   \n","45    129.378519         NaN  2148.501967   257.432377    94.262896  0.715257   \n","46    122.748723         NaN   366.787164   257.432377    38.234560  0.650385   \n","48    154.960884         NaN  1144.743005   257.432377    14.007084  0.669528   \n","64    143.854704         NaN   910.350304   257.432377    12.499760  0.924166   \n","71    136.741662         NaN   974.971771   257.432377    12.646816  0.629668   \n","88    446.659191   87.791105   790.961191   257.432377    34.484632  0.708965   \n","114   337.068324   71.384815   366.357685   257.432377          NaN       NaN   \n","119   186.299811         NaN  1520.766992   257.432377    14.650454  0.707478   \n","125   195.625611         NaN  1623.705850   257.432377    19.301100  0.715342   \n","128   203.118043         NaN   846.826731   257.432377    32.981904  0.952232   \n","153   177.999849         NaN  1002.984690   257.432377    12.499760  0.853483   \n","166   148.424346         NaN   333.538836   257.432377    60.908757  0.781478   \n","177   105.559578         NaN  3466.745415   257.432377    20.165054  0.558321   \n","178   206.918307  344.644105   450.015355   257.432377   768.900678  0.578083   \n","196   199.631466         NaN  1642.784396   257.432377    15.054858  0.674647   \n","231   715.606785         NaN   747.940703   257.432377    12.499760  0.637967   \n","233   156.597138         NaN   849.684883   257.432377    42.186690  0.801463   \n","235   161.260038         NaN   946.214825   257.432377    21.626423  0.567021   \n","236   169.089471         NaN   684.770996   257.432377    12.499760  0.456729   \n","244   255.921147         NaN   528.398297   257.432377    14.581521  0.612092   \n","253   168.864804         NaN  1185.960891   257.432377    32.003062  0.642823   \n","263   130.141539         NaN   682.599405   257.432377    12.499760  0.863973   \n","264   166.050108         NaN  1043.918273   743.648493    43.602104  0.471727   \n","266   154.820997         NaN  2796.473872   257.432377    14.774532  1.538831   \n","272   160.047684         NaN  1108.993415   257.432377    13.336141  0.736025   \n","279   130.251753         NaN   730.652661   257.432377    16.672474  0.583065   \n","281   145.639323         NaN  2128.364846   257.432377    12.499760  0.587263   \n","283   115.644159         NaN   587.566590  1387.831083    12.499760  0.691389   \n","285   177.853603         NaN   429.182599   257.432377    19.052943  0.506868   \n","289   125.440488         NaN   330.753271   257.432377    19.668740  1.087353   \n","304   203.141358   55.832965  2083.027591   738.131262    19.135662  0.280565   \n","305   160.018011         NaN   690.538717   840.323779    12.499760  0.675740   \n","316   146.894067         NaN  2026.372657   257.432377    32.287983  1.002021   \n","330  1027.410669  344.644105   740.681903  1510.069965   536.221322       NaN   \n","341    86.128002         NaN   672.152782   257.432377    25.312014  0.651122   \n","356   173.328471         NaN   515.574417   257.432377    47.379605  0.340140   \n","358   192.671028         NaN   942.174093  1215.877383    12.499760  0.760716   \n","363   134.804439         NaN  1652.320644   257.432377    13.667017  0.652089   \n","364   281.007549         NaN  1295.239101   257.432377    21.460985  0.753109   \n","369   196.626015         NaN   939.669807   257.432377    12.499760  0.634650   \n","375   134.376300         NaN  1805.239364  1146.389288    17.692675  0.649601   \n","422   237.087270         NaN    51.216883  1296.856509   235.611285  0.344036   \n","449   280.405611         NaN  1889.783213   257.432377  1467.150139  0.512770   \n","458   118.797975         NaN   555.113706   257.432377    15.353566  0.532565   \n","469   327.471228         NaN  2458.132130   257.432377    46.662707  0.855799   \n","471   381.861837    9.492620   198.310416   595.886550    70.853419  0.289390   \n","490   266.603427  344.644105   478.566635   257.432377    67.489513  0.410217   \n","492   207.575352         NaN   732.031833   257.432377    21.286356  0.898593   \n","507   196.062228         NaN   590.648556   257.432377    51.589083  0.626385   \n","516   239.219487  178.906190  1325.220969   257.432377    34.080228  0.520555   \n","517   175.748940         NaN   590.182783   257.432377    64.079652  0.644133   \n","529   106.619328         NaN   838.914639   257.432377    12.499760  0.600247   \n","537   140.260032         NaN  1641.601816   257.432377    12.784681  0.679721   \n","562   205.180317         NaN   996.999205   257.432377    15.165150  0.899028   \n","568   278.731206         NaN   819.609255   257.432377    29.264144  0.572220   \n","570   174.345831         NaN   211.944862  1227.771646    12.499760  0.632591   \n","573   164.680911         NaN   842.190172   257.432377    24.622689  0.648720   \n","579   145.656279         NaN   524.820313   257.432377    17.665102  0.732696   \n","582   239.367852         NaN  1197.266472   953.234999    23.409477  0.534980   \n","583   100.684728         NaN  2246.834511   257.432377    29.052751  0.889808   \n","594   138.076947         NaN   862.898924   257.432377    27.609764  0.761854   \n","602   146.917382         NaN    51.216883   257.432377    52.347341  0.651957   \n","603   672.424092         NaN   573.106456   257.432377   159.454659  0.499747   \n","615   119.162529         NaN   722.377629   257.432377    12.499760  0.602254   \n","\n","            CD          CF        CH        CL        CR         CS        CU  \\\n","8     93.225352  14.566390  0.033830  1.050225  1.050375  29.914973  1.473039   \n","15   373.115464   6.925878  0.051342  1.050225  0.768900  13.784111  1.953018   \n","18    67.094664  35.649643  0.033432  1.050225  0.621375  33.660011  1.903365   \n","23    56.891328   6.659790  0.023880  1.050225  0.571237  33.109065  1.125468   \n","24    49.688740  11.840134  0.026069  1.050225  0.731025  57.192031  1.299254   \n","45   210.837232  10.924793  0.044974  1.196620  3.039675  22.717805  1.081332   \n","46    85.471768  15.300792  0.018308  1.050225  0.895950  32.474431  1.130985   \n","48   137.867920   2.721695  0.023482  1.050225  0.944475  34.552683  1.037196   \n","64    87.984944  20.713772  0.026666  1.050225  0.921150  39.096244  3.210894   \n","71    83.759320  18.995607  0.027064  1.304825  0.673875  38.946303  1.837161   \n","88    70.884248   4.268044  0.025870  1.050225  0.634725  49.860613  1.164087   \n","114   60.783976  20.943367  0.031442  1.050225  0.841800  36.679753  1.655100   \n","119  385.388008  30.986269  0.029850  1.050225  1.360200  13.784111  1.826127   \n","125   68.307648   9.585232  0.023482  1.050225  0.537150  19.516739  0.982026   \n","128  126.475384   8.484390  0.026666  1.050225  0.620625  37.532325  2.124045   \n","153   76.013664   9.077385  0.029850  1.050225  0.616275  34.594527  1.368216   \n","166   52.190024  13.140161  0.027462  1.050225  0.470288  18.543866  1.164087   \n","177   96.237992  10.500573  0.033034  1.050225  0.867975  13.784111  0.976509   \n","178  139.794424  30.714100  0.035024  1.050225  0.913275  27.829747  1.340631   \n","196  140.745784  10.573557  0.020298  1.457585  0.675300  31.388230  1.688202   \n","231   91.933088   2.441923  0.023482  1.763105  0.774075  74.077828  2.223351   \n","233  116.319616  14.976925  0.023482  1.050225  0.647175  31.491097  0.926856   \n","235   48.947472   1.783546  0.023880  1.228445  0.720600  13.784111  1.186155   \n","236   92.234352  13.663213  0.020298  1.050225  0.747975  13.784111  2.267487   \n","244  128.235400  19.383334  0.039402  1.050225  1.348275  29.571503  1.875780   \n","253  100.122712   6.034865  0.030646  1.050225  1.259100  29.175729  1.020645   \n","263  109.231984   0.510888  0.029054  1.132970  0.812325  37.126089  3.503295   \n","264   69.068736  32.900579  0.029850  1.050225  0.538613  29.384949  1.649583   \n","266   89.911448  14.937392  0.032636  1.225262  0.627075  44.087885  1.616481   \n","272  118.904144   1.540266  0.021094  1.432125  0.725850  37.457354  1.815093   \n","279  275.759624   2.055716  0.024278  1.514870  0.862200  35.961431  1.445454   \n","281   87.699536  13.752923  0.032238  1.050225  0.753150  38.451149  1.279944   \n","283   99.615320  16.117300  0.028258  1.050225  0.730875  35.101886  1.776474   \n","285  189.415776   4.144883  0.046566  1.050225  0.652050  18.488074  1.406835   \n","289   51.809480  10.923272  0.017114  1.050225  0.552937  35.882973  1.048230   \n","304  100.550824   4.188978  0.038208  1.521235  0.445875  31.876410  1.605447   \n","305   79.287928  11.987622  0.025870  1.050225  0.471000  37.094706  1.197189   \n","316   65.009600  21.144073  0.031840  1.050225  0.669825  36.432176  1.997154   \n","330  633.534408  50.082229  0.082386  2.195925  0.665475  46.868767  1.164087   \n","341   55.543568  19.165903  0.039402  1.050225  0.571125  29.426793  1.026162   \n","356   91.370200   4.731796  0.121788  1.050225  0.853425  68.437606  1.015128   \n","358   26.820424   1.651263  0.032238  1.050225  0.808350  45.324026  1.119951   \n","363  107.693952  11.196962  0.023482  1.050225  0.717525  30.507763  1.015128   \n","364   31.783352  27.548419  0.024676  1.190255  0.590100  13.784111  1.517175   \n","369   38.323952  12.715941  0.024278  1.050225  0.718575  26.647654  2.046807   \n","375  112.807512   7.190444  0.031840  1.177525  0.679575  41.572014  1.693719   \n","422  135.370600   4.512844  0.047362  1.050225  0.699975  34.897896  0.739278   \n","449  179.038024  12.553248  0.045372  1.050225  1.275000  19.483612  0.706176   \n","458   44.373016   7.842739  0.012338  1.050225  0.447150  17.121170  0.777897   \n","469   85.773032  19.568835  0.043382  1.145700  0.637200  28.556787  1.268910   \n","471   99.789736   2.423677  0.025870  1.050225  0.576450  38.686521  1.456488   \n","490  146.604576   4.643607  0.027462  1.050225  0.888900  37.024966  1.616481   \n","492   32.845704  29.242256  0.023482  1.444855  0.571200  59.482990  1.621998   \n","507  131.763360  22.057893  0.044178  1.686725  0.959025  55.167827  0.877203   \n","516  161.754984  10.667828  0.032636  1.050225  0.715125  44.093115  1.964052   \n","517   77.424848  17.315454  0.021890  1.438490  0.581400  29.020557  1.329597   \n","529  102.334624   5.309586  0.034228  1.050225  0.556575  19.070403  1.125468   \n","537   63.978960  13.828947  0.018308  1.101145  0.716625  39.828514  1.969569   \n","562   89.435768  28.153578  0.047760  1.050225  1.012500  31.376026  1.704753   \n","568  126.467456  15.332722  0.030248  1.101145  0.679350  25.547505  0.993060   \n","570   66.412856   6.696282  0.031243  1.050225  0.894825  36.027684  1.164087   \n","573  127.799360   1.914310  0.025074  1.152065  0.706050  38.702213  3.122622   \n","579   56.601956  16.266309  0.037412  1.050225  0.487725  35.773133  1.213740   \n","582   76.013664   0.510888  0.030248  4.372755  0.623775  45.261260  1.235808   \n","583  199.650824  12.843663  0.030646  1.050225  0.495225  32.160601  1.153053   \n","594   86.978088   9.116918  0.034626  1.050225  1.264050  25.673037  0.617904   \n","602   90.347488   8.092101  0.018706  1.050225  0.593100  26.370438  1.263393   \n","603  206.714672   6.980615  0.036616  1.228445  0.819225  28.589913  1.202706   \n","615  122.939496   2.964975  0.022288  1.050225  0.583125  34.367872  1.428903   \n","\n","           CW         DA           DE         DF        DH          DI  \\\n","8    43.015704  76.77356   231.134460   0.238680  0.330693  131.349555   \n","15    7.030640  24.32760   647.221725   0.238680  0.333426  117.818145   \n","18   36.658872  57.58308   176.650485   0.238680  0.475542  129.756960   \n","23   42.228736  30.65394   149.521590   0.238680  0.409950   96.227752   \n","24   36.817848  42.31334   356.052887   0.901017  0.379887  137.799000   \n","45   39.496704  32.13804   556.277615   0.238680  0.308829  264.318060   \n","46   34.569920  51.10348   802.970055   0.238680  0.396285  129.113145   \n","48   36.179552  35.39336   554.867285   0.238680  0.276033  125.378265   \n","64    7.030640  22.03840   740.605085   0.890838  0.445479  131.646990   \n","71    7.030640  48.38748   379.117105   0.632502  0.519270  158.856645   \n","88   42.802632  44.87996   278.615570   0.238680  0.174912  126.163268   \n","114  37.531400  32.63856   162.458485   0.238680  0.385353  157.260285   \n","119  36.216168  39.31992   332.766920   0.238680  0.374421  115.190175   \n","125  37.575192  38.00072  1030.960100   0.238680  0.440013  125.847008   \n","128  36.686472  57.00302   507.896200   0.238680  0.478275  130.468545   \n","153  36.122328  44.28632   258.489540   0.238680  0.303363  156.349155   \n","166  41.793760  42.00294   220.707775   0.238680  0.251436  119.952900   \n","177   7.030640  25.15016   696.312740   0.238680  0.295164   93.140452   \n","178  36.162256  36.34396   136.930625   0.238680  0.254169  139.007565   \n","196   7.030640  69.72166   287.352520   0.238680  0.245970  100.734458   \n","231  45.734856  70.10384  1590.643795   0.656370  0.418149  100.427610   \n","233   7.030640  37.13936   571.303395   0.238680  0.235038  101.549580   \n","235   7.030640  42.38512   390.306610   0.238680  0.420882  108.876270   \n","236   7.030640  27.16194   248.005200   0.238680  0.472809  134.169540   \n","244  35.728200  26.80304   444.732930   0.238680  0.554799  152.902298   \n","253  37.820464  54.74292   369.688295   0.238680  0.265101  150.765660   \n","263   7.030640  49.43508   291.752040   0.238680  0.308829  142.102395   \n","264   7.030640  64.03552   162.023855   0.238680  0.587595   72.641910   \n","266   7.030640  45.04874   217.008985   0.866619  0.459144  169.489005   \n","272   7.030640  54.51012   729.539760   0.238680  0.429081  136.586670   \n","279  36.476528  28.30848   134.553465   0.238680  0.418149  189.582810   \n","281   7.030640  45.19424   257.039295   0.238680  0.467343  144.203265   \n","283  38.886560  45.40764   120.330420   0.238680  0.456411  126.647070   \n","285   7.030640  23.50310   314.006870   0.238680  0.399018  102.411765   \n","289   7.030640  41.57614   219.040215   0.238680  0.330693  112.972590   \n","304  38.942772  24.13554    66.014975   0.378729  0.196776  178.688783   \n","305  45.507248  44.47450   255.132245   0.421551  0.478275  104.810070   \n","316   7.030640  53.64100   312.760635   0.238680  0.538401  121.598205   \n","330   7.030640  23.91632   416.264665   0.556686  0.314295  311.516100   \n","341   7.030640  45.34556   263.447870   0.238680  0.336159  115.882935   \n","356   7.030640  11.63806   292.239890  37.895013  0.204975  654.364530   \n","358   7.030640  46.88592   137.711185   0.791154  0.407217  113.672880   \n","363   7.030640  60.75692   228.371455   0.238680  0.374421  150.328920   \n","364   7.030640  61.60082   570.797805   0.238680  0.371688   99.623783   \n","369   7.030640  65.60692   768.079910   0.238680  0.513804  180.674820   \n","375   7.030640  51.63892   167.669610   0.455598  0.557532  161.518500   \n","422  45.362440  46.22438   437.911900   0.441909  0.349824   60.232470   \n","449  41.185088  31.42218   340.696700   0.238680  0.172179   68.080613   \n","458   7.030640  16.56372   213.684953   0.238680  0.180378  132.951562   \n","469  40.887744  10.68358   128.379945   0.434889  0.248703   74.225093   \n","471   7.030640  57.63352   267.661120   0.238680  0.338892  140.918303   \n","490  36.072648  67.34516   118.316930   0.238680  0.333426   99.508950   \n","492   7.030640  41.71970   182.522425   0.238680  0.486474   94.371607   \n","507  41.413156  38.13458   240.212905   0.734994  0.276033  117.281633   \n","516  33.788656  33.67840   136.136760   0.238680  0.271933  116.022240   \n","517   7.030640  35.21682   615.662265   0.238680  0.338892  118.985295   \n","529  36.343496  18.77920   228.974615   0.238680  0.401751   97.180297   \n","537  36.172928  44.00696   155.420140   0.238680  0.401751  146.752170   \n","562   7.030640  77.31482   573.516460   0.238680  0.349824  127.814220   \n","568   7.030640  45.36302   427.675920   0.238680  0.207708   74.588415   \n","570  42.731608  58.14374   592.555915   0.238680  0.274666   93.765443   \n","573  36.806256  68.30740   909.387880   1.239030  0.513804  173.570265   \n","579  41.239920  77.94532   448.946180   0.760617  0.327960  149.547683   \n","582  43.414984  37.21696  2052.389385   2.681640  0.661386  182.094225   \n","583   7.030640  43.73924   149.898565   0.238680  0.399018  142.354650   \n","594   7.030640  46.60656   308.019620   0.238680  0.204975   80.990797   \n","602   7.030640  48.87054   150.224537   0.238680  0.418149  127.985528   \n","603  36.250024  56.76052   310.312515   0.238680  0.240504  104.606760   \n","615  36.699352  51.04140   112.196630   0.532818  0.549333  113.526045   \n","\n","            DL         DN         DU       DV         DY         EB  \\\n","8     98.16872  29.466032   0.613833  1.74307   7.200676  10.771632   \n","15    75.31724  15.927216   0.268983  1.74307   6.446020   4.926396   \n","18    85.36710  21.386416   0.372438  1.74307  17.932064   6.241044   \n","23    95.75828  21.270408   0.600039  1.74307  27.686442   4.926396   \n","24    77.89940  15.988632   0.005518  1.74307  23.394336  15.429444   \n","45   102.47868  18.820592   0.151734  1.74307  39.264572   7.089204   \n","46    71.35708  29.186248   0.558657  1.74307  12.977388   4.926396   \n","48    99.68664  27.296000   0.834537  1.74307  46.096904   9.442848   \n","64    84.63676  26.477120   1.069035  1.74307  22.549840   4.926396   \n","71    94.98448  13.668472   0.524172  1.74307  47.610708   6.149160   \n","88    50.68072  20.806376  17.083869  1.74307  64.707260   9.403974   \n","114  128.93628  18.847888   0.005518  1.74307  29.166556   9.032904   \n","119   98.16872  22.580616   0.289674  1.74307  23.556048   6.824154   \n","125   99.13544  22.280360   0.434511  1.74307  62.494950   4.926396   \n","128  125.68632  23.222072   0.800052  1.74307  79.279308  10.665612   \n","153   88.92976  13.047488   0.262086  1.74307  38.487456   8.580552   \n","166  100.42652  22.846752   0.689700  1.74307  18.727148   4.926396   \n","177   92.08008  24.914424   0.662112  1.74307  36.533436   4.926396   \n","178   67.77852  31.233448   0.737979  1.74307  12.087972  10.135512   \n","196  148.88972  17.155536   3.489882  1.74307  16.557512   5.756886   \n","231   87.41396  28.824576   3.462294  1.74307  34.592892   8.969292   \n","233   80.39252  19.775952   2.034615  1.74307   8.606672   4.926396   \n","235   91.17696  12.221784   1.082829  1.74307  49.861200  10.637340   \n","236  123.91188  28.606208   0.496584  1.74307  57.821024   4.926396   \n","244  113.72528  34.379312   0.800052  1.74307  47.278300   8.326104   \n","253   66.73972  29.506976   0.531069  1.74307  27.239488   8.743116   \n","263  102.64828  13.368216   0.337953  1.74307  28.416392  11.549112   \n","264  115.42552  24.743824   0.744876  1.74307  34.476100   6.643920   \n","266  145.55708  26.238280   0.372438  1.74307  44.659464   7.767732   \n","272   88.92764  17.271544   0.786258  1.74307  24.211880   7.513284   \n","279   91.72180  23.979536   0.296571  1.74307  30.752232   9.075312   \n","281   97.14900  23.556448   1.655280  1.74307  35.221772   7.675848   \n","283  120.20188  17.135064   0.841434  1.74307  28.645484   6.827688   \n","285  122.97484  15.019624   0.696597  1.74307  15.757936   4.926396   \n","289  112.22008  14.384992   0.834537  1.74307  20.355498   6.802950   \n","304   93.19944  34.986648   0.779361  1.74307  17.190884  11.163906   \n","305   98.82592  14.903616   0.737979  1.74307  37.409376   6.237510   \n","316   74.61764  34.795576   0.344850  1.74307  33.389036   9.400440   \n","330   65.77300  62.808096   0.005518  3.04325  16.287992  27.713628   \n","341   63.08908  22.375896   1.655280  1.74307  19.117952   4.926396   \n","356   76.09104  12.719936   0.303468  1.74307   6.032756  14.019378   \n","358   84.01984  23.147008   0.937992  1.74307  37.674404  14.086524   \n","363  100.68092  14.794432   0.931095  1.74307  22.114116  10.503048   \n","364  100.53040  26.381584   0.717288  1.74307  32.607428   5.110164   \n","369   87.33976  19.830544   0.206910  1.74307  24.840760   8.382648   \n","375  109.47468  19.332392   1.282842  1.74307  19.315600  12.573972   \n","422   86.20556  18.561280   0.806949  1.74307  18.432922   6.163296   \n","449  108.27476  23.870352   0.620730  1.74307  49.021196   4.926396   \n","458   42.11804   6.339496   0.006897  1.74307  63.013776   4.926396   \n","469   91.03280  13.047488   4.565814  1.74307  43.473576   5.873508   \n","471   75.60556  27.275528   5.641746  1.74307  22.837328   8.951622   \n","490   71.43340  42.158672   5.634849  1.74307  19.131428   5.894712   \n","492  103.30336  18.929776   1.531134  1.74307  36.389692   8.184744   \n","507  131.53328  38.425944   1.420782  1.74307  14.181244  12.429078   \n","516   80.36178  17.315900   9.986856  1.74307  16.112804   6.364734   \n","517  116.77384  20.970152   0.496584  1.74307  27.017134   4.926396   \n","529  101.50772  17.810640   0.344850  1.74307  51.361528   4.926396   \n","537  109.94744  20.199040   1.517340  1.74307  13.799424   9.803316   \n","562  144.52040  15.592840   0.558657  1.74307  50.265480   6.806484   \n","568  120.62800  20.253632   0.675906  1.74307  26.803764   6.007800   \n","570   75.57270  19.086728   0.006897  1.74307  31.255336   6.891300   \n","573   79.11840  31.629240   0.620730  1.74307  19.782768  12.467952   \n","579  126.81840  24.266144   1.000065  1.74307  25.905364   9.128322   \n","582   84.63676  26.531712   2.013924  3.18311  13.732044   4.926396   \n","583   83.89688  18.288320   1.006962  1.74307  16.840508   4.926396   \n","594   89.26048  31.035552        NaN  1.74307  32.652348   5.523642   \n","602   99.96224  12.883712   0.931095  1.74307  69.778728   4.926396   \n","603  105.26648  24.887128   0.689700  1.74307  15.802856   8.106996   \n","615   96.97092  27.104928   0.510378  1.74307  38.271840  10.078968   \n","\n","            EE            EG        EH EJ          EL          EP          EU  \\\n","8     1.342323   3004.926575  0.066924  B         NaN   78.526968   56.610456   \n","15    3.115963    185.594100  0.006084  B         NaN   78.526968   41.357688   \n","18    3.970535   1389.371025  0.006084  B         NaN  102.487333   36.673488   \n","23    6.735801   8012.394450  0.121680  B         NaN   78.526968   21.775200   \n","24    1.130696    559.246525  0.003042  A   87.303431  304.176138   47.280036   \n","45    5.865105   1000.589825  0.006084  B         NaN  102.199994   41.383008   \n","46    6.497972   1470.425350  0.042588  B         NaN   78.526968    3.828384   \n","48    2.793483   1611.404325  0.097344  B         NaN   78.526968   10.274856   \n","64    3.196583   1692.073050  0.200772  B         NaN   79.815359   10.836960   \n","71    5.155649   1212.940950  0.048672  B         NaN   81.307668    8.391048   \n","88    0.286201   1091.675775  0.723996  B         NaN   78.526968   20.942172   \n","114   3.321544   1895.308350  0.003042  A  109.125159   78.526968   61.244016   \n","119   3.236893   1035.950550  0.060840  B         NaN   78.526968    7.160496   \n","125   8.424790   1268.379988  0.066924  B         NaN   78.526968   21.620748   \n","128   3.315498   1849.937088  0.182520  B         NaN  116.891359   12.637212   \n","153   2.914413  16845.249300  0.030420  B         NaN  106.528617   45.707664   \n","166   1.467284   2135.901663  0.054756  B         NaN   78.526968   13.305660   \n","177   4.172085    185.594100  0.066924  B         NaN   78.526968   14.483040   \n","178   2.636274   2023.472150  0.279864  B         NaN   96.267834   36.663360   \n","196   3.027281   2355.305050  0.894348  B  109.125159   78.526968    6.517368   \n","231   6.373011   1697.037650  0.352872  B         NaN  125.011003   15.541416   \n","233   5.425726   1078.264125  0.298116  B         NaN   90.808393    4.486704   \n","235   4.567123   1300.466125  0.212940  B         NaN  122.044923    7.449144   \n","236   2.809607    685.413037  0.048672  B         NaN   78.526968   42.730032   \n","244   2.966816   2079.131100  0.103428  B         NaN   78.526968   45.553212   \n","253   2.781390   2298.356750  0.121680  B         NaN   86.924682    6.380640   \n","263   1.039998   1432.479900  0.085176  B         NaN  147.071223   58.458816   \n","264   1.636586   1306.054313  0.109512  B         NaN   78.526968    4.382892   \n","266   4.694100    921.550862  0.060840  B         NaN   78.526968   31.558848   \n","272   3.176428   1051.248025  0.176436  B         NaN   78.526968    3.828384   \n","279   3.853636   1386.894750  0.048672  B         NaN  104.563589   48.067488   \n","281   3.382009   1723.595850  0.304200  B         NaN  110.560632   38.344608   \n","283   1.822012   1301.005363  0.225108  B         NaN  127.689744    3.828384   \n","285   3.944333    988.738650  0.152100  B         NaN   78.526968   12.771408   \n","289   2.571778   1621.074450  0.146016  B         NaN   80.695914    3.828384   \n","304   1.334261   3114.186938  0.152100  B         NaN  102.751499   11.280060   \n","305   8.098279   1817.609950  0.121680  B         NaN   94.237923   23.522280   \n","316   7.445257   2330.295275  0.024336  B         NaN   78.526968    7.702344   \n","330   6.360918   6845.912275  0.003042  A         NaN  110.708936  132.899616   \n","341   1.168990   1793.690700  0.352872  B         NaN   89.325353    4.927272   \n","356   5.284641   1233.916988  0.006084  B   44.720247   78.526968   89.830296   \n","358   2.555654   1821.821425  0.152100  B         NaN  159.667794   52.630152   \n","363  11.101374   1114.884075  0.115596  B         NaN   78.526968    5.438736   \n","364   4.563092   1462.827825  0.188604  B         NaN   78.526968   22.580376   \n","369   3.277203   1040.324700  0.006084  B         NaN   78.526968    3.828384   \n","375   1.777671   1497.610150  0.249444  B         NaN  170.086150   50.103216   \n","422   3.611776    796.794200  0.176436  B         NaN  115.607602    5.737512   \n","449   4.252705   1021.002525  0.170352  B   41.658903   78.526968   11.928252   \n","458   1.223408    442.885700  0.024336  B         NaN   78.526968  428.566320   \n","469   4.651774   2918.702800  0.456300  B   34.320000   78.526968    6.216060   \n","471   2.108213   1337.128250  0.523224  B         NaN  169.604162   20.055972   \n","490   3.394102   1740.026025  0.407628  B         NaN   78.526968   34.911216   \n","492   5.191928   1016.676575  0.048672  B         NaN   78.526968   22.856364   \n","507   3.865729   2383.158625  0.450216  B         NaN  193.272553   33.698388   \n","516   0.842479    698.746363  1.648764  B         NaN   98.598988   20.972556   \n","517   1.096432   1257.056000  0.030420  B         NaN   78.526968    4.686732   \n","529   1.688989    964.578400  0.036504  B         NaN  100.406442   14.900820   \n","537   2.741080   1557.498650  0.231192  B         NaN   78.526968    5.884368   \n","562   9.888043   1867.743975  0.006084  B  109.125159   78.526968    7.778304   \n","568   7.844326   1863.448150  0.121680  B  109.125159   78.526968    4.651284   \n","570   1.830074   1116.143300  0.024336  B         NaN  119.027863   22.699380   \n","573   3.325575   2755.124050  0.237276  B         NaN   95.739501   17.475864   \n","579   4.434100    811.199975  0.255528  B         NaN  124.876603   25.922616   \n","582   3.430381   1895.284250  0.438048  B         NaN  149.277245   84.194064   \n","583   3.091777   1905.701475  0.103428  B         NaN   91.790907    9.282312   \n","594   6.119058   4383.172438  0.006084  B   41.967354   78.526968    4.210716   \n","602   0.955347   1103.108213  0.237276  B         NaN   78.526968   36.676020   \n","603   2.265422   1515.781550  0.133848  B         NaN   92.328509   46.912896   \n","615   1.628524   1318.962875  0.139932  B         NaN   99.706633    8.259384   \n","\n","             FC        FD             FE         FI          FL        FR  \\\n","8     35.300160   1.389258   3380.026318  11.450501    4.762291   1.18262   \n","15    41.566224   2.719146   4143.635748   7.723713   67.872762   0.77720   \n","18    32.329920   3.312846   4170.630264  13.727370   97.303580   2.73702   \n","23    35.808528   2.493540   5709.501083   8.481751    4.648113   0.49706   \n","24   117.815712   0.296850  13173.694370  10.358927    0.173229   1.82323   \n","45    17.867136   0.486834   6448.462858   4.917596    9.126892   2.44238   \n","46    18.901008   3.449397   6946.192026   9.162606   17.726310   0.99586   \n","48    44.673552   1.525809   3060.890652   6.769964    4.192794   0.78474   \n","64    51.282336   3.271287   5845.233492   9.829679    4.932888   0.86014   \n","71    42.354480   4.316199   5136.721022   9.625698   18.799615   0.49706   \n","88    98.086464  12.301464   3740.069231  14.559833   20.563808   0.78909   \n","114   22.379616   0.296850   6342.797968  12.007314    0.173229   1.09620   \n","119   35.305872   1.674234   2842.486602   9.504412    4.336821   1.59732   \n","125   44.702112   1.128030   8145.464198   7.935963    3.253336   0.49706   \n","128   43.354080   3.449397   3613.990019   9.973017    4.949731   0.49706   \n","153  130.867632   1.110219   6157.759020  11.218955    5.470930   1.56078   \n","166   45.593184   0.902424   3455.444025   7.908398    4.007733   0.49706   \n","177   19.592160   0.789621   3353.604481   6.951893    2.811204   0.49706   \n","178   14.131488   6.049803   4688.721352  10.215589    5.437584   1.51496   \n","196   40.263888   8.489910   5401.684249  12.271938    5.192682   2.51111   \n","231   54.326832   6.584133   5809.502814   6.643165   10.166071   1.57412   \n","233   64.791216   5.378922   1563.136688   6.847146    7.536000   0.98194   \n","235   50.431248   2.903193   4209.198136   9.592620    4.154209   0.49706   \n","236   23.476320   0.884613   3160.705233   8.920034    3.750250   0.49706   \n","244   37.784880   1.199274   4224.993596   8.578228    3.036891   2.11816   \n","253   22.688064   2.167005   2036.483954   9.416204    3.800196   1.05328   \n","263   73.005072   3.900609  12440.489320   8.594767    7.795305   0.49706   \n","264   96.435696   3.841239   4661.397452   8.542393    8.864238   1.24352   \n","266   44.713536   1.175526   5446.749969   9.950965    3.452708   0.49706   \n","272   88.827312   6.103236   4229.155812  10.733811    8.981426   1.03472   \n","279   37.356480   0.374031   5073.352032  11.307163    1.225413   1.00398   \n","281   43.691088   4.791159   5781.445286   9.829679    5.933445   1.29804   \n","283  113.503152   5.076135   5016.031730   9.973017    6.056783   0.49706   \n","285   27.406176   3.811554   4230.574409   8.390786    6.124258   0.49706   \n","289   22.213968   3.663129   7925.319653   7.781599    6.710646   0.49706   \n","304   41.880384   2.950689  13797.341800   7.988337    5.014797   1.04371   \n","305   76.769280   4.090593   3376.320748   8.426621    8.456270   0.49706   \n","316   71.851248   1.151778   6540.929930  10.772402    8.138127   2.66336   \n","330         NaN   0.296850   5676.738604  12.768108    0.173229  54.94862   \n","341   26.098128   3.312846   4020.573394  10.132894    3.536792   1.65184   \n","356   53.350080   4.161837   6862.199106   7.326777  110.342316   0.87580   \n","358  137.270784   3.502830   5156.873334  11.020487    6.530993   1.72260   \n","363   74.158896   1.692045   8758.919440   9.498899    4.135765   1.03356   \n","364   44.570736   0.890550  16122.542060   9.984043    1.170965   0.49706   \n","369   32.775456   2.499477   3683.179374  11.213442   54.719291   0.87696   \n","375   53.829888   3.888735   3841.777770   9.327996    5.170251   1.19712   \n","422   18.969552   2.778516   3963.342924   5.196002    4.142271   0.49706   \n","449   23.190720   4.043097   6308.160246   7.249595    5.475302   0.49706   \n","458   18.187008   0.296850   8267.998789   7.133822    0.296625   2.08916   \n","469   61.746720   7.563738   4993.562501  12.001801   10.371341   0.49706   \n","471   28.868448  23.510520   6302.762840   7.800895   31.251519   1.13593   \n","490   24.093216  12.307401  51958.461990  13.490311   20.986174   1.07764   \n","492   56.697312   0.522456   7577.827019  11.009461    3.889259   0.49706   \n","507   94.367952  10.674726   4333.121380  12.227834    8.275406   0.72848   \n","516   67.978512  14.397225   8356.041635   9.217736    8.080244   2.74891   \n","517  360.547152   0.504645   6589.558986   9.540247    3.423047   0.49706   \n","529   36.533952   0.522456   2884.329599  12.233347    2.461014   0.49706   \n","537   44.302272   3.473145   7410.144362   9.085424    5.418528   1.95112   \n","562   54.429648   2.641965   9810.504061  11.163825   95.038650   0.49706   \n","568   46.718448   2.689461   4651.223978  10.733811    5.320825   0.49706   \n","570   22.351056   0.296850   5039.283246   7.900129    0.296625   2.15064   \n","573   35.482944   5.242371   8018.868452   8.633358    5.097005   0.49706   \n","579   35.694288   2.558847   2600.344446   7.971798    2.932309   0.49706   \n","582   37.053744   5.663898  33984.269060  10.877149    5.372854   0.97150   \n","583  143.274096   1.715793   2503.834934  10.744837    4.874422   1.76204   \n","594   32.187120   2.719146   5280.276301   8.252961         NaN   0.49706   \n","602   35.734272   4.001538   6730.643885   9.162606    4.764967   0.49706   \n","603   26.663616   3.182232  12454.802560  10.006095    5.781491   1.56600   \n","615   38.133312   6.192291   6464.250832   8.026928    9.256996   0.78764   \n","\n","           FS         GB          GE            GF         GH         GI  \\\n","8    0.067730  17.245908  147.218610   4589.611956  29.771721  54.675576   \n","15   0.582478   4.102182   72.611063   2218.449060  23.806958  35.843392   \n","18   0.711165  16.362218   72.611063   3597.877440  31.330820  25.444796   \n","23   0.866944  21.664358  198.469061   5987.708568  32.610844  15.019194   \n","24   0.433472   8.311337   72.611063   1884.728169  48.039971  37.160256   \n","45   0.067730  30.919848   72.611063    819.350802  20.156657  31.537864   \n","46   0.291239  14.585536  160.164837   6209.544726  36.942088  33.093924   \n","48   0.209963  18.557490  118.296094    952.591590  29.634044  19.863556   \n","64   0.711165  12.036788   72.611063   2418.052176  43.892916  33.003904   \n","71   0.237055  26.733948  103.216456    642.540600  32.149440  39.436476   \n","88   0.074503  42.454328   81.681372   2307.938913  35.077867  33.731780   \n","114  0.067730  25.636312  198.146620   6926.005926  25.287916  73.265992   \n","119  0.392834  14.725066   72.611063  13055.309620  31.795945  29.781188   \n","125  0.338650  15.180864  208.879930    272.340549  48.968360  23.073412   \n","128  0.501202  38.645159  117.233806   1577.712735  32.223860  40.028036   \n","153  1.178502  25.217722   72.611063    410.058126  30.575457  27.944780   \n","166  0.067730  15.673870  229.023659   2850.852915  32.934571  28.299716   \n","177  0.067730  11.599594   72.611063    762.097329  52.670755  10.840980   \n","178  0.067730  10.185690   78.459171  10032.175780  19.847814  41.756420   \n","196  0.711165  27.636242  120.939668   5159.734425  18.218016  18.276632   \n","231  0.067730  30.901244   72.611063    862.299108  28.670305  34.181880   \n","233  0.426699  13.422786   72.611063   6844.557672  21.124117  17.026640   \n","235  0.067730  41.914812  126.767900    407.989224  21.261794  34.495664   \n","236  0.067730  22.989893  258.259781     13.038894  55.000101  66.347312   \n","244  1.639066  25.013078  175.772307   2112.316137  54.702421  42.713204   \n","253  0.494429  19.041194   72.611063   3494.694780  36.417427  28.006508   \n","263  0.067730  27.589732   72.611063   7069.258800  34.315062  34.930332   \n","264  0.182871  27.087424  215.072564   2368.894977  36.052769   5.546518   \n","266  0.582478  22.264337  268.959964     13.038894  39.710512  70.796872   \n","272  0.284466  29.673380  126.405706   2425.619196  32.212697  52.944620   \n","279  0.067730  17.831934  103.918759  23672.744100  26.586545  51.882384   \n","281  0.555386  37.319624   72.611063   3586.155120  40.666809  35.509032   \n","283  0.067730  19.459784   72.611063   2742.701391  31.129886  32.178292   \n","285  0.243828  11.906560  154.749595    578.244987  38.188623  31.488996   \n","289  0.067730  12.446076  260.053084   4316.090427  39.677023  13.694614   \n","304  1.666158  17.264512   72.611063   3595.331772  35.583923  36.584128   \n","305  0.067730  35.775492  139.349725   2605.661784  34.143896  11.847918   \n","316  0.067730  32.668624  126.993167    311.914314  33.805285  39.611372   \n","330       NaN  31.636102  296.036174  12261.844150  49.586046  39.457052   \n","341  0.108368  21.041124  103.865755   4255.175916  36.796969  69.122500   \n","356  0.975312  36.231290   93.993760  14702.798590  39.427716  74.479976   \n","358  0.318331  39.533500   72.611063    829.174806  49.712560  35.581048   \n","363  0.392834  19.515596  103.923176     13.038894  31.643384  28.703520   \n","364  0.501202  20.724856  127.591671   7359.279057  32.547587   4.436700   \n","369  1.219140   9.525248   73.207358   2322.462780  26.221887  95.251448   \n","375  0.629889  14.697160   72.611063   3754.632852  26.705617  49.400404   \n","422  0.799214   6.018394   72.611063   1773.175860  24.610694   3.598228   \n","449  0.379288  12.966988   72.611063    975.316707  20.506431   9.364652   \n","458  0.067730  12.734438  103.874589   3266.415720  19.918513  66.949160   \n","469  0.067730  23.896838  144.616997   1753.748739  20.324102   3.150700   \n","471  0.067730  22.966638   72.611063   4646.471769  23.356717  46.537768   \n","490  0.535067  23.106168   72.611063   2497.724586  42.534751  19.323436   \n","492  0.067730  30.491956  142.216357    558.039294  32.127114   5.280316   \n","507  1.022723  32.715134  114.890587  31583.309000  50.170243  29.752896   \n","516  0.988858  31.143096   72.611063   4999.158324  33.403417   8.258692   \n","517  0.257374  27.013008  134.912848   2407.388364  34.668557  10.711094   \n","529  0.067730  24.445656  118.355723    160.814484  29.310317  19.210268   \n","537  0.839852  29.329206   72.611063   9786.129534  24.160453  31.712760   \n","562       NaN  25.766540  191.971654   4833.383724  25.113029  40.025464   \n","568  0.067730   8.967128  125.065146   4911.188436  21.630173   8.299844   \n","570  0.067730  23.385228   72.611063   6023.124846  47.014835  21.422188   \n","573  0.067730  16.315708  110.632599   7444.066860  16.111930  76.509284   \n","579  0.250601  13.571618  243.025549   4421.799072  42.728243  29.952226   \n","582  0.399607  25.803748  151.900630   8899.331652  31.929901  42.134504   \n","583  0.386061  12.660022   72.611063   2118.717486  20.714807  29.786332   \n","594  0.731484  37.310322  143.490662   1849.552461  31.371751  10.043660   \n","602  0.704392  12.027486  212.210348   9146.473587  17.287766  30.712252   \n","603  0.067730  12.073996   72.611063   2369.417670  19.367805  25.591400   \n","615  0.670527  24.594488   72.611063   1965.343176  25.116750  37.155112   \n","\n","            GL  Class  \n","8     0.073416      0  \n","15    0.015231      0  \n","18    0.011000      0  \n","23    0.136552      0  \n","24   21.978000      0  \n","45    0.027000      0  \n","46    0.051333      0  \n","48    0.078545      0  \n","64    0.126465      0  \n","71    0.062526      0  \n","88    0.028537      1  \n","114  21.978000      0  \n","119   0.141429      0  \n","125   0.103714      0  \n","128   0.153621      0  \n","153   0.078158      0  \n","166   0.053460      0  \n","177   0.068062      0  \n","178   0.255364      0  \n","196   0.172565      0  \n","231   0.068629      0  \n","233   0.098664      0  \n","235   0.132420      0  \n","236   0.066000      0  \n","244   0.087052      0  \n","253   0.154286      0  \n","263   0.169714      0  \n","264   0.099000      0  \n","266   0.110000      0  \n","272   0.151105      0  \n","279   0.110512      0  \n","281   0.123750      0  \n","283   0.180148      0  \n","285   0.147030      0  \n","289   0.117818      0  \n","304   0.131416      1  \n","305   0.111028      0  \n","316   0.047520      0  \n","330  21.978000      1  \n","341   0.143550      0  \n","356   0.013500      0  \n","358   0.109191      0  \n","363   0.083600      0  \n","364   0.177058      0  \n","369   0.019800      0  \n","375   0.130935      0  \n","422   0.147231      0  \n","449   0.184800      0  \n","458   2.376000      0  \n","469   0.067296      0  \n","471   0.062450      1  \n","490   0.048712      1  \n","492   0.021405      0  \n","507   0.213379      0  \n","516   0.111170      1  \n","517   0.041250      0  \n","529   0.071280      0  \n","537   0.102600      0  \n","562   0.007333      0  \n","568   0.121224      0  \n","570   2.376000      0  \n","573   0.257400      0  \n","579   0.172055      0  \n","582   0.146466      0  \n","583   0.069164      0  \n","594        NaN      0  \n","602   0.171600      0  \n","603   0.130680      0  \n","615   0.184622      0  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Keep all rows with at least one missing data\n","train_df[train_df.isna().any(axis=1)]"]},{"cell_type":"markdown","id":"d6948e29","metadata":{"papermill":{"duration":0.033708,"end_time":"2023-07-30T19:54:58.429602","exception":false,"start_time":"2023-07-30T19:54:58.395894","status":"completed"},"tags":[]},"source":["# Check duplication"]},{"cell_type":"code","execution_count":12,"id":"38bc667d","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:58.499685Z","iopub.status.busy":"2023-07-30T19:54:58.499308Z","iopub.status.idle":"2023-07-30T19:54:58.529185Z","shell.execute_reply":"2023-07-30T19:54:58.527366Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.067974,"end_time":"2023-07-30T19:54:58.531709","exception":false,"start_time":"2023-07-30T19:54:58.463735","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mTrain set: There are a total of \u001b[1m0\u001b[0;0m \u001b[1mduplicate rows.\n","\u001b[0;0m\n","\u001b[1mGreeks: There are a total of \u001b[1m0\u001b[0;0m \u001b[1mduplicate rows.\n","\u001b[0;0m\n","\u001b[1mTest set: There are a total of \u001b[1m0\u001b[0;0m \u001b[1mduplicate rows.\n","\u001b[0;0m\n","\u001b[1mSubmission: There are a total of \u001b[1m0\u001b[0;0m \u001b[1mduplicate rows.\n","\u001b[0;0m\n"]}],"source":["# Check for duplicates\n","\n","print(start+'Train set: There are a total of', start+str(train_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)\n","print(start+'Greeks: There are a total of', start+str(greeks_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)\n","print(start+'Test set: There are a total of', start+str(test_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)\n","print(start+'Submission: There are a total of', start+str(sample_submission_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)"]},{"cell_type":"code","execution_count":13,"id":"5439680f","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:58.602258Z","iopub.status.busy":"2023-07-30T19:54:58.601826Z","iopub.status.idle":"2023-07-30T19:54:58.637517Z","shell.execute_reply":"2023-07-30T19:54:58.636086Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.074175,"end_time":"2023-07-30T19:54:58.640006","exception":false,"start_time":"2023-07-30T19:54:58.565831","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EJ</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [Id, AB, AF, AH, AM, AR, AX, AY, AZ, BC, BD , BN, BP, BQ, BR, BZ, CB, CC, CD , CF, CH, CL, CR, CS, CU, CW , DA, DE, DF, DH, DI, DL, DN, DU, DV, DY, EB, EE, EG, EH, EJ, EL, EP, EU, FC, FD , FE, FI, FL, FR, FS, GB, GE, GF, GH, GI, GL, Class]\n","Index: []"]},"execution_count":13,"metadata":{},"output_type":"execute_result"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Alpha</th>\n","      <th>Beta</th>\n","      <th>Gamma</th>\n","      <th>Delta</th>\n","      <th>Epsilon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [Id, Alpha, Beta, Gamma, Delta, Epsilon]\n","Index: []"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Check duplication by Id\n","train_df[train_df.Id.duplicated(keep=False)].sort_values(\"Id\")\n","greeks_df[greeks_df.Id.duplicated(keep=False)].sort_values(\"Id\")"]},{"cell_type":"markdown","id":"7fea981f","metadata":{"papermill":{"duration":0.035058,"end_time":"2023-07-30T19:54:58.712468","exception":false,"start_time":"2023-07-30T19:54:58.67741","status":"completed"},"tags":[]},"source":["# Class imbalance"]},{"cell_type":"code","execution_count":14,"id":"5f537e0c","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:58.784841Z","iopub.status.busy":"2023-07-30T19:54:58.784389Z","iopub.status.idle":"2023-07-30T19:54:58.971637Z","shell.execute_reply":"2023-07-30T19:54:58.970332Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.226453,"end_time":"2023-07-30T19:54:58.974425","exception":false,"start_time":"2023-07-30T19:54:58.747972","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Class imbalance (counts): 1=Diagnosed, 0=Not Diagnosed\n","0    509\n","1    108\n","Name: Class, dtype: int64 \n","\n","Normalized class: Class 1, Class 0\n","0    0.824959\n","1    0.175041\n","Name: Class, dtype: float64\n"]},{"data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>                            <div id=\"3f02918d-0496-49fa-b84e-5e462e5bf8e7\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3f02918d-0496-49fa-b84e-5e462e5bf8e7\")) {                    Plotly.newPlot(                        \"3f02918d-0496-49fa-b84e-5e462e5bf8e7\",                        [{\"labels\":[\"Class 0    (n=509)\",\"Class 1    (n=108)\"],\"values\":[509,108],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"font\":{\"size\":14},\"text\":\"\\u003cb\\u003ePie chart of 'Class'\\u003c\\u002fb\\u003e\",\"y\":0.85,\"x\":0.4,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('3f02918d-0496-49fa-b84e-5e462e5bf8e7');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["piefreq=train_df.Class.value_counts()\n","\n","print('Class imbalance (counts): 1=Diagnosed, 0=Not Diagnosed')\n","print(piefreq,'\\n')\n","\n","# Imbalance class\n","print('Normalized class: Class 1, Class 0')\n","print(train_df.Class.value_counts(normalize=True))\n","\n","# Pie chart of class imbalance\n","fig=go.Figure(data=[go.Pie(labels=['Class 0    (n=' + str(piefreq[0]) +')',\n","                                   'Class 1    (n=' + str(piefreq[1]) +')'],\n","                           values=train_df.Class.value_counts())])\n","fig.update_layout(title=dict(text=\"<b>Pie chart of 'Class'</b>\",\n","                             y=0.85,x=0.4,\n","                             xanchor='center',\n","                             yanchor='top',\n","                             font=dict(size=14)\n","                            )\n","                  ,width=600\n","                  ,height=600)\n","\n","# Delete piefreq dataframe to release memory\n","del piefreq, fig"]},{"cell_type":"markdown","id":"72a2929b","metadata":{"papermill":{"duration":0.035098,"end_time":"2023-07-30T19:54:59.045758","exception":false,"start_time":"2023-07-30T19:54:59.01066","status":"completed"},"tags":[]},"source":["# Merge datasets by Id\n","- Train and Greek "]},{"cell_type":"code","execution_count":15,"id":"5bb73486","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.118841Z","iopub.status.busy":"2023-07-30T19:54:59.118462Z","iopub.status.idle":"2023-07-30T19:54:59.131717Z","shell.execute_reply":"2023-07-30T19:54:59.130562Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.053711,"end_time":"2023-07-30T19:54:59.134811","exception":false,"start_time":"2023-07-30T19:54:59.0811","status":"completed"},"tags":[]},"outputs":[],"source":["# Merge train and greeks dataframe by Id\n","merged_df = pd.merge(train_df, greeks_df, on=\"Id\")"]},{"cell_type":"code","execution_count":16,"id":"5e261bd7","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.211715Z","iopub.status.busy":"2023-07-30T19:54:59.211248Z","iopub.status.idle":"2023-07-30T19:54:59.27586Z","shell.execute_reply":"2023-07-30T19:54:59.274529Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.106736,"end_time":"2023-07-30T19:54:59.278419","exception":false,"start_time":"2023-07-30T19:54:59.171683","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>AB</th>\n","      <th>AF</th>\n","      <th>AH</th>\n","      <th>AM</th>\n","      <th>AR</th>\n","      <th>AX</th>\n","      <th>AY</th>\n","      <th>AZ</th>\n","      <th>BC</th>\n","      <th>BD</th>\n","      <th>BN</th>\n","      <th>BP</th>\n","      <th>BQ</th>\n","      <th>BR</th>\n","      <th>BZ</th>\n","      <th>CB</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>CF</th>\n","      <th>CH</th>\n","      <th>CL</th>\n","      <th>CR</th>\n","      <th>CS</th>\n","      <th>CU</th>\n","      <th>CW</th>\n","      <th>DA</th>\n","      <th>DE</th>\n","      <th>DF</th>\n","      <th>DH</th>\n","      <th>DI</th>\n","      <th>DL</th>\n","      <th>DN</th>\n","      <th>DU</th>\n","      <th>DV</th>\n","      <th>DY</th>\n","      <th>EB</th>\n","      <th>EE</th>\n","      <th>EG</th>\n","      <th>EH</th>\n","      <th>EJ</th>\n","      <th>EL</th>\n","      <th>EP</th>\n","      <th>EU</th>\n","      <th>FC</th>\n","      <th>FD</th>\n","      <th>FE</th>\n","      <th>FI</th>\n","      <th>FL</th>\n","      <th>FR</th>\n","      <th>FS</th>\n","      <th>GB</th>\n","      <th>GE</th>\n","      <th>GF</th>\n","      <th>GH</th>\n","      <th>GI</th>\n","      <th>GL</th>\n","      <th>Class</th>\n","      <th>Alpha</th>\n","      <th>Beta</th>\n","      <th>Gamma</th>\n","      <th>Delta</th>\n","      <th>Epsilon</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000ff2bfdfe9</td>\n","      <td>0.209377</td>\n","      <td>3109.03329</td>\n","      <td>85.200147</td>\n","      <td>22.394407</td>\n","      <td>8.138688</td>\n","      <td>0.699861</td>\n","      <td>0.025578</td>\n","      <td>9.812214</td>\n","      <td>5.555634</td>\n","      <td>4126.58731</td>\n","      <td>22.5984</td>\n","      <td>175.638726</td>\n","      <td>152.707705</td>\n","      <td>823.928241</td>\n","      <td>257.432377</td>\n","      <td>47.223358</td>\n","      <td>0.563481</td>\n","      <td>23.387600</td>\n","      <td>4.851915</td>\n","      <td>0.023482</td>\n","      <td>1.050225</td>\n","      <td>0.069225</td>\n","      <td>13.784111</td>\n","      <td>1.302012</td>\n","      <td>36.205956</td>\n","      <td>69.08340</td>\n","      <td>295.570575</td>\n","      <td>0.23868</td>\n","      <td>0.284232</td>\n","      <td>89.245560</td>\n","      <td>84.31664</td>\n","      <td>29.657104</td>\n","      <td>5.310690</td>\n","      <td>1.74307</td>\n","      <td>23.187704</td>\n","      <td>7.294176</td>\n","      <td>1.987283</td>\n","      <td>1433.166750</td>\n","      <td>0.949104</td>\n","      <td>B</td>\n","      <td>30.879420</td>\n","      <td>78.526968</td>\n","      <td>3.828384</td>\n","      <td>13.394640</td>\n","      <td>10.265073</td>\n","      <td>9028.291921</td>\n","      <td>3.583450</td>\n","      <td>7.298162</td>\n","      <td>1.73855</td>\n","      <td>0.094822</td>\n","      <td>11.339138</td>\n","      <td>72.611063</td>\n","      <td>2003.810319</td>\n","      <td>22.136229</td>\n","      <td>69.834944</td>\n","      <td>0.120343</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>C</td>\n","      <td>G</td>\n","      <td>D</td>\n","      <td>3/19/2019</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>007255e47698</td>\n","      <td>0.145282</td>\n","      <td>978.76416</td>\n","      <td>85.200147</td>\n","      <td>36.968889</td>\n","      <td>8.138688</td>\n","      <td>3.632190</td>\n","      <td>0.025578</td>\n","      <td>13.517790</td>\n","      <td>1.229900</td>\n","      <td>5496.92824</td>\n","      <td>19.4205</td>\n","      <td>155.868030</td>\n","      <td>14.754720</td>\n","      <td>51.216883</td>\n","      <td>257.432377</td>\n","      <td>30.284345</td>\n","      <td>0.484710</td>\n","      <td>50.628208</td>\n","      <td>6.085041</td>\n","      <td>0.031442</td>\n","      <td>1.113875</td>\n","      <td>1.117800</td>\n","      <td>28.310953</td>\n","      <td>1.357182</td>\n","      <td>37.476568</td>\n","      <td>70.79836</td>\n","      <td>178.553100</td>\n","      <td>0.23868</td>\n","      <td>0.363489</td>\n","      <td>110.581815</td>\n","      <td>75.74548</td>\n","      <td>37.532000</td>\n","      <td>0.005518</td>\n","      <td>1.74307</td>\n","      <td>17.222328</td>\n","      <td>4.926396</td>\n","      <td>0.858603</td>\n","      <td>1111.287150</td>\n","      <td>0.003042</td>\n","      <td>A</td>\n","      <td>109.125159</td>\n","      <td>95.415086</td>\n","      <td>52.260480</td>\n","      <td>17.175984</td>\n","      <td>0.296850</td>\n","      <td>6785.003474</td>\n","      <td>10.358927</td>\n","      <td>0.173229</td>\n","      <td>0.49706</td>\n","      <td>0.568932</td>\n","      <td>9.292698</td>\n","      <td>72.611063</td>\n","      <td>27981.562750</td>\n","      <td>29.135430</td>\n","      <td>32.131996</td>\n","      <td>21.978000</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>013f2bd269f5</td>\n","      <td>0.470030</td>\n","      <td>2635.10654</td>\n","      <td>85.200147</td>\n","      <td>32.360553</td>\n","      <td>8.138688</td>\n","      <td>6.732840</td>\n","      <td>0.025578</td>\n","      <td>12.824570</td>\n","      <td>1.229900</td>\n","      <td>5135.78024</td>\n","      <td>26.4825</td>\n","      <td>128.988531</td>\n","      <td>219.320160</td>\n","      <td>482.141594</td>\n","      <td>257.432377</td>\n","      <td>32.563713</td>\n","      <td>0.495852</td>\n","      <td>85.955376</td>\n","      <td>5.376488</td>\n","      <td>0.036218</td>\n","      <td>1.050225</td>\n","      <td>0.700350</td>\n","      <td>39.364743</td>\n","      <td>1.009611</td>\n","      <td>21.459644</td>\n","      <td>70.81970</td>\n","      <td>321.426625</td>\n","      <td>0.23868</td>\n","      <td>0.210441</td>\n","      <td>120.056438</td>\n","      <td>65.46984</td>\n","      <td>28.053464</td>\n","      <td>1.289739</td>\n","      <td>1.74307</td>\n","      <td>36.861352</td>\n","      <td>7.813674</td>\n","      <td>8.146651</td>\n","      <td>1494.076488</td>\n","      <td>0.377208</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>78.526968</td>\n","      <td>5.390628</td>\n","      <td>224.207424</td>\n","      <td>8.745201</td>\n","      <td>8338.906181</td>\n","      <td>11.626917</td>\n","      <td>7.709560</td>\n","      <td>0.97556</td>\n","      <td>1.198821</td>\n","      <td>37.077772</td>\n","      <td>88.609437</td>\n","      <td>13676.957810</td>\n","      <td>28.022851</td>\n","      <td>35.192676</td>\n","      <td>0.196941</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>043ac50845d5</td>\n","      <td>0.252107</td>\n","      <td>3819.65177</td>\n","      <td>120.201618</td>\n","      <td>77.112203</td>\n","      <td>8.138688</td>\n","      <td>3.685344</td>\n","      <td>0.025578</td>\n","      <td>11.053708</td>\n","      <td>1.229900</td>\n","      <td>4169.67738</td>\n","      <td>23.6577</td>\n","      <td>237.282264</td>\n","      <td>11.050410</td>\n","      <td>661.518640</td>\n","      <td>257.432377</td>\n","      <td>15.201914</td>\n","      <td>0.717882</td>\n","      <td>88.159360</td>\n","      <td>2.347652</td>\n","      <td>0.029054</td>\n","      <td>1.400300</td>\n","      <td>0.636075</td>\n","      <td>41.116960</td>\n","      <td>0.722727</td>\n","      <td>21.530392</td>\n","      <td>47.27586</td>\n","      <td>196.607985</td>\n","      <td>0.23868</td>\n","      <td>0.292431</td>\n","      <td>139.824570</td>\n","      <td>71.57120</td>\n","      <td>24.354856</td>\n","      <td>2.655345</td>\n","      <td>1.74307</td>\n","      <td>52.003884</td>\n","      <td>7.386060</td>\n","      <td>3.813326</td>\n","      <td>15691.552180</td>\n","      <td>0.614484</td>\n","      <td>B</td>\n","      <td>31.674357</td>\n","      <td>78.526968</td>\n","      <td>31.323372</td>\n","      <td>59.301984</td>\n","      <td>7.884336</td>\n","      <td>10965.766040</td>\n","      <td>14.852022</td>\n","      <td>6.122162</td>\n","      <td>0.49706</td>\n","      <td>0.284466</td>\n","      <td>18.529584</td>\n","      <td>82.416803</td>\n","      <td>2094.262452</td>\n","      <td>39.948656</td>\n","      <td>90.493248</td>\n","      <td>0.155829</td>\n","      <td>0</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>044fb8a146ec</td>\n","      <td>0.380297</td>\n","      <td>3733.04844</td>\n","      <td>85.200147</td>\n","      <td>14.103738</td>\n","      <td>8.138688</td>\n","      <td>3.942255</td>\n","      <td>0.054810</td>\n","      <td>3.396778</td>\n","      <td>102.151980</td>\n","      <td>5728.73412</td>\n","      <td>24.0108</td>\n","      <td>324.546318</td>\n","      <td>149.717165</td>\n","      <td>6074.859475</td>\n","      <td>257.432377</td>\n","      <td>82.213495</td>\n","      <td>0.536467</td>\n","      <td>72.644264</td>\n","      <td>30.537722</td>\n","      <td>0.025472</td>\n","      <td>1.050225</td>\n","      <td>0.693150</td>\n","      <td>31.724726</td>\n","      <td>0.827550</td>\n","      <td>34.415360</td>\n","      <td>74.06532</td>\n","      <td>200.178160</td>\n","      <td>0.23868</td>\n","      <td>0.207708</td>\n","      <td>97.920120</td>\n","      <td>52.83888</td>\n","      <td>26.019912</td>\n","      <td>1.144902</td>\n","      <td>1.74307</td>\n","      <td>9.064856</td>\n","      <td>7.350720</td>\n","      <td>3.490846</td>\n","      <td>1403.656300</td>\n","      <td>0.164268</td>\n","      <td>B</td>\n","      <td>109.125159</td>\n","      <td>91.994825</td>\n","      <td>51.141336</td>\n","      <td>29.102640</td>\n","      <td>4.274640</td>\n","      <td>16198.049590</td>\n","      <td>13.666727</td>\n","      <td>8.153058</td>\n","      <td>48.50134</td>\n","      <td>0.121914</td>\n","      <td>16.408728</td>\n","      <td>146.109943</td>\n","      <td>8524.370502</td>\n","      <td>45.381316</td>\n","      <td>36.262628</td>\n","      <td>0.096614</td>\n","      <td>1</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>3/25/2020</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id        AB          AF          AH         AM        AR  \\\n","0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n","1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n","2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n","3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n","4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n","\n","         AX        AY         AZ          BC         BD        BN          BP  \\\n","0  0.699861  0.025578   9.812214    5.555634  4126.58731  22.5984  175.638726   \n","1  3.632190  0.025578  13.517790    1.229900  5496.92824  19.4205  155.868030   \n","2  6.732840  0.025578  12.824570    1.229900  5135.78024  26.4825  128.988531   \n","3  3.685344  0.025578  11.053708    1.229900  4169.67738  23.6577  237.282264   \n","4  3.942255  0.054810   3.396778  102.151980  5728.73412  24.0108  324.546318   \n","\n","           BQ           BR          BZ         CB        CC        CD   \\\n","0  152.707705   823.928241  257.432377  47.223358  0.563481  23.387600   \n","1   14.754720    51.216883  257.432377  30.284345  0.484710  50.628208   \n","2  219.320160   482.141594  257.432377  32.563713  0.495852  85.955376   \n","3   11.050410   661.518640  257.432377  15.201914  0.717882  88.159360   \n","4  149.717165  6074.859475  257.432377  82.213495  0.536467  72.644264   \n","\n","          CF        CH        CL        CR         CS        CU        CW   \\\n","0   4.851915  0.023482  1.050225  0.069225  13.784111  1.302012  36.205956   \n","1   6.085041  0.031442  1.113875  1.117800  28.310953  1.357182  37.476568   \n","2   5.376488  0.036218  1.050225  0.700350  39.364743  1.009611  21.459644   \n","3   2.347652  0.029054  1.400300  0.636075  41.116960  0.722727  21.530392   \n","4  30.537722  0.025472  1.050225  0.693150  31.724726  0.827550  34.415360   \n","\n","         DA          DE       DF        DH          DI        DL         DN  \\\n","0  69.08340  295.570575  0.23868  0.284232   89.245560  84.31664  29.657104   \n","1  70.79836  178.553100  0.23868  0.363489  110.581815  75.74548  37.532000   \n","2  70.81970  321.426625  0.23868  0.210441  120.056438  65.46984  28.053464   \n","3  47.27586  196.607985  0.23868  0.292431  139.824570  71.57120  24.354856   \n","4  74.06532  200.178160  0.23868  0.207708   97.920120  52.83888  26.019912   \n","\n","         DU       DV         DY        EB        EE            EG        EH  \\\n","0  5.310690  1.74307  23.187704  7.294176  1.987283   1433.166750  0.949104   \n","1  0.005518  1.74307  17.222328  4.926396  0.858603   1111.287150  0.003042   \n","2  1.289739  1.74307  36.861352  7.813674  8.146651   1494.076488  0.377208   \n","3  2.655345  1.74307  52.003884  7.386060  3.813326  15691.552180  0.614484   \n","4  1.144902  1.74307   9.064856  7.350720  3.490846   1403.656300  0.164268   \n","\n","  EJ          EL         EP         EU          FC        FD             FE  \\\n","0  B   30.879420  78.526968   3.828384   13.394640  10.265073   9028.291921   \n","1  A  109.125159  95.415086  52.260480   17.175984   0.296850   6785.003474   \n","2  B  109.125159  78.526968   5.390628  224.207424   8.745201   8338.906181   \n","3  B   31.674357  78.526968  31.323372   59.301984   7.884336  10965.766040   \n","4  B  109.125159  91.994825  51.141336   29.102640   4.274640  16198.049590   \n","\n","          FI        FL        FR        FS         GB          GE  \\\n","0   3.583450  7.298162   1.73855  0.094822  11.339138   72.611063   \n","1  10.358927  0.173229   0.49706  0.568932   9.292698   72.611063   \n","2  11.626917  7.709560   0.97556  1.198821  37.077772   88.609437   \n","3  14.852022  6.122162   0.49706  0.284466  18.529584   82.416803   \n","4  13.666727  8.153058  48.50134  0.121914  16.408728  146.109943   \n","\n","             GF         GH         GI         GL  Class Alpha Beta Gamma  \\\n","0   2003.810319  22.136229  69.834944   0.120343      1     B    C     G   \n","1  27981.562750  29.135430  32.131996  21.978000      0     A    C     M   \n","2  13676.957810  28.022851  35.192676   0.196941      0     A    C     M   \n","3   2094.262452  39.948656  90.493248   0.155829      0     A    C     M   \n","4   8524.370502  45.381316  36.262628   0.096614      1     D    B     F   \n","\n","  Delta    Epsilon  \n","0     D  3/19/2019  \n","1     B    Unknown  \n","2     B    Unknown  \n","3     B    Unknown  \n","4     B  3/25/2020  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["merged_df.head()"]},{"cell_type":"code","execution_count":17,"id":"f9fb0459","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.36086Z","iopub.status.busy":"2023-07-30T19:54:59.360487Z","iopub.status.idle":"2023-07-30T19:54:59.369314Z","shell.execute_reply":"2023-07-30T19:54:59.368332Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.051775,"end_time":"2023-07-30T19:54:59.371846","exception":false,"start_time":"2023-07-30T19:54:59.320071","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["B    395\n","A    222\n","Name: EJ, dtype: int64"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Categorical feature\n","merged_df.EJ.value_counts()"]},{"cell_type":"code","execution_count":18,"id":"84115559","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.449425Z","iopub.status.busy":"2023-07-30T19:54:59.448992Z","iopub.status.idle":"2023-07-30T19:54:59.499977Z","shell.execute_reply":"2023-07-30T19:54:59.498683Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.092605,"end_time":"2023-07-30T19:54:59.502371","exception":false,"start_time":"2023-07-30T19:54:59.409766","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mAlpha:\u001b[0;0m\n"]},{"data":{"text/plain":["A    509\n","B     61\n","G     29\n","D     18\n","Name: Alpha, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1mBeta:\u001b[0;0m\n"]},{"data":{"text/plain":["C    407\n","B    202\n","A      8\n","Name: Beta, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1mGamma:\u001b[0;0m\n"]},{"data":{"text/plain":["M    445\n","N     64\n","H     53\n","B     18\n","A     11\n","F     10\n","G      8\n","E      8\n","Name: Gamma, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1mDelta:\u001b[0;0m\n"]},{"data":{"text/plain":["B    456\n","A     75\n","C     64\n","D     22\n","Name: Delta, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1mEpsilon:\u001b[0;0m\n"]},{"data":{"text/plain":["Unknown       144\n","5/29/2019      24\n","6/26/2019      19\n","9/15/2020      17\n","8/29/2019      13\n","4/24/2019      11\n","9/8/2020       11\n","1/29/2019      10\n","1/31/2019      10\n","2/18/2019      10\n","4/30/2020       9\n","9/13/2020       8\n","7/30/2020       7\n","7/27/2020       6\n","6/11/2020       5\n","9/14/2020       5\n","11/27/2018      5\n","11/25/2019      5\n","9/11/2020       5\n","3/1/2019        5\n","12/10/2018      5\n","7/28/2020       5\n","5/6/2020        5\n","3/15/2019       5\n","2/28/2019       5\n","5/27/2020       4\n","6/21/2019       4\n","10/1/2019       4\n","4/29/2020       4\n","11/30/2018      4\n","12/4/2018       4\n","12/20/2018      4\n","3/13/2019       4\n","7/24/2020       4\n","4/28/2020       4\n","6/2/2020        4\n","9/7/2020        4\n","9/16/2020       3\n","7/16/2020       3\n","7/29/2020       3\n","12/24/2019      3\n","7/19/2019       3\n","3/7/2019        3\n","12/30/2019      3\n","4/9/2019        3\n","12/19/2019      3\n","12/9/2019       3\n","3/28/2019       2\n","5/2/2020        2\n","7/30/2019       2\n","7/15/2020       2\n","7/15/2019       2\n","1/28/2020       2\n","6/25/2020       2\n","2/22/2019       2\n","10/18/2019      2\n","12/19/2018      2\n","9/17/2020       2\n","5/13/2020       2\n","4/8/2019        2\n","3/11/2019       2\n","4/12/2019       2\n","5/7/2020        2\n","7/8/2020        2\n","5/5/2020        2\n","2/20/2019       2\n","12/31/2019      2\n","11/21/2018      2\n","6/3/2020        2\n","10/31/2018      2\n","5/28/2020       2\n","2/5/2020        2\n","6/1/2020        2\n","6/4/2020        2\n","7/23/2020       2\n","7/23/2019       2\n","1/29/2020       2\n","2/12/2019       2\n","4/17/2019       2\n","10/30/2019      2\n","7/29/2019       2\n","12/26/2016      1\n","4/11/2019       1\n","12/11/2018      1\n","11/28/2018      1\n","7/1/2020        1\n","11/5/2019       1\n","7/16/2014       1\n","5/23/2019       1\n","9/18/2020       1\n","3/10/2020       1\n","4/26/2019       1\n","4/9/2018        1\n","1/16/2018       1\n","3/4/2020        1\n","3/25/2019       1\n","9/20/2019       1\n","9/20/2018       1\n","3/19/2019       1\n","8/6/2020        1\n","11/5/2018       1\n","2/4/2020        1\n","3/29/2019       1\n","11/7/2018       1\n","9/16/2014       1\n","5/16/2019       1\n","4/22/2019       1\n","1/7/2019        1\n","1/23/2018       1\n","8/15/2020       1\n","12/26/2018      1\n","7/24/2014       1\n","11/12/2019      1\n","2/13/2019       1\n","1/23/2020       1\n","2/12/2020       1\n","8/17/2020       1\n","2/28/2020       1\n","11/6/2018       1\n","7/10/2019       1\n","10/30/2018      1\n","12/20/2017      1\n","11/15/2019      1\n","1/7/2020        1\n","1/6/2020        1\n","1/11/2018       1\n","1/8/2020        1\n","5/1/2020        1\n","8/11/2020       1\n","12/26/2019      1\n","8/1/2012        1\n","12/2/2019       1\n","11/2/2018       1\n","5/9/2019        1\n","7/22/2018       1\n","9/10/2018       1\n","5/4/2020        1\n","7/4/2019        1\n","6/18/2019       1\n","9/3/2014        1\n","5/29/2020       1\n","8/15/2018       1\n","5/22/2019       1\n","7/25/2019       1\n","3/6/2019        1\n","7/8/2019        1\n","2/8/2019        1\n","9/13/2018       1\n","4/23/2019       1\n","6/12/2020       1\n","5/24/2019       1\n","1/3/2019        1\n","3/20/2019       1\n","11/4/2019       1\n","4/10/2019       1\n","10/29/2019      1\n","7/10/2020       1\n","3/27/2019       1\n","1/2/2020        1\n","12/13/2018      1\n","9/27/2019       1\n","11/8/2019       1\n","12/18/2019      1\n","6/23/2020       1\n","6/19/2020       1\n","3/25/2020       1\n","4/25/2019       1\n","2/24/2020       1\n","9/10/2020       1\n","9/29/2020       1\n","2/11/2020       1\n","5/8/2020        1\n","12/18/2018      1\n","4/1/2019        1\n","4/4/2019        1\n","5/11/2019       1\n","2/15/2018       1\n","5/17/2019       1\n","3/4/2019        1\n","5/17/2012       1\n","9/9/2014        1\n","7/2/2020        1\n","7/29/2014       1\n","3/8/2018        1\n","7/14/2019       1\n","11/13/2019      1\n","12/14/2018      1\n","7/9/2014        1\n","4/19/2019       1\n","9/19/2018       1\n","11/20/2019      1\n","5/30/2019       1\n","5/10/2019       1\n","2/21/2019       1\n","8/13/2019       1\n","5/18/2020       1\n","12/20/2019      1\n","7/24/2019       1\n","Name: Epsilon, dtype: int64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Categorical feature\n","print(start+\"Alpha:\"+end)\n","greeks_df[~greeks_df[\"Alpha\"].str.isnumeric()][\"Alpha\"].value_counts()\n","print(\"\\n\"+start+\"Beta:\"+end)\n","greeks_df[~greeks_df[\"Beta\"].str.isnumeric()][\"Beta\"].value_counts()\n","print(\"\\n\"+start+\"Gamma:\"+end)\n","greeks_df[~greeks_df[\"Gamma\"].str.isnumeric()][\"Gamma\"].value_counts()\n","print(\"\\n\"+start+\"Delta:\"+end)\n","greeks_df[~greeks_df[\"Delta\"].str.isnumeric()][\"Delta\"].value_counts()\n","print(\"\\n\"+start+\"Epsilon:\"+end)\n","greeks_df[~greeks_df[\"Epsilon\"].str.isnumeric()][\"Epsilon\"].value_counts()"]},{"cell_type":"code","execution_count":19,"id":"eafb0e26","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.581285Z","iopub.status.busy":"2023-07-30T19:54:59.580885Z","iopub.status.idle":"2023-07-30T19:54:59.605413Z","shell.execute_reply":"2023-07-30T19:54:59.604304Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.066793,"end_time":"2023-07-30T19:54:59.60789","exception":false,"start_time":"2023-07-30T19:54:59.541097","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["Id            Alpha  Beta  Gamma  Delta  Epsilon\n","007255e47698  A      C     M      B      Unknown    1\n","013f2bd269f5  A      C     M      B      Unknown    1\n","a7b1c7b83f53  A      C     M      B      Unknown    1\n","ab39fd701211  A      C     M      B      Unknown    1\n","ab4bc55cb79e  A      C     M      B      Unknown    1\n","adb67a0dd661  A      C     M      B      Unknown    1\n","aee064d35f72  A      C     M      B      Unknown    1\n","af0802c15f01  A      C     M      B      Unknown    1\n","afad421356e3  A      C     M      B      Unknown    1\n","b06b043e7abe  A      C     M      B      Unknown    1\n","b1056bf99b86  A      C     M      B      Unknown    1\n","b10bae274dfc  A      C     M      B      Unknown    1\n","b10f6f101138  A      C     M      B      Unknown    1\n","b301f38c110c  A      C     M      B      Unknown    1\n","b4d611fab6c5  A      C     M      B      Unknown    1\n","b874e25c20aa  A      C     M      B      Unknown    1\n","ba0c42e12f1f  A      C     M      B      Unknown    1\n","a633a258eeed  A      C     M      B      Unknown    1\n","9ee887ad93d5  A      C     M      B      Unknown    1\n","9e725e00b348  A      C     M      B      Unknown    1\n","8b4dfe76ff44  A      B     M      B      Unknown    1\n","810ff5afd0e2  A      C     M      B      Unknown    1\n","8296caddae14  A      C     M      B      Unknown    1\n","8457871d9624  A      C     N      B      Unknown    1\n","8856a9d8e2b4  A      B     M      B      Unknown    1\n","88ceb24fa799  A      C     M      B      Unknown    1\n","8ae3966cdb92  A      B     M      B      Unknown    1\n","8b7131974251  A      C     M      B      Unknown    1\n","98944bb311a4  A      C     M      B      Unknown    1\n","8d7f231c9cb7  A      C     M      B      Unknown    1\n","8e22648bf996  A      C     M      B      Unknown    1\n","8e35c5943760  A      C     M      B      Unknown    1\n","94f28a9c879b  A      C     M      B      Unknown    1\n","968491b9238f  A      C     M      B      Unknown    1\n","96ee4e851fbd  A      B     M      B      Unknown    1\n","bfcbf52e5449  A      C     M      B      Unknown    1\n","c6c3a77ec885  A      C     M      B      Unknown    1\n","c82e5a429e5b  A      C     M      B      Unknown    1\n","ed4a24c7ec54  A      C     M      B      Unknown    1\n","e70b5934b571  A      C     M      B      Unknown    1\n","e9417cc82b93  A      C     M      B      Unknown    1\n","e999bb1c01d7  A      C     M      B      Unknown    1\n","ea50b3c5bd63  A      C     M      B      Unknown    1\n","eb9c2a590373  A      C     M      B      Unknown    1\n","ecf1ac3d6dfc  A      C     M      B      Unknown    1\n","efcba7fac353  A      C     M      B      Unknown    1\n","e6aa6fa49abd  A      C     M      B      Unknown    1\n","f003d68995be  A      C     M      B      Unknown    1\n","f03b541de10c  A      B     M      B      Unknown    1\n","f1a68746ca6e  A      C     M      B      Unknown    1\n","f46e39a96ee9  A      C     M      B      Unknown    1\n","f7a862a414de  A      B     M      B      Unknown    1\n","f82b07dfd7fb  A      C     M      B      Unknown    1\n","e70889ea6013  A      C     M      B      Unknown    1\n","e235af39779b  A      C     M      B      Unknown    1\n","c86be787cb28  A      C     M      B      Unknown    1\n","d061b54c6650  A      C     M      B      Unknown    1\n","c8a5264f7458  A      C     M      B      Unknown    1\n","ca4b0957e0c8  A      C     M      B      Unknown    1\n","cc42ed28ac3f  A      C     M      B      Unknown    1\n","ccd8b4b583df  A      C     M      B      Unknown    1\n","ce42176962b9  A      C     M      B      Unknown    1\n","d02c11462079  A      C     M      B      Unknown    1\n","d10976c44b2b  A      C     M      B      Unknown    1\n","e15ae7d5194f  A      C     M      B      Unknown    1\n","d35148a64ca9  A      C     M      B      Unknown    1\n","d44d3320d240  A      C     M      B      Unknown    1\n","d7dbf59b37f9  A      C     M      B      Unknown    1\n","da6c7e4e124d  A      C     M      B      Unknown    1\n","df956c379776  A      C     M      B      Unknown    1\n","e0bf5a4a77d2  A      C     M      B      Unknown    1\n","809087be105e  A      C     M      B      Unknown    1\n","800c6b3239c6  A      C     M      B      Unknown    1\n","7feabcc65b6b  A      C     M      B      Unknown    1\n","332a3850302f  A      C     M      B      Unknown    1\n","2bb2902bd5e1  A      B     M      B      Unknown    1\n","2e4e80b95e24  A      C     M      B      Unknown    1\n","2f020a35ce2b  A      C     M      B      Unknown    1\n","3101fca6b743  A      C     M      B      Unknown    1\n","312661adb2ff  A      C     M      B      Unknown    1\n","321f58c2e5d1  A      C     M      B      Unknown    1\n","3493c79c8f35  A      B     M      B      Unknown    1\n","24dfe3da6769  A      C     M      B      Unknown    1\n","34dc3190c6fb  A      C     M      B      Unknown    1\n","34f10f630b68  A      C     M      B      Unknown    1\n","3840054e6aa5  A      C     N      B      Unknown    1\n","41475fa34ab3  A      C     M      B      Unknown    1\n","41e9e3cec765  A      B     M      B      Unknown    1\n","431c73b16f33  A      C     M      B      Unknown    1\n","298989cc4e92  A      C     M      B      Unknown    1\n","21d33a9fee44  A      B     M      B      Unknown    1\n","4401d2485580  A      C     M      B      Unknown    1\n","10187958312d  A      C     M      B      Unknown    1\n","043ac50845d5  A      C     M      B      Unknown    1\n","0cdf781c81b9  A      C     M      B      Unknown    1\n","0cf6c827b8bb  A      C     M      B      Unknown    1\n","0d1b855c7635  A      B     M      B      Unknown    1\n","0db07bc343e3  A      C     M      B      Unknown    1\n","0e17c8abe9b6  A      B     M      B      Unknown    1\n","1073082e7823  A      C     M      B      Unknown    1\n","20731b639de9  A      C     M      B      Unknown    1\n","10aaf6adb652  A      C     M      B      Unknown    1\n","128cc82dc5d6  A      C     M      B      Unknown    1\n","14713ec51d95  A      B     M      B      Unknown    1\n","1919e4c3a7cc  A      C     M      B      Unknown    1\n","19e4c52ea251  A      B     M      B      Unknown    1\n","1a9fecf65695  A      C     M      B      Unknown    1\n","434b3925094e  A      B     M      B      Unknown    1\n","4537a9a3ecde  A      C     M      B      Unknown    1\n","7cc870296984  A      C     M      B      Unknown    1\n","6487b5140ab2  A      C     M      B      Unknown    1\n","5c522f58308c  A      C     M      B      Unknown    1\n","5ce5f23fff0d  A      C     N      B      Unknown    1\n","5ee622a3e3be  A      C     M      B      Unknown    1\n","619aac34f423  A      C     M      B      Unknown    1\n","61af8fde49eb  A      C     M      B      Unknown    1\n","61e882a215f4  A      C     M      B      Unknown    1\n","65de682cc48c  A      C     M      B      Unknown    1\n","59bf633c1018  A      C     M      B      Unknown    1\n","6850ef5b0092  A      C     M      B      Unknown    1\n","6860e7cbccad  A      C     M      B      Unknown    1\n","7017fab77607  A      C     M      B      Unknown    1\n","70926a82d4e1  A      C     M      B      Unknown    1\n","73468ffe1cb5  A      C     M      B      Unknown    1\n","778e1213d462  A      B     M      B      Unknown    1\n","59bf79fac3fa  A      C     M      B      Unknown    1\n","58843604dcb5  A      C     M      B      Unknown    1\n","457d8d386eb2  A      C     M      B      Unknown    1\n","4e9059199e3d  A      C     M      B      Unknown    1\n","46a2c24d2624  A      C     M      B      Unknown    1\n","470d18ff7777  A      C     M      B      Unknown    1\n","48c64ab517c9  A      C     M      B      Unknown    1\n","4bc8f3ea493a  A      C     M      B      Unknown    1\n","4d54e3a957e6  A      C     M      B      Unknown    1\n","4e6477903aa3  A      C     M      B      Unknown    1\n","4fef9a973791  A      C     M      B      Unknown    1\n","535a9e672d18  A      C     M      B      Unknown    1\n","50183292c0e7  A      C     M      B      Unknown    1\n","51111505c6f2  A      C     M      B      Unknown    1\n","514d2ac4fdb5  A      C     M      B      Unknown    1\n","51a5b926ab4d  A      C     M      B      Unknown    1\n","52acfa7cc2fc  A      C     M      B      Unknown    1\n","53468141b7c9  A      C     M      B      Unknown    1\n","ffcca4ded3bb  A      C     M      B      Unknown    1\n","dtype: int64"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Print counts of 'Unknown' Epsilon\n","unknown_df=greeks_df.query(\"Epsilon=='Unknown'\")\n","unknown_df.value_counts()"]},{"cell_type":"markdown","id":"f5a84809","metadata":{"papermill":{"duration":0.041127,"end_time":"2023-07-30T19:54:59.687607","exception":false,"start_time":"2023-07-30T19:54:59.64648","status":"completed"},"tags":[]},"source":["# Feature Encoding"]},{"cell_type":"code","execution_count":20,"id":"7156b7c0","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.768699Z","iopub.status.busy":"2023-07-30T19:54:59.767193Z","iopub.status.idle":"2023-07-30T19:54:59.776469Z","shell.execute_reply":"2023-07-30T19:54:59.775141Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.051891,"end_time":"2023-07-30T19:54:59.778996","exception":false,"start_time":"2023-07-30T19:54:59.727105","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nle = LabelEncoder()\\n\\n# Columns to encode\\ncat_features = [\"EJ\", \"Alpha\", \"Beta\", \"Gamma\", \"Delta\"] \\nenc_df=merged_df.copy()\\n\\n# Apply label encoder to each column\\nenc_df[cat_features] = enc_df[cat_features].apply(le.fit_transform) \\n\\nenc_df.info()\\n'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","le = LabelEncoder()\n","\n","# Columns to encode\n","cat_features = [\"EJ\", \"Alpha\", \"Beta\", \"Gamma\", \"Delta\"] \n","enc_df=merged_df.copy()\n","\n","# Apply label encoder to each column\n","enc_df[cat_features] = enc_df[cat_features].apply(le.fit_transform) \n","\n","enc_df.info()\n","'''"]},{"cell_type":"code","execution_count":21,"id":"77ac10fd","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:54:59.858626Z","iopub.status.busy":"2023-07-30T19:54:59.858142Z","iopub.status.idle":"2023-07-30T19:54:59.866495Z","shell.execute_reply":"2023-07-30T19:54:59.865211Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.051852,"end_time":"2023-07-30T19:54:59.869489","exception":false,"start_time":"2023-07-30T19:54:59.817637","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nprint(start+\"Before\"+end)\\ntrain_df[\\'EJ\\'].value_counts()\\nenc_df[\\'EJ\\'].value_counts()\\n\\ngreeks_df[\\'Alpha\\'].value_counts()\\nenc_df[\\'Alpha\\'].value_counts()\\n\\ngreeks_df[\\'Beta\\'].value_counts()\\nenc_df[\\'Beta\\'].value_counts()\\n\\ngreeks_df[\\'Gamma\\'].value_counts()\\nenc_df[\\'Gamma\\'].value_counts()\\n\\ngreeks_df[\\'Delta\\'].value_counts()\\nenc_df[\\'Delta\\'].value_counts()\\n'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","print(start+\"Before\"+end)\n","train_df['EJ'].value_counts()\n","enc_df['EJ'].value_counts()\n","\n","greeks_df['Alpha'].value_counts()\n","enc_df['Alpha'].value_counts()\n","\n","greeks_df['Beta'].value_counts()\n","enc_df['Beta'].value_counts()\n","\n","greeks_df['Gamma'].value_counts()\n","enc_df['Gamma'].value_counts()\n","\n","greeks_df['Delta'].value_counts()\n","enc_df['Delta'].value_counts()\n","'''"]},{"cell_type":"markdown","id":"53909747","metadata":{"papermill":{"duration":0.038652,"end_time":"2023-07-30T19:54:59.946937","exception":false,"start_time":"2023-07-30T19:54:59.908285","status":"completed"},"tags":[]},"source":["# Modeling"]},{"cell_type":"markdown","id":"6ad2d09a","metadata":{"papermill":{"duration":0.039851,"end_time":"2023-07-30T19:55:00.026987","exception":false,"start_time":"2023-07-30T19:54:59.987136","status":"completed"},"tags":[]},"source":["## Evaluation metric"]},{"cell_type":"code","execution_count":22,"id":"13030819","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.106812Z","iopub.status.busy":"2023-07-30T19:55:00.106427Z","iopub.status.idle":"2023-07-30T19:55:00.114668Z","shell.execute_reply":"2023-07-30T19:55:00.113334Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.051682,"end_time":"2023-07-30T19:55:00.117453","exception":false,"start_time":"2023-07-30T19:55:00.065771","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\ndef balanced_log_loss(y_true, y_pred):\\n    # y_true: correct labels 0, 1\\n    # y_pred: predicted probabilities of class=1\\n    # calculate the number of observations for each class\\n    N_0 = np.sum(1 - y_true)\\n    N_1 = np.sum(y_true)\\n    # calculate the weights for each class to balance classes\\n    w_0 = 1 / N_0\\n    w_1 = 1 / N_1\\n    # calculate the predicted probabilities for each class\\n    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\\n    p_0 = 1 - p_1\\n    # calculate the summed log loss for each class\\n    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\\n    log_loss_1 = -np.sum(y_true * np.log(p_1))\\n    # calculate the weighted summed logarithmic loss\\n    # (factor of 2 included to give same result as LL with balanced input)\\n    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\\n    # return the average log loss\\n    return balanced_log_loss/(N_0+N_1)\\n'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","def balanced_log_loss(y_true, y_pred):\n","    # y_true: correct labels 0, 1\n","    # y_pred: predicted probabilities of class=1\n","    # calculate the number of observations for each class\n","    N_0 = np.sum(1 - y_true)\n","    N_1 = np.sum(y_true)\n","    # calculate the weights for each class to balance classes\n","    w_0 = 1 / N_0\n","    w_1 = 1 / N_1\n","    # calculate the predicted probabilities for each class\n","    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n","    p_0 = 1 - p_1\n","    # calculate the summed log loss for each class\n","    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n","    log_loss_1 = -np.sum(y_true * np.log(p_1))\n","    # calculate the weighted summed logarithmic loss\n","    # (factor of 2 included to give same result as LL with balanced input)\n","    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n","    # return the average log loss\n","    return balanced_log_loss/(N_0+N_1)\n","'''"]},{"cell_type":"code","execution_count":23,"id":"66d555fa","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.200159Z","iopub.status.busy":"2023-07-30T19:55:00.199664Z","iopub.status.idle":"2023-07-30T19:55:00.207383Z","shell.execute_reply":"2023-07-30T19:55:00.2059Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.053085,"end_time":"2023-07-30T19:55:00.210064","exception":false,"start_time":"2023-07-30T19:55:00.156979","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["\"\\ndef balanced_log_loss_eval(y_pred, dtrain):\\n    y_true = dtrain.get_label()\\n    bll = balanced_log_loss(y_true, y_pred)\\n    return 'balanced_log_loss', bll, False\\n\""]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","def balanced_log_loss_eval(y_pred, dtrain):\n","    y_true = dtrain.get_label()\n","    bll = balanced_log_loss(y_true, y_pred)\n","    return 'balanced_log_loss', bll, False\n","'''"]},{"cell_type":"code","execution_count":24,"id":"26235ae1","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.29611Z","iopub.status.busy":"2023-07-30T19:55:00.295122Z","iopub.status.idle":"2023-07-30T19:55:00.303399Z","shell.execute_reply":"2023-07-30T19:55:00.302129Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.054289,"end_time":"2023-07-30T19:55:00.305852","exception":false,"start_time":"2023-07-30T19:55:00.251563","status":"completed"},"tags":[]},"outputs":[],"source":["# Drop features not found in test data, Separate the features and target variable\n","#X_df = enc_df.drop([\"Id\", \"Alpha\", \"Beta\", \"Gamma\", \"Delta\",\"Epsilon\",\"Class\"], axis=1)\n","#y_df = enc_df['Class']\n","X_df = merged_df.drop([\"Id\", \"Alpha\", \"Beta\", \"Gamma\", \"Delta\",\"Epsilon\",\"Class\"], axis=1)\n","y_df = merged_df['Class']"]},{"cell_type":"markdown","id":"8c4d1bce","metadata":{"papermill":{"duration":0.04161,"end_time":"2023-07-30T19:55:00.388166","exception":false,"start_time":"2023-07-30T19:55:00.346556","status":"completed"},"tags":[]},"source":["## 1)"]},{"cell_type":"code","execution_count":25,"id":"9dbbfaeb","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.471378Z","iopub.status.busy":"2023-07-30T19:55:00.470873Z","iopub.status.idle":"2023-07-30T19:55:00.483844Z","shell.execute_reply":"2023-07-30T19:55:00.482465Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.05793,"end_time":"2023-07-30T19:55:00.486353","exception":false,"start_time":"2023-07-30T19:55:00.428423","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\ndef objective(trial):\\n    train_x,valid_x,train_y,valid_y=train_test_split(X_df,y_df,test_size=0.2,random_state=42,shuffle=True,stratify=y_df)\\n    \\n    dtrain = lgb.Dataset(train_x,label=train_y,\\n                         feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                       \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                       \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                       \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                       \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                         categorical_feature=[\"EJ\"])\\n    dvalid = lgb.Dataset(valid_x,label=valid_y,\\n                         feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                       \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                       \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                       \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                       \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                         categorical_feature=[\"EJ\"])\\n    \\n    param = {\"objective\": \"binary\",\\n             \"metric\": \"binary_logloss\",\\n             \"verbosity\": -1,\\n             \"boosting_type\": \"gbdt\",\\n             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\\n             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\\n             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\\n             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\\n             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\\n             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\\n             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\\n             \"seed\":42}\\n  \\n    # Train the LightGBM model with the custom evaluation function\\n    gbm = lgb.train(param, dtrain, valid_sets=[dvalid],feval=balanced_log_loss_eval,categorical_feature=[\"EJ\"])\\n    preds = gbm.predict(valid_x)\\n    \\n    bll = balanced_log_loss(valid_y,preds)\\n    \\n    return bll\\n\\n\\nif __name__ == \"__main__\":\\n    # Reproducible optimization results\\n    # https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\\n    sampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\\n    study = optuna.create_study(direction=\"minimize\",sampler=sampler)\\n    study.optimize(objective, n_trials=300)\\n\\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\\n\\n    print(\"Best trial:\")\\n    trial = study.best_trial\\n\\n    print(\"  Value: {}\".format(trial.value))\\n\\n    print(\"  Params: \")\\n    for key, value in trial.params.items():\\n        print(\"    {}: {}\".format(key, value))\\n'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","def objective(trial):\n","    train_x,valid_x,train_y,valid_y=train_test_split(X_df,y_df,test_size=0.2,random_state=42,shuffle=True,stratify=y_df)\n","    \n","    dtrain = lgb.Dataset(train_x,label=train_y,\n","                         feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                         categorical_feature=[\"EJ\"])\n","    dvalid = lgb.Dataset(valid_x,label=valid_y,\n","                         feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                         categorical_feature=[\"EJ\"])\n","    \n","    param = {\"objective\": \"binary\",\n","             \"metric\": \"binary_logloss\",\n","             \"verbosity\": -1,\n","             \"boosting_type\": \"gbdt\",\n","             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","             \"seed\":42}\n","  \n","    # Train the LightGBM model with the custom evaluation function\n","    gbm = lgb.train(param, dtrain, valid_sets=[dvalid],feval=balanced_log_loss_eval,categorical_feature=[\"EJ\"])\n","    preds = gbm.predict(valid_x)\n","    \n","    bll = balanced_log_loss(valid_y,preds)\n","    \n","    return bll\n","\n","\n","if __name__ == \"__main__\":\n","    # Reproducible optimization results\n","    # https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\n","    sampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\n","    study = optuna.create_study(direction=\"minimize\",sampler=sampler)\n","    study.optimize(objective, n_trials=300)\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","'''"]},{"cell_type":"code","execution_count":26,"id":"af3ee87e","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.571193Z","iopub.status.busy":"2023-07-30T19:55:00.570714Z","iopub.status.idle":"2023-07-30T19:55:00.579302Z","shell.execute_reply":"2023-07-30T19:55:00.578316Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.054482,"end_time":"2023-07-30T19:55:00.581753","exception":false,"start_time":"2023-07-30T19:55:00.527271","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nNumber of finished trials: 100\\nBest trial:\\n  Value: 0.20360767490328946\\n  Params: \\n    lambda_l1: 0.00019581436316056585\\n    lambda_l2: 0.00032484094837833774\\n    num_leaves: 37\\n    feature_fraction: 0.8160074937253832\\n    bagging_fraction: 0.8503122588378281\\n    bagging_freq: 4\\n    min_child_samples: 56\\n    \\nNumber of finished trials: 200\\nBest trial:\\n  Value: 0.19274028582043182\\n  Params: \\n    lambda_l1: 0.00024753739779854604\\n    lambda_l2: 0.002320160687709684\\n    num_leaves: 70\\n    feature_fraction: 0.9151613574810961\\n    bagging_fraction: 0.7996847883349252\\n    bagging_freq: 7\\n    min_child_samples: 33\\n    \\nNumber of finished trials: 300\\nBest trial:\\n  Value: 0.1758890868830618\\n  Params: \\n    lambda_l1: 0.00026016459510927616\\n    lambda_l2: 0.0015693248796316954\\n    num_leaves: 65\\n    feature_fraction: 0.9633681484892685\\n    bagging_fraction: 0.7855075941459672\\n    bagging_freq: 7\\n    min_child_samples: 39\\n    \\nNumber of finished trials: 400\\nBest trial:\\n  Value: 0.1758890868830618\\n  Params: \\n    lambda_l1: 0.00026016459510927616\\n    lambda_l2: 0.0015693248796316954\\n    num_leaves: 65\\n    feature_fraction: 0.9633681484892685\\n    bagging_fraction: 0.7855075941459672\\n    bagging_freq: 7\\n    min_child_samples: 39\\n'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Number of finished trials: 100\n","Best trial:\n","  Value: 0.20360767490328946\n","  Params: \n","    lambda_l1: 0.00019581436316056585\n","    lambda_l2: 0.00032484094837833774\n","    num_leaves: 37\n","    feature_fraction: 0.8160074937253832\n","    bagging_fraction: 0.8503122588378281\n","    bagging_freq: 4\n","    min_child_samples: 56\n","    \n","Number of finished trials: 200\n","Best trial:\n","  Value: 0.19274028582043182\n","  Params: \n","    lambda_l1: 0.00024753739779854604\n","    lambda_l2: 0.002320160687709684\n","    num_leaves: 70\n","    feature_fraction: 0.9151613574810961\n","    bagging_fraction: 0.7996847883349252\n","    bagging_freq: 7\n","    min_child_samples: 33\n","    \n","Number of finished trials: 300\n","Best trial:\n","  Value: 0.1758890868830618\n","  Params: \n","    lambda_l1: 0.00026016459510927616\n","    lambda_l2: 0.0015693248796316954\n","    num_leaves: 65\n","    feature_fraction: 0.9633681484892685\n","    bagging_fraction: 0.7855075941459672\n","    bagging_freq: 7\n","    min_child_samples: 39\n","    \n","Number of finished trials: 400\n","Best trial:\n","  Value: 0.1758890868830618\n","  Params: \n","    lambda_l1: 0.00026016459510927616\n","    lambda_l2: 0.0015693248796316954\n","    num_leaves: 65\n","    feature_fraction: 0.9633681484892685\n","    bagging_fraction: 0.7855075941459672\n","    bagging_freq: 7\n","    min_child_samples: 39\n","'''"]},{"cell_type":"markdown","id":"a564fa15","metadata":{"papermill":{"duration":0.038813,"end_time":"2023-07-30T19:55:00.660264","exception":false,"start_time":"2023-07-30T19:55:00.621451","status":"completed"},"tags":[]},"source":["### Submission"]},{"cell_type":"code","execution_count":27,"id":"d1cb7aa0","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.742529Z","iopub.status.busy":"2023-07-30T19:55:00.742099Z","iopub.status.idle":"2023-07-30T19:55:00.751644Z","shell.execute_reply":"2023-07-30T19:55:00.750245Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.053269,"end_time":"2023-07-30T19:55:00.754135","exception":false,"start_time":"2023-07-30T19:55:00.700866","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\n# Get the best hyperparameters from the Optuna study\\nbest_params = study.best_params\\n\\n# Create a LightGBM dataset from the entire training data\\ndtrain = lgb.Dataset(X_df, label=y_df,params={\\'force_col_wise\\': True})\\n\\n# Merge the best_params dictionary with the force_col_wise parameter\\nparams = {**best_params, **{\\'force_col_wise\\': True}}\\n\\n# Train a LightGBM model using the merged parameters\\ngbm = lgb.train(params, dtrain)\\n\\nsubmission_df=test_df.drop([\"Id\"], axis=1)\\nsubmission_df[\\'EJ\\'] = le.transform(submission_df[\\'EJ\\']) # Replaces the original categorical values with their corresponding integer encodings.\\n\\n# Make predictions on unseen data\\npreds = gbm.predict(submission_df)\\n\\n# The predictions are probabilities for class 1\\nprob_class_1 = preds\\n\\n# To get probabilities for class 0, subtract from 1\\nprob_class_0 = 1 - prob_class_1\\n\\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\\nsample = pd.read_csv(\\'/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\\')\\nsample[\\'class_1\\'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\\nsample[\\'class_0\\'] = prob_class_0\\nsample.to_csv(\\'submission.csv\\', index = False)\\n\\n# Display the contents of the submission.csv\\ndisplay(pd.read_csv(\\'submission.csv\\'))\\n'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","# Get the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# Create a LightGBM dataset from the entire training data\n","dtrain = lgb.Dataset(X_df, label=y_df,params={'force_col_wise': True})\n","\n","# Merge the best_params dictionary with the force_col_wise parameter\n","params = {**best_params, **{'force_col_wise': True}}\n","\n","# Train a LightGBM model using the merged parameters\n","gbm = lgb.train(params, dtrain)\n","\n","submission_df=test_df.drop([\"Id\"], axis=1)\n","submission_df['EJ'] = le.transform(submission_df['EJ']) # Replaces the original categorical values with their corresponding integer encodings.\n","\n","# Make predictions on unseen data\n","preds = gbm.predict(submission_df)\n","\n","# The predictions are probabilities for class 1\n","prob_class_1 = preds\n","\n","# To get probabilities for class 0, subtract from 1\n","prob_class_0 = 1 - prob_class_1\n","\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\n","sample = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n","sample['class_1'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\n","sample['class_0'] = prob_class_0\n","sample.to_csv('submission.csv', index = False)\n","\n","# Display the contents of the submission.csv\n","display(pd.read_csv('submission.csv'))\n","'''"]},{"cell_type":"code","execution_count":28,"id":"a8764eb2","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.83572Z","iopub.status.busy":"2023-07-30T19:55:00.835312Z","iopub.status.idle":"2023-07-30T19:55:00.843598Z","shell.execute_reply":"2023-07-30T19:55:00.842251Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.05215,"end_time":"2023-07-30T19:55:00.845923","exception":false,"start_time":"2023-07-30T19:55:00.793773","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nId\\tclass_0\\tclass_1\\n0\\t00eed32682bb\\t0.544107\\t0.455893\\n1\\t010ebe33f668\\t0.544107\\t0.455893\\n2\\t02fa521e1838\\t0.544107\\t0.455893\\n3\\t040e15f562a2\\t0.544107\\t0.455893\\n4\\t046e85c7cc7f\\t0.544107\\t0.455893\\n'"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Id\tclass_0\tclass_1\n","0\t00eed32682bb\t0.544107\t0.455893\n","1\t010ebe33f668\t0.544107\t0.455893\n","2\t02fa521e1838\t0.544107\t0.455893\n","3\t040e15f562a2\t0.544107\t0.455893\n","4\t046e85c7cc7f\t0.544107\t0.455893\n","'''"]},{"cell_type":"code","execution_count":29,"id":"5efb3d64","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:00.928673Z","iopub.status.busy":"2023-07-30T19:55:00.928242Z","iopub.status.idle":"2023-07-30T19:55:00.935329Z","shell.execute_reply":"2023-07-30T19:55:00.93396Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.051475,"end_time":"2023-07-30T19:55:00.937766","exception":false,"start_time":"2023-07-30T19:55:00.886291","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\ndel dtrain, gbm, preds, study, trial\\ndel submission_df, best_params\\ndel prob_class_1, prob_class_0, sample\\n'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","del dtrain, gbm, preds, study, trial\n","del submission_df, best_params\n","del prob_class_1, prob_class_0, sample\n","'''"]},{"cell_type":"markdown","id":"17e4b724","metadata":{"papermill":{"duration":0.040326,"end_time":"2023-07-30T19:55:01.017948","exception":false,"start_time":"2023-07-30T19:55:00.977622","status":"completed"},"tags":[]},"source":["## 2) "]},{"cell_type":"code","execution_count":30,"id":"dd915562","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.100591Z","iopub.status.busy":"2023-07-30T19:55:01.100157Z","iopub.status.idle":"2023-07-30T19:55:01.112233Z","shell.execute_reply":"2023-07-30T19:55:01.110976Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.056927,"end_time":"2023-07-30T19:55:01.114696","exception":false,"start_time":"2023-07-30T19:55:01.057769","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nX = X_df.to_numpy()\\ny = y_df.to_numpy()\\n\\ndef objective(trial):\\n    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\\n    scores = []\\n    \\n    param = {\"objective\": \"binary\",\\n             \"metric\": \"binary_logloss\",\\n             \"verbosity\": -1,\\n             \"boosting_type\": \"gbdt\",\\n             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\\n             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\\n             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\\n             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\\n             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\\n             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\\n             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\\n             \"seed\": 42,\\n             \"learning_rate\":trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\\n            }\\n\\n    for train_index, valid_index in skf.split(X, y):\\n        train_x, valid_x = X[train_index], X[valid_index]\\n        train_y, valid_y = y[train_index], y[valid_index]\\n\\n        dtrain = lgb.Dataset(train_x, label=train_y,\\n                     feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                   \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                   \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                   \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                   \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                     categorical_feature=[\"EJ\"])\\n                                   \\n        dvalid = lgb.Dataset(valid_x, label=valid_y,\\n                     feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                   \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                   \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                   \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                   \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                     categorical_feature=[\"EJ\"])\\n                                   \\n        # Train the LightGBM model with the custom evaluation function\\n        gbm = lgb.train(param, dtrain, valid_sets=[dvalid], feval=balanced_log_loss_eval)\\n        preds = gbm.predict(valid_x)\\n\\n        bll = balanced_log_loss(valid_y, preds)\\n        scores.append(bll)\\n\\n    return np.mean(scores)\\n\\nif __name__ == \"__main__\":\\n    \\n    sampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\\n    study = optuna.create_study(direction=\"minimize\",sampler=sampler)\\n    study.optimize(objective, n_trials=300)\\n\\n\\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\\n\\n    print(\"Best trial:\")\\n    trial = study.best_trial\\n\\n    print(\"  Value: {}\".format(trial.value))\\n\\n    print(\"  Params: \")\\n    for key, value in trial.params.items():\\n        print(\"    {}: {}\".format(key, value))\\n'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","X = X_df.to_numpy()\n","y = y_df.to_numpy()\n","\n","def objective(trial):\n","    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n","    scores = []\n","    \n","    param = {\"objective\": \"binary\",\n","             \"metric\": \"binary_logloss\",\n","             \"verbosity\": -1,\n","             \"boosting_type\": \"gbdt\",\n","             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","             \"seed\": 42,\n","             \"learning_rate\":trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n","            }\n","\n","    for train_index, valid_index in skf.split(X, y):\n","        train_x, valid_x = X[train_index], X[valid_index]\n","        train_y, valid_y = y[train_index], y[valid_index]\n","\n","        dtrain = lgb.Dataset(train_x, label=train_y,\n","                     feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                   'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                   'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                   'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                   'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                     categorical_feature=[\"EJ\"])\n","                                   \n","        dvalid = lgb.Dataset(valid_x, label=valid_y,\n","                     feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                   'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                   'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                   'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                   'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                     categorical_feature=[\"EJ\"])\n","                                   \n","        # Train the LightGBM model with the custom evaluation function\n","        gbm = lgb.train(param, dtrain, valid_sets=[dvalid], feval=balanced_log_loss_eval)\n","        preds = gbm.predict(valid_x)\n","\n","        bll = balanced_log_loss(valid_y, preds)\n","        scores.append(bll)\n","\n","    return np.mean(scores)\n","\n","if __name__ == \"__main__\":\n","    \n","    sampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\n","    study = optuna.create_study(direction=\"minimize\",sampler=sampler)\n","    study.optimize(objective, n_trials=300)\n","\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","'''"]},{"cell_type":"code","execution_count":31,"id":"0f2a646e","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.199441Z","iopub.status.busy":"2023-07-30T19:55:01.198953Z","iopub.status.idle":"2023-07-30T19:55:01.208538Z","shell.execute_reply":"2023-07-30T19:55:01.207292Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.055911,"end_time":"2023-07-30T19:55:01.211049","exception":false,"start_time":"2023-07-30T19:55:01.155138","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nNumber of finished trials: 100\\nBest trial:\\n  Value: 0.22606619458720836\\n  Params: \\n    lambda_l1: 0.0009562865883307864\\n    lambda_l2: 1.0501184667562712e-05\\n    num_leaves: 196\\n    feature_fraction: 0.8877290003776485\\n    bagging_fraction: 0.855495279749778\\n    bagging_freq: 2\\n    min_child_samples: 73\\n    learning_rate: 0.07893136657351986\\n    \\nNumber of finished trials: 200\\nBest trial:\\n  Value: 0.2165360692415715\\n  Params: \\n    lambda_l1: 0.0005763971757861298\\n    lambda_l2: 5.567550574259273e-05\\n    num_leaves: 197\\n    feature_fraction: 0.8936258395576222\\n    bagging_fraction: 0.8839392483012035\\n    bagging_freq: 2\\n    min_child_samples: 71\\n    learning_rate: 0.09824604022136249\\n    \\nNumber of finished trials: 300\\nBest trial:\\n  Value: 0.20683746255683158\\n  Params: \\n    lambda_l1: 7.940111512618743e-06\\n    lambda_l2: 1.774347600050857e-06\\n    num_leaves: 215\\n    feature_fraction: 0.9988662903874678\\n    bagging_fraction: 0.8490318978526208\\n    bagging_freq: 1\\n    min_child_samples: 64\\n    learning_rate: 0.07562682408122855\\n    \\nNumber of finished trials: 400\\nBest trial:\\n  Value: 0.20683746255683158\\n  Params: \\n    lambda_l1: 7.940111512618743e-06\\n    lambda_l2: 1.774347600050857e-06\\n    num_leaves: 215\\n    feature_fraction: 0.9988662903874678\\n    bagging_fraction: 0.8490318978526208\\n    bagging_freq: 1\\n    min_child_samples: 64\\n    learning_rate: 0.07562682408122855\\n'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Number of finished trials: 100\n","Best trial:\n","  Value: 0.22606619458720836\n","  Params: \n","    lambda_l1: 0.0009562865883307864\n","    lambda_l2: 1.0501184667562712e-05\n","    num_leaves: 196\n","    feature_fraction: 0.8877290003776485\n","    bagging_fraction: 0.855495279749778\n","    bagging_freq: 2\n","    min_child_samples: 73\n","    learning_rate: 0.07893136657351986\n","    \n","Number of finished trials: 200\n","Best trial:\n","  Value: 0.2165360692415715\n","  Params: \n","    lambda_l1: 0.0005763971757861298\n","    lambda_l2: 5.567550574259273e-05\n","    num_leaves: 197\n","    feature_fraction: 0.8936258395576222\n","    bagging_fraction: 0.8839392483012035\n","    bagging_freq: 2\n","    min_child_samples: 71\n","    learning_rate: 0.09824604022136249\n","    \n","Number of finished trials: 300\n","Best trial:\n","  Value: 0.20683746255683158\n","  Params: \n","    lambda_l1: 7.940111512618743e-06\n","    lambda_l2: 1.774347600050857e-06\n","    num_leaves: 215\n","    feature_fraction: 0.9988662903874678\n","    bagging_fraction: 0.8490318978526208\n","    bagging_freq: 1\n","    min_child_samples: 64\n","    learning_rate: 0.07562682408122855\n","    \n","Number of finished trials: 400\n","Best trial:\n","  Value: 0.20683746255683158\n","  Params: \n","    lambda_l1: 7.940111512618743e-06\n","    lambda_l2: 1.774347600050857e-06\n","    num_leaves: 215\n","    feature_fraction: 0.9988662903874678\n","    bagging_fraction: 0.8490318978526208\n","    bagging_freq: 1\n","    min_child_samples: 64\n","    learning_rate: 0.07562682408122855\n","'''"]},{"cell_type":"markdown","id":"7a6438a0","metadata":{"papermill":{"duration":0.042952,"end_time":"2023-07-30T19:55:01.296826","exception":false,"start_time":"2023-07-30T19:55:01.253874","status":"completed"},"tags":[]},"source":["### Submission"]},{"cell_type":"code","execution_count":32,"id":"03eab880","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.393995Z","iopub.status.busy":"2023-07-30T19:55:01.393622Z","iopub.status.idle":"2023-07-30T19:55:01.402281Z","shell.execute_reply":"2023-07-30T19:55:01.400913Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.064892,"end_time":"2023-07-30T19:55:01.404937","exception":false,"start_time":"2023-07-30T19:55:01.340045","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\n# Get the best hyperparameters from the Optuna study\\nbest_params = study.best_params\\n\\n# Create a LightGBM dataset from the entire training data\\ndtrain = lgb.Dataset(X_df, label=y_df,params={\\'force_col_wise\\': True})\\n\\n# Merge the best_params dictionary with the force_col_wise parameter\\nparams = {**best_params, **{\\'force_col_wise\\': True}}\\n\\n# Train a LightGBM model using the merged parameters\\ngbm = lgb.train(params, dtrain)\\n\\nsubmission_df=test_df.drop([\"Id\"], axis=1)\\nsubmission_df[\\'EJ\\'] = le.transform(submission_df[\\'EJ\\']) # Replaces the original categorical values with their corresponding integer encodings.\\n\\n# Make predictions on unseen data\\npreds = gbm.predict(submission_df)\\n\\n# The predictions are probabilities for class 1\\nprob_class_1 = preds\\n\\n# To get probabilities for class 0, subtract from 1\\nprob_class_0 = 1 - prob_class_1\\n\\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\\nsample = pd.read_csv(\\'/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\\')\\nsample[\\'class_1\\'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\\nsample[\\'class_0\\'] = prob_class_0\\nsample.to_csv(\\'submission.csv\\', index = False)\\n\\n# Display the contents of the submission.csv\\ndisplay(pd.read_csv(\\'submission.csv\\'))\\n'"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","# Get the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# Create a LightGBM dataset from the entire training data\n","dtrain = lgb.Dataset(X_df, label=y_df,params={'force_col_wise': True})\n","\n","# Merge the best_params dictionary with the force_col_wise parameter\n","params = {**best_params, **{'force_col_wise': True}}\n","\n","# Train a LightGBM model using the merged parameters\n","gbm = lgb.train(params, dtrain)\n","\n","submission_df=test_df.drop([\"Id\"], axis=1)\n","submission_df['EJ'] = le.transform(submission_df['EJ']) # Replaces the original categorical values with their corresponding integer encodings.\n","\n","# Make predictions on unseen data\n","preds = gbm.predict(submission_df)\n","\n","# The predictions are probabilities for class 1\n","prob_class_1 = preds\n","\n","# To get probabilities for class 0, subtract from 1\n","prob_class_0 = 1 - prob_class_1\n","\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\n","sample = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n","sample['class_1'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\n","sample['class_0'] = prob_class_0\n","sample.to_csv('submission.csv', index = False)\n","\n","# Display the contents of the submission.csv\n","display(pd.read_csv('submission.csv'))\n","'''"]},{"cell_type":"code","execution_count":33,"id":"20344960","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.492415Z","iopub.status.busy":"2023-07-30T19:55:01.491856Z","iopub.status.idle":"2023-07-30T19:55:01.500402Z","shell.execute_reply":"2023-07-30T19:55:01.499116Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.056067,"end_time":"2023-07-30T19:55:01.503483","exception":false,"start_time":"2023-07-30T19:55:01.447416","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nNumber of finished trials: 100:\\nId\\tclass_0\\tclass_1\\n0\\t00eed32682bb\\t0.595334\\t0.404666\\n1\\t010ebe33f668\\t0.595334\\t0.404666\\n2\\t02fa521e1838\\t0.595334\\t0.404666\\n3\\t040e15f562a2\\t0.595334\\t0.404666\\n4\\t046e85c7cc7f\\t0.595334\\t0.404666\\n\\nNumber of finished trials: 300:\\n\\tId\\tclass_0\\tclass_1\\n0\\t00eed32682bb\\t0.581345\\t0.418655\\n1\\t010ebe33f668\\t0.581345\\t0.418655\\n2\\t02fa521e1838\\t0.581345\\t0.418655\\n3\\t040e15f562a2\\t0.581345\\t0.418655\\n4\\t046e85c7cc7f\\t0.581345\\t0.418655\\n'"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Number of finished trials: 100:\n","Id\tclass_0\tclass_1\n","0\t00eed32682bb\t0.595334\t0.404666\n","1\t010ebe33f668\t0.595334\t0.404666\n","2\t02fa521e1838\t0.595334\t0.404666\n","3\t040e15f562a2\t0.595334\t0.404666\n","4\t046e85c7cc7f\t0.595334\t0.404666\n","\n","Number of finished trials: 300:\n","\tId\tclass_0\tclass_1\n","0\t00eed32682bb\t0.581345\t0.418655\n","1\t010ebe33f668\t0.581345\t0.418655\n","2\t02fa521e1838\t0.581345\t0.418655\n","3\t040e15f562a2\t0.581345\t0.418655\n","4\t046e85c7cc7f\t0.581345\t0.418655\n","'''"]},{"cell_type":"code","execution_count":34,"id":"1999edc5","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.589529Z","iopub.status.busy":"2023-07-30T19:55:01.588756Z","iopub.status.idle":"2023-07-30T19:55:01.596508Z","shell.execute_reply":"2023-07-30T19:55:01.595382Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.053781,"end_time":"2023-07-30T19:55:01.599017","exception":false,"start_time":"2023-07-30T19:55:01.545236","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\ndel dtrain, gbm, preds, study, trial\\ndel submission_df, best_params\\ndel prob_class_1, prob_class_0, sample\\n'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","del dtrain, gbm, preds, study, trial\n","del submission_df, best_params\n","del prob_class_1, prob_class_0, sample\n","'''"]},{"cell_type":"markdown","id":"10bc4e67","metadata":{"papermill":{"duration":0.043069,"end_time":"2023-07-30T19:55:01.682979","exception":false,"start_time":"2023-07-30T19:55:01.63991","status":"completed"},"tags":[]},"source":["## 3) LightGBMTunerCV"]},{"cell_type":"code","execution_count":35,"id":"e7c2a067","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.767315Z","iopub.status.busy":"2023-07-30T19:55:01.766088Z","iopub.status.idle":"2023-07-30T19:55:01.777843Z","shell.execute_reply":"2023-07-30T19:55:01.776727Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.056362,"end_time":"2023-07-30T19:55:01.780257","exception":false,"start_time":"2023-07-30T19:55:01.723895","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nimport optuna.integration.lightgbm as lgb\\nfrom lightgbm import early_stopping\\nfrom lightgbm import log_evaluation\\nimport sklearn.datasets\\nfrom sklearn.model_selection import StratifiedKFold\\n\\ndef objective(trial):\\n    dtrain = lgb.Dataset(X_df,label=y_df,                      \\n                         feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                       \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                       \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                       \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                       \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                         categorical_feature=[\"EJ\"])\\n\\n    param = {\"objective\": \"binary\",\\n             \"metric\": \"binary_logloss\",\\n             \"verbosity\": -1,\\n             \"boosting_type\": \"gbdt\",\\n             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\\n             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\\n             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\\n             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\\n             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\\n             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\\n             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\\n             \"seed\": 42}\\n\\n    tuner = lgb.LightGBMTunerCV(param,\\n                                dtrain,\\n                                folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\\n                                callbacks=[early_stopping(100),\\n                                           log_evaluation(100)],\\n                                optuna_seed=42,\\n                                feval=balanced_log_loss_eval,\\n                                categorical_feature=[\"EJ\"]\\n                                )\\n    tuner.run()\\n\\n    return tuner.best_score\\n\\nsampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\\nstudy = optuna.create_study(direction=\"minimize\",sampler=sampler)\\nstudy.optimize(objective, n_trials=100)\\n\\nprint(\"Best score:\", study.best_value)\\nbest_params = study.best_params\\nprint(\"Best params:\", best_params)\\nprint(\"  Params: \")\\nfor key, value in best_params.items():\\n    print(\"    {}: {}\".format(key, value))\\n'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","import optuna.integration.lightgbm as lgb\n","from lightgbm import early_stopping\n","from lightgbm import log_evaluation\n","import sklearn.datasets\n","from sklearn.model_selection import StratifiedKFold\n","\n","def objective(trial):\n","    dtrain = lgb.Dataset(X_df,label=y_df,                      \n","                         feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                         categorical_feature=[\"EJ\"])\n","\n","    param = {\"objective\": \"binary\",\n","             \"metric\": \"binary_logloss\",\n","             \"verbosity\": -1,\n","             \"boosting_type\": \"gbdt\",\n","             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","             \"seed\": 42}\n","\n","    tuner = lgb.LightGBMTunerCV(param,\n","                                dtrain,\n","                                folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n","                                callbacks=[early_stopping(100),\n","                                           log_evaluation(100)],\n","                                optuna_seed=42,\n","                                feval=balanced_log_loss_eval,\n","                                categorical_feature=[\"EJ\"]\n","                                )\n","    tuner.run()\n","\n","    return tuner.best_score\n","\n","sampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\n","study = optuna.create_study(direction=\"minimize\",sampler=sampler)\n","study.optimize(objective, n_trials=100)\n","\n","print(\"Best score:\", study.best_value)\n","best_params = study.best_params\n","print(\"Best params:\", best_params)\n","print(\"  Params: \")\n","for key, value in best_params.items():\n","    print(\"    {}: {}\".format(key, value))\n","'''"]},{"cell_type":"code","execution_count":36,"id":"df295be8","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:01.867144Z","iopub.status.busy":"2023-07-30T19:55:01.86666Z","iopub.status.idle":"2023-07-30T19:55:01.878502Z","shell.execute_reply":"2023-07-30T19:55:01.877283Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.058067,"end_time":"2023-07-30T19:55:01.881011","exception":false,"start_time":"2023-07-30T19:55:01.822944","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["\"\\nBest score: 0.16610925806720525\\nBest params: {'lambda_l1': 2.348881295853308e-05, 'lambda_l2': 3.6010467344475403, 'num_leaves': 188, 'feature_fraction': 0.759195090518222, 'bagging_fraction': 0.4936111842654619, 'bagging_freq': 2, 'min_child_samples': 10}\\n  Params: \\n    lambda_l1: 2.348881295853308e-05\\n    lambda_l2: 3.6010467344475403\\n    num_leaves: 188\\n    feature_fraction: 0.759195090518222\\n    bagging_fraction: 0.4936111842654619\\n    bagging_freq: 2\\n    min_child_samples: 10\\n\""]},"execution_count":36,"metadata":{},"output_type":"execute_result"},{"data":{"text/plain":["\"\\nBest score: 0.16501718423663816\\nBest params: {'lambda_l1': 0.018919430862786926, 'lambda_l2': 2.0866860111902543, 'num_leaves': 146, 'feature_fraction': 0.7052977973517935, 'bagging_fraction': 0.7029310340616282, 'bagging_freq': 2, 'min_child_samples': 6}\\n  Params: \\n    lambda_l1: 0.018919430862786926\\n    lambda_l2: 2.0866860111902543\\n    num_leaves: 146\\n    feature_fraction: 0.7052977973517935\\n    bagging_fraction: 0.7029310340616282\\n    bagging_freq: 2\\n    min_child_samples: 6\\n\""]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# ** Long running time\n","\n","'''\n","Best score: 0.16610925806720525\n","Best params: {'lambda_l1': 2.348881295853308e-05, 'lambda_l2': 3.6010467344475403, 'num_leaves': 188, 'feature_fraction': 0.759195090518222, 'bagging_fraction': 0.4936111842654619, 'bagging_freq': 2, 'min_child_samples': 10}\n","  Params: \n","    lambda_l1: 2.348881295853308e-05\n","    lambda_l2: 3.6010467344475403\n","    num_leaves: 188\n","    feature_fraction: 0.759195090518222\n","    bagging_fraction: 0.4936111842654619\n","    bagging_freq: 2\n","    min_child_samples: 10\n","'''\n","\n","'''\n","Best score: 0.16501718423663816\n","Best params: {'lambda_l1': 0.018919430862786926, 'lambda_l2': 2.0866860111902543, 'num_leaves': 146, 'feature_fraction': 0.7052977973517935, 'bagging_fraction': 0.7029310340616282, 'bagging_freq': 2, 'min_child_samples': 6}\n","  Params: \n","    lambda_l1: 0.018919430862786926\n","    lambda_l2: 2.0866860111902543\n","    num_leaves: 146\n","    feature_fraction: 0.7052977973517935\n","    bagging_fraction: 0.7029310340616282\n","    bagging_freq: 2\n","    min_child_samples: 6\n","'''"]},{"cell_type":"markdown","id":"63f9f646","metadata":{"papermill":{"duration":0.04122,"end_time":"2023-07-30T19:55:01.964338","exception":false,"start_time":"2023-07-30T19:55:01.923118","status":"completed"},"tags":[]},"source":["### Submission"]},{"cell_type":"code","execution_count":37,"id":"029ce051","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:02.068447Z","iopub.status.busy":"2023-07-30T19:55:02.067622Z","iopub.status.idle":"2023-07-30T19:55:02.074334Z","shell.execute_reply":"2023-07-30T19:55:02.073417Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.061558,"end_time":"2023-07-30T19:55:02.076559","exception":false,"start_time":"2023-07-30T19:55:02.015001","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nsubmission_df=test_df.drop([\"Id\"], axis=1)\\nsubmission_df[\\'EJ\\'] = le.transform(submission_df[\\'EJ\\']) # Replaces the original categorical values with their corresponding integer encodings.\\n\\n# Create a LightGBM dataset from the entire training data\\ndtrain = lgb.Dataset(X_df,label=y_df,params={\\'force_col_wise\\': True})\\n\\ngbm = lgb.train(best_params,dtrain)\\npreds = gbm.predict_proba(submission_df)\\n'"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","submission_df=test_df.drop([\"Id\"], axis=1)\n","submission_df['EJ'] = le.transform(submission_df['EJ']) # Replaces the original categorical values with their corresponding integer encodings.\n","\n","# Create a LightGBM dataset from the entire training data\n","dtrain = lgb.Dataset(X_df,label=y_df,params={'force_col_wise': True})\n","\n","gbm = lgb.train(best_params,dtrain)\n","preds = gbm.predict_proba(submission_df)\n","'''"]},{"cell_type":"code","execution_count":38,"id":"d9dc41e7","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:02.163663Z","iopub.status.busy":"2023-07-30T19:55:02.162808Z","iopub.status.idle":"2023-07-30T19:55:02.17433Z","shell.execute_reply":"2023-07-30T19:55:02.172753Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.0588,"end_time":"2023-07-30T19:55:02.177244","exception":false,"start_time":"2023-07-30T19:55:02.118444","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nimport optuna.integration.lightgbm as lgb\\n\\nfrom lightgbm import early_stopping\\nfrom lightgbm import log_evaluation\\nimport sklearn.datasets\\n#from sklearn.model_selection import KFold\\nfrom sklearn.model_selection import StratifiedKFold\\n\\nif __name__ == \"__main__\":\\n    dtrain = lgb.Dataset(X_df, label=y_df,\\n                         feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                       \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                       \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                       \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                       \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                         categorical_feature=[\"EJ\"])\\n\\n    param = {\"objective\": \"binary\",\\n             \"metric\": \"binary_logloss\",\\n             \"verbosity\": -1,\\n             \"boosting_type\": \"gbdt\",\\n             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\\n             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\\n             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\\n             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\\n             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\\n             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\\n             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\\n             \"seed\":42,\\n             \"use_missing\":True}\\n        \\n    tuner = lgb.LightGBMTunerCV(param,\\n                                dtrain,\\n                                folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\\n                                callbacks=[early_stopping(100), \\n                                           log_evaluation(100)],\\n                                optuna_seed=42,\\n                                feval=balanced_log_loss_eval,\\n                                feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                              \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                              \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                              \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                              \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                                categorical_feature=[\"EJ\"]\\n                               )\\n   \\n    tuner.run()\\n\\n    print(\"Best score:\", tuner.best_score)\\n    best_params = tuner.best_params\\n    print(\"Best params:\", best_params)\\n    print(\"  Params: \")\\n    for key, value in best_params.items():\\n        print(\"    {}: {}\".format(key, value))\\n'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","import optuna.integration.lightgbm as lgb\n","\n","from lightgbm import early_stopping\n","from lightgbm import log_evaluation\n","import sklearn.datasets\n","#from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","if __name__ == \"__main__\":\n","    dtrain = lgb.Dataset(X_df, label=y_df,\n","                         feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                         categorical_feature=[\"EJ\"])\n","\n","    param = {\"objective\": \"binary\",\n","             \"metric\": \"binary_logloss\",\n","             \"verbosity\": -1,\n","             \"boosting_type\": \"gbdt\",\n","             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","             \"seed\":42,\n","             \"use_missing\":True}\n","        \n","    tuner = lgb.LightGBMTunerCV(param,\n","                                dtrain,\n","                                folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n","                                callbacks=[early_stopping(100), \n","                                           log_evaluation(100)],\n","                                optuna_seed=42,\n","                                feval=balanced_log_loss_eval,\n","                                feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                              'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                              'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                              'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                              'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                                categorical_feature=[\"EJ\"]\n","                               )\n","   \n","    tuner.run()\n","\n","    print(\"Best score:\", tuner.best_score)\n","    best_params = tuner.best_params\n","    print(\"Best params:\", best_params)\n","    print(\"  Params: \")\n","    for key, value in best_params.items():\n","        print(\"    {}: {}\".format(key, value))\n","'''"]},{"cell_type":"code","execution_count":39,"id":"54097639","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:02.266415Z","iopub.status.busy":"2023-07-30T19:55:02.265649Z","iopub.status.idle":"2023-07-30T19:55:02.277045Z","shell.execute_reply":"2023-07-30T19:55:02.276127Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.059188,"end_time":"2023-07-30T19:55:02.279204","exception":false,"start_time":"2023-07-30T19:55:02.220016","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nimport optuna.integration.lightgbm as lgb\\nfrom lightgbm import early_stopping\\nfrom lightgbm import log_evaluation\\nimport sklearn.datasets\\nfrom sklearn.model_selection import StratifiedKFold\\n\\nif __name__ == \"__main__\":\\n    # Dataset initialization\\n    dtrain = lgb.Dataset(X_df, label=y_df,\\n                         feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD \\', \\'BN\\', \\'BP\\',\\n                                       \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD \\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                       \\'CW \\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                       \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD \\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                       \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                         categorical_feature=[\"EJ\"])\\n\\n    def objective(trial):\\n        param = {\\n            \"objective\": \"binary\",\\n            \"metric\": \"binary_logloss\",\\n            \"verbosity\": -1,\\n            \"boosting_type\": \"gbdt\",\\n            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\\n            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\\n            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\\n            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\\n            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\\n            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\\n            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\\n            \"seed\": 42,\\n            \"use_missing\": True\\n        }\\n\\n        tuner = lgb.LightGBMTunerCV(param,\\n                                    dtrain,\\n                                    folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\\n                                    callbacks=[early_stopping(100),\\n                                               log_evaluation(100)],\\n                                    optuna_seed=42,\\n                                    feval=balanced_log_loss_eval,\\n                                    feature_name=[\\'AB\\', \\'AF\\', \\'AH\\', \\'AM\\', \\'AR\\', \\'AX\\', \\'AY\\', \\'AZ\\', \\'BC\\', \\'BD\\', \\'BN\\', \\'BP\\',\\n                                                  \\'BQ\\', \\'BR\\', \\'BZ\\', \\'CB\\', \\'CC\\', \\'CD\\', \\'CF\\', \\'CH\\', \\'CL\\', \\'CR\\', \\'CS\\', \\'CU\\',\\n                                                  \\'CW\\', \\'DA\\', \\'DE\\', \\'DF\\', \\'DH\\', \\'DI\\', \\'DL\\', \\'DN\\', \\'DU\\', \\'DV\\', \\'DY\\', \\'EB\\',\\n                                                  \\'EE\\', \\'EG\\', \\'EH\\', \\'EJ\\', \\'EL\\', \\'EP\\', \\'EU\\', \\'FC\\', \\'FD\\', \\'FE\\', \\'FI\\', \\'FL\\',\\n                                                  \\'FR\\', \\'FS\\', \\'GB\\', \\'GE\\', \\'GF\\', \\'GH\\', \\'GI\\', \\'GL\\'],\\n                                    categorical_feature=[\"EJ\"]\\n                                    )\\n        tuner.run()\\n\\n        return tuner.best_score\\n\\n    study = optuna.create_study(direction=\"minimize\")\\n    study.optimize(objective, n_trials=100)\\n\\n    print(\"Best score:\", study.best_value)\\n    best_params = study.best_params\\n    print(\"Best params:\", best_params)\\n    print(\"  Params: \")\\n    for key, value in best_params.items():\\n        print(\"    {}: {}\".format(key, value))\\n'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","import optuna.integration.lightgbm as lgb\n","from lightgbm import early_stopping\n","from lightgbm import log_evaluation\n","import sklearn.datasets\n","from sklearn.model_selection import StratifiedKFold\n","\n","if __name__ == \"__main__\":\n","    # Dataset initialization\n","    dtrain = lgb.Dataset(X_df, label=y_df,\n","                         feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN', 'BP',\n","                                       'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                       'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                       'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI', 'FL',\n","                                       'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                         categorical_feature=[\"EJ\"])\n","\n","    def objective(trial):\n","        param = {\n","            \"objective\": \"binary\",\n","            \"metric\": \"binary_logloss\",\n","            \"verbosity\": -1,\n","            \"boosting_type\": \"gbdt\",\n","            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","            \"seed\": 42,\n","            \"use_missing\": True\n","        }\n","\n","        tuner = lgb.LightGBMTunerCV(param,\n","                                    dtrain,\n","                                    folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n","                                    callbacks=[early_stopping(100),\n","                                               log_evaluation(100)],\n","                                    optuna_seed=42,\n","                                    feval=balanced_log_loss_eval,\n","                                    feature_name=['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN', 'BP',\n","                                                  'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU',\n","                                                  'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB',\n","                                                  'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI', 'FL',\n","                                                  'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL'],\n","                                    categorical_feature=[\"EJ\"]\n","                                    )\n","        tuner.run()\n","\n","        return tuner.best_score\n","\n","    study = optuna.create_study(direction=\"minimize\")\n","    study.optimize(objective, n_trials=100)\n","\n","    print(\"Best score:\", study.best_value)\n","    best_params = study.best_params\n","    print(\"Best params:\", best_params)\n","    print(\"  Params: \")\n","    for key, value in best_params.items():\n","        print(\"    {}: {}\".format(key, value))\n","'''"]},{"cell_type":"markdown","id":"75d7b283","metadata":{"papermill":{"duration":0.043978,"end_time":"2023-07-30T19:55:02.366736","exception":false,"start_time":"2023-07-30T19:55:02.322758","status":"completed"},"tags":[]},"source":["## 4) A pruner for LightGBM"]},{"cell_type":"code","execution_count":40,"id":"982042f8","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:02.45627Z","iopub.status.busy":"2023-07-30T19:55:02.455506Z","iopub.status.idle":"2023-07-30T19:55:02.466762Z","shell.execute_reply":"2023-07-30T19:55:02.465844Z"},"papermill":{"duration":0.058734,"end_time":"2023-07-30T19:55:02.469097","exception":false,"start_time":"2023-07-30T19:55:02.410363","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nX = X_df.to_numpy()\\ny = y_df.to_numpy()\\n\\n# FYI: Objective functions can take additional arguments\\n# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\\ndef objective(trial):\\n    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\\n    scores = []\\n    \\n    param = {\"objective\": \"binary\",\\n             \"metric\": \"binary_logloss\",\\n             \"verbosity\": -1,\\n             \"boosting_type\": \"gbdt\",\\n             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\\n             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\\n             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\\n             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\\n             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\\n             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\\n             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\\n             \"seed\": 42,\\n             \"learning_rate\":trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\\n            }\\n\\n    for train_index, valid_index in skf.split(X, y):\\n        train_x, valid_x = X[train_index], X[valid_index]\\n        train_y, valid_y = y[train_index], y[valid_index]\\n    \\n        dtrain = lgb.Dataset(train_x,label=train_y,\\n                             feature_name=[\"AB\", \"AF\", \"AH\", \"AM\", \"AR\", \"AX\", \"AY\", \"AZ\", \"BC\", \"BD \", \"BN\", \"BP\",\\n                                           \"BQ\", \"BR\", \"BZ\", \"CB\", \"CC\", \"CD \", \"CF\", \"CH\", \"CL\", \"CR\", \"CS\", \"CU\",\\n                                           \"CW \", \"DA\", \"DE\", \"DF\", \"DH\", \"DI\", \"DL\", \"DN\", \"DU\", \"DV\", \"DY\", \"EB\",\\n                                           \"EE\", \"EG\", \"EH\", \"EJ\", \"EL\", \"EP\", \"EU\", \"FC\", \"FD \", \"FE\", \"FI\", \"FL\",\\n                                           \"FR\", \"FS\", \"GB\", \"GE\", \"GF\", \"GH\", \"GI\", \"GL\"],\\n                             categorical_feature=[\"EJ\"]\\n                            )\\n        dvalid = lgb.Dataset(valid_x,label=valid_y,\\n                             feature_name=[\"AB\", \"AF\", \"AH\", \"AM\", \"AR\", \"AX\", \"AY\", \"AZ\", \"BC\", \"BD \", \"BN\", \"BP\",\\n                                           \"BQ\", \"BR\", \"BZ\", \"CB\", \"CC\", \"CD \", \"CF\", \"CH\", \"CL\", \"CR\", \"CS\", \"CU\",\\n                                           \"CW \", \"DA\", \"DE\", \"DF\", \"DH\", \"DI\", \"DL\", \"DN\", \"DU\", \"DV\", \"DY\", \"EB\",\\n                                           \"EE\", \"EG\", \"EH\", \"EJ\", \"EL\", \"EP\", \"EU\", \"FC\", \"FD \", \"FE\", \"FI\", \"FL\",\\n                                           \"FR\", \"FS\", \"GB\", \"GE\", \"GF\", \"GH\", \"GI\", \"GL\"],\\n                             categorical_feature=[\"EJ\"]\\n                            )\\n\\n        # Add a callback for pruning.\\n        # https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric\\n        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"\") \\n\\n        gbm = lgb.train(param, dtrain, valid_sets=[dvalid],feval=balanced_log_loss_eval,categorical_feature=[\"EJ\"])\\n\\n        preds = gbm.predict(valid_x)\\n        \\n        bll = balanced_log_loss(valid_y,preds)\\n\\n        return bll\\n\\nif __name__ == \"__main__\":\\n    # https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\\n    # Make the sampler behave in a deterministic way\\n    sampler = TPESampler(seed=42)  \\n    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\",sampler=sampler)\\n    study.optimize(objective, n_trials=300)\\n\\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\\n\\n    print(\"Best trial:\")\\n    trial = study.best_trial\\n\\n    print(\"  Value: {}\".format(trial.value))\\n\\n    print(\"  Params: \")\\n    for key, value in trial.params.items():\\n        print(\"    {}: {}\".format(key, value))\\n'"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","X = X_df.to_numpy()\n","y = y_df.to_numpy()\n","\n","# FYI: Objective functions can take additional arguments\n","# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n","def objective(trial):\n","    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n","    scores = []\n","    \n","    param = {\"objective\": \"binary\",\n","             \"metric\": \"binary_logloss\",\n","             \"verbosity\": -1,\n","             \"boosting_type\": \"gbdt\",\n","             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","             \"seed\": 42,\n","             \"learning_rate\":trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n","            }\n","\n","    for train_index, valid_index in skf.split(X, y):\n","        train_x, valid_x = X[train_index], X[valid_index]\n","        train_y, valid_y = y[train_index], y[valid_index]\n","    \n","        dtrain = lgb.Dataset(train_x,label=train_y,\n","                             feature_name=[\"AB\", \"AF\", \"AH\", \"AM\", \"AR\", \"AX\", \"AY\", \"AZ\", \"BC\", \"BD \", \"BN\", \"BP\",\n","                                           \"BQ\", \"BR\", \"BZ\", \"CB\", \"CC\", \"CD \", \"CF\", \"CH\", \"CL\", \"CR\", \"CS\", \"CU\",\n","                                           \"CW \", \"DA\", \"DE\", \"DF\", \"DH\", \"DI\", \"DL\", \"DN\", \"DU\", \"DV\", \"DY\", \"EB\",\n","                                           \"EE\", \"EG\", \"EH\", \"EJ\", \"EL\", \"EP\", \"EU\", \"FC\", \"FD \", \"FE\", \"FI\", \"FL\",\n","                                           \"FR\", \"FS\", \"GB\", \"GE\", \"GF\", \"GH\", \"GI\", \"GL\"],\n","                             categorical_feature=[\"EJ\"]\n","                            )\n","        dvalid = lgb.Dataset(valid_x,label=valid_y,\n","                             feature_name=[\"AB\", \"AF\", \"AH\", \"AM\", \"AR\", \"AX\", \"AY\", \"AZ\", \"BC\", \"BD \", \"BN\", \"BP\",\n","                                           \"BQ\", \"BR\", \"BZ\", \"CB\", \"CC\", \"CD \", \"CF\", \"CH\", \"CL\", \"CR\", \"CS\", \"CU\",\n","                                           \"CW \", \"DA\", \"DE\", \"DF\", \"DH\", \"DI\", \"DL\", \"DN\", \"DU\", \"DV\", \"DY\", \"EB\",\n","                                           \"EE\", \"EG\", \"EH\", \"EJ\", \"EL\", \"EP\", \"EU\", \"FC\", \"FD \", \"FE\", \"FI\", \"FL\",\n","                                           \"FR\", \"FS\", \"GB\", \"GE\", \"GF\", \"GH\", \"GI\", \"GL\"],\n","                             categorical_feature=[\"EJ\"]\n","                            )\n","\n","        # Add a callback for pruning.\n","        # https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric\n","        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"\") \n","\n","        gbm = lgb.train(param, dtrain, valid_sets=[dvalid],feval=balanced_log_loss_eval,categorical_feature=[\"EJ\"])\n","\n","        preds = gbm.predict(valid_x)\n","        \n","        bll = balanced_log_loss(valid_y,preds)\n","\n","        return bll\n","\n","if __name__ == \"__main__\":\n","    # https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\n","    # Make the sampler behave in a deterministic way\n","    sampler = TPESampler(seed=42)  \n","    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\",sampler=sampler)\n","    study.optimize(objective, n_trials=300)\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","'''"]},{"cell_type":"code","execution_count":41,"id":"c3c25b75","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:02.559133Z","iopub.status.busy":"2023-07-30T19:55:02.55833Z","iopub.status.idle":"2023-07-30T19:55:02.570738Z","shell.execute_reply":"2023-07-30T19:55:02.569748Z"},"papermill":{"duration":0.060937,"end_time":"2023-07-30T19:55:02.573654","exception":false,"start_time":"2023-07-30T19:55:02.512717","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the column transformer to perform encoding and imputation\n","preprocessor = ColumnTransformer(transformers=[('cat', \n","                                                Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n","                                                                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))]),\n","                                                [39]),  # Use integer column index instead of string column name\n","                                               ('num', \n","                                                SimpleImputer(strategy='median'), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n","                                                                                   11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n","                                                                                   21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n","                                                                                   31, 32, 33, 34, 35, 36, 37, 38, 40,\n","                                                                                   41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n","                                                                                   51, 52, 53, 54, 55])  \n","                                              ],\n","                                 remainder='passthrough', sparse_threshold=0)\n","\n","X = X_df.to_numpy()\n","y = y_df.to_numpy()"]},{"cell_type":"code","execution_count":42,"id":"18649b91","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:55:02.664489Z","iopub.status.busy":"2023-07-30T19:55:02.663762Z","iopub.status.idle":"2023-07-30T19:56:56.897891Z","shell.execute_reply":"2023-07-30T19:56:56.897096Z"},"papermill":{"duration":114.282082,"end_time":"2023-07-30T19:56:56.900591","exception":false,"start_time":"2023-07-30T19:55:02.618509","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-07-30 19:55:02,681] A new study created in memory with name: no-name-7def33c1-6e8b-4446-9120-8239fd2ca20c\n","[I 2023-07-30 19:55:03,090] Trial 0 finished with value: 0.6398841686466716 and parameters: {'lambda_l1': 2.348881295853308e-05, 'lambda_l2': 3.6010467344475403, 'num_leaves': 188, 'feature_fraction': 0.759195090518222, 'bagging_fraction': 0.4936111842654619, 'bagging_freq': 2, 'pos_bagging_fraction': 0.4348501673009197, 'neg_bagging_fraction': 0.9197056874649611, 'min_child_samples': 62, 'learning_rate': 0.006796578090758156}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:03,410] Trial 1 finished with value: 0.9544326794478387 and parameters: {'lambda_l1': 1.5320059381854043e-08, 'lambda_l2': 5.360294728728285, 'num_leaves': 214, 'feature_fraction': 0.5274034664069657, 'bagging_fraction': 0.5090949803242604, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5825453457757226, 'neg_bagging_fraction': 0.7148538589793427, 'min_child_samples': 46, 'learning_rate': 0.0001461896279370495}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:03,711] Trial 2 finished with value: 0.9670592585663722 and parameters: {'lambda_l1': 0.0032112643094417484, 'lambda_l2': 1.8007140198129195e-07, 'num_leaves': 76, 'feature_fraction': 0.619817105976215, 'bagging_fraction': 0.6736419905302216, 'bagging_freq': 6, 'pos_bagging_fraction': 0.5198042692950159, 'neg_bagging_fraction': 0.708540663048167, 'min_child_samples': 61, 'learning_rate': 1.5339162591163613e-05}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:03,953] Trial 3 finished with value: 0.8916213580154678 and parameters: {'lambda_l1': 0.0029369981104377003, 'lambda_l2': 3.425445902633376e-07, 'num_leaves': 18, 'feature_fraction': 0.9693313223519999, 'bagging_fraction': 0.9793792198447356, 'bagging_freq': 6, 'pos_bagging_fraction': 0.5827682615040224, 'neg_bagging_fraction': 0.45860326840383037, 'min_child_samples': 70, 'learning_rate': 0.00057624872164786}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:04,259] Trial 4 finished with value: 0.9613049016511503 and parameters: {'lambda_l1': 1.254134495897175e-07, 'lambda_l2': 0.00028614897264046574, 'num_leaves': 10, 'feature_fraction': 0.9455922412472693, 'bagging_fraction': 0.5552679889600102, 'bagging_freq': 5, 'pos_bagging_fraction': 0.5870266456536466, 'neg_bagging_fraction': 0.7120408127066865, 'min_child_samples': 57, 'learning_rate': 5.4880470007660426e-05}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:04,689] Trial 5 finished with value: 0.9465216471047849 and parameters: {'lambda_l1': 5.324289357128436, 'lambda_l2': 0.09466630153726856, 'num_leaves': 241, 'feature_fraction': 0.9368964102565893, 'bagging_fraction': 0.7587399872866512, 'bagging_freq': 7, 'pos_bagging_fraction': 0.4530955012311517, 'neg_bagging_fraction': 0.5175897174514872, 'min_child_samples': 9, 'learning_rate': 0.0002001342062287998}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:05,611] Trial 6 finished with value: 0.6857185985511708 and parameters: {'lambda_l1': 3.148441347423712e-05, 'lambda_l2': 2.7678419414850017e-06, 'num_leaves': 213, 'feature_fraction': 0.6140519960161536, 'bagging_fraction': 0.5685607058124285, 'bagging_freq': 4, 'pos_bagging_fraction': 0.4845545349848576, 'neg_bagging_fraction': 0.8813181884524238, 'min_child_samples': 12, 'learning_rate': 0.08862326508576249}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:05,672] Trial 7 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:05,983] Trial 8 finished with value: 0.88243956942454 and parameters: {'lambda_l1': 0.5860448217200517, 'lambda_l2': 0.004070831640873338, 'num_leaves': 86, 'feature_fraction': 0.4381350101716142, 'bagging_fraction': 0.5865893930293973, 'bagging_freq': 3, 'pos_bagging_fraction': 0.8377637070028385, 'neg_bagging_fraction': 0.7825344828131279, 'min_child_samples': 90, 'learning_rate': 0.0007742116473996246}. Best is trial 0 with value: 0.6398841686466716.\n","[I 2023-07-30 19:55:06,103] Trial 9 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:06,520] Trial 10 finished with value: 0.60830737803335 and parameters: {'lambda_l1': 2.3457929170351198e-05, 'lambda_l2': 2.487470846788633, 'num_leaves': 152, 'feature_fraction': 0.7925015835643137, 'bagging_fraction': 0.4092206423968626, 'bagging_freq': 1, 'pos_bagging_fraction': 0.40908654226165414, 'neg_bagging_fraction': 0.9856839399147971, 'min_child_samples': 95, 'learning_rate': 0.008987153901963656}. Best is trial 10 with value: 0.60830737803335.\n","[I 2023-07-30 19:55:07,018] Trial 11 finished with value: 0.6343058934031836 and parameters: {'lambda_l1': 1.302013103054208e-05, 'lambda_l2': 3.253025590604337, 'num_leaves': 157, 'feature_fraction': 0.788028895181074, 'bagging_fraction': 0.41022523369707764, 'bagging_freq': 1, 'pos_bagging_fraction': 0.4064948381096366, 'neg_bagging_fraction': 0.9993649835283197, 'min_child_samples': 96, 'learning_rate': 0.007887826251941597}. Best is trial 10 with value: 0.60830737803335.\n","[I 2023-07-30 19:55:07,419] Trial 12 finished with value: 0.7234538311379072 and parameters: {'lambda_l1': 1.0024983618567058e-05, 'lambda_l2': 9.746600385105031, 'num_leaves': 140, 'feature_fraction': 0.8060908348573689, 'bagging_fraction': 0.4163879796747685, 'bagging_freq': 1, 'pos_bagging_fraction': 0.40190150290937926, 'neg_bagging_fraction': 0.9976099190484612, 'min_child_samples': 99, 'learning_rate': 0.006097028910019557}. Best is trial 10 with value: 0.60830737803335.\n","[I 2023-07-30 19:55:07,849] Trial 13 finished with value: 0.6218699795835263 and parameters: {'lambda_l1': 2.6491362420564193e-06, 'lambda_l2': 0.27161810973596784, 'num_leaves': 146, 'feature_fraction': 0.8337042013583905, 'bagging_fraction': 0.4159650786776957, 'bagging_freq': 1, 'pos_bagging_fraction': 0.40788418943068494, 'neg_bagging_fraction': 0.9792027676392733, 'min_child_samples': 82, 'learning_rate': 0.007037437893019667}. Best is trial 10 with value: 0.60830737803335.\n","[I 2023-07-30 19:55:08,286] Trial 14 finished with value: 0.6827511994724734 and parameters: {'lambda_l1': 5.385659685389972e-07, 'lambda_l2': 0.1535714491181795, 'num_leaves': 107, 'feature_fraction': 0.8739794131187998, 'bagging_fraction': 0.41566649125817917, 'bagging_freq': 2, 'pos_bagging_fraction': 0.987677839776488, 'neg_bagging_fraction': 0.8865004562355121, 'min_child_samples': 79, 'learning_rate': 0.0030093498978634044}. Best is trial 10 with value: 0.60830737803335.\n","[I 2023-07-30 19:55:08,686] Trial 15 finished with value: 0.3507717278231102 and parameters: {'lambda_l1': 1.8251623370246791e-06, 'lambda_l2': 0.31856132881420873, 'num_leaves': 157, 'feature_fraction': 0.8411589973565382, 'bagging_fraction': 0.6600044055220933, 'bagging_freq': 1, 'pos_bagging_fraction': 0.4825500516531853, 'neg_bagging_fraction': 0.8288158877790732, 'min_child_samples': 85, 'learning_rate': 0.027453612584523012}. Best is trial 15 with value: 0.3507717278231102.\n","[I 2023-07-30 19:55:09,136] Trial 16 finished with value: 0.2991685370434252 and parameters: {'lambda_l1': 0.0003474444210156447, 'lambda_l2': 0.002557687335165542, 'num_leaves': 171, 'feature_fraction': 0.7289483756189898, 'bagging_fraction': 0.661723702622221, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5159145811621062, 'neg_bagging_fraction': 0.8138046551270604, 'min_child_samples': 81, 'learning_rate': 0.04071652118027245}. Best is trial 16 with value: 0.2991685370434252.\n","[I 2023-07-30 19:55:09,565] Trial 17 finished with value: 0.2615863051058111 and parameters: {'lambda_l1': 0.00040777902462325383, 'lambda_l2': 0.0010825255176985578, 'num_leaves': 256, 'feature_fraction': 0.7032985332677887, 'bagging_fraction': 0.6632929152403992, 'bagging_freq': 3, 'pos_bagging_fraction': 0.508774450835003, 'neg_bagging_fraction': 0.793626300652922, 'min_child_samples': 76, 'learning_rate': 0.06877181657541481}. Best is trial 17 with value: 0.2615863051058111.\n","[I 2023-07-30 19:55:10,015] Trial 18 finished with value: 0.2754104911729129 and parameters: {'lambda_l1': 0.00040599973475969724, 'lambda_l2': 0.0002458152801571884, 'num_leaves': 254, 'feature_fraction': 0.6738835734350274, 'bagging_fraction': 0.732779622323091, 'bagging_freq': 3, 'pos_bagging_fraction': 0.538450919419236, 'neg_bagging_fraction': 0.8079137079365308, 'min_child_samples': 70, 'learning_rate': 0.09087845133833547}. Best is trial 17 with value: 0.2615863051058111.\n","[I 2023-07-30 19:55:10,547] Trial 19 finished with value: 0.2347652830312867 and parameters: {'lambda_l1': 0.0005265622475910979, 'lambda_l2': 4.242119292870835e-05, 'num_leaves': 256, 'feature_fraction': 0.6673297675302176, 'bagging_fraction': 0.7348607997534249, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6584651161873948, 'neg_bagging_fraction': 0.6370467822084508, 'min_child_samples': 36, 'learning_rate': 0.07742230169721102}. Best is trial 19 with value: 0.2347652830312867.\n","[I 2023-07-30 19:55:11,064] Trial 20 finished with value: 0.31481725197962745 and parameters: {'lambda_l1': 0.014504522003258998, 'lambda_l2': 2.6894244332221912e-05, 'num_leaves': 224, 'feature_fraction': 0.6836781117376376, 'bagging_fraction': 0.630584999373574, 'bagging_freq': 5, 'pos_bagging_fraction': 0.642739854468289, 'neg_bagging_fraction': 0.6200747892749875, 'min_child_samples': 34, 'learning_rate': 0.02524373582670851}. Best is trial 19 with value: 0.2347652830312867.\n","[I 2023-07-30 19:55:11,771] Trial 21 finished with value: 0.34663504880255375 and parameters: {'lambda_l1': 0.0002482392614057073, 'lambda_l2': 9.360590232849835e-05, 'num_leaves': 253, 'feature_fraction': 0.6703408659384753, 'bagging_fraction': 0.7288764283068369, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5437203668345908, 'neg_bagging_fraction': 0.7465548799232171, 'min_child_samples': 24, 'learning_rate': 0.0954975022061644}. Best is trial 19 with value: 0.2347652830312867.\n","[I 2023-07-30 19:55:12,179] Trial 22 finished with value: 0.22205877825882078 and parameters: {'lambda_l1': 0.0005301458075025844, 'lambda_l2': 1.3311706099419597e-05, 'num_leaves': 256, 'feature_fraction': 0.6487550539569624, 'bagging_fraction': 0.7268878873533379, 'bagging_freq': 3, 'pos_bagging_fraction': 0.641045809490872, 'neg_bagging_fraction': 0.6306249916963769, 'min_child_samples': 74, 'learning_rate': 0.09642896668687348}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:12,620] Trial 23 finished with value: 0.2713429170662598 and parameters: {'lambda_l1': 0.002007597174191225, 'lambda_l2': 1.925727791846737e-08, 'num_leaves': 230, 'feature_fraction': 0.607018337979075, 'bagging_fraction': 0.7666132891296144, 'bagging_freq': 4, 'pos_bagging_fraction': 0.6709686614283311, 'neg_bagging_fraction': 0.6128730530891233, 'min_child_samples': 49, 'learning_rate': 0.03796205584174268}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:13,043] Trial 24 finished with value: 0.356990305339157 and parameters: {'lambda_l1': 0.0001554030842728698, 'lambda_l2': 2.228765095355298e-05, 'num_leaves': 199, 'feature_fraction': 0.7123384888329835, 'bagging_fraction': 0.7098209982329854, 'bagging_freq': 2, 'pos_bagging_fraction': 0.715698311424656, 'neg_bagging_fraction': 0.5523977161079254, 'min_child_samples': 70, 'learning_rate': 0.01952353293231525}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:13,610] Trial 25 finished with value: 0.25522879103339274 and parameters: {'lambda_l1': 0.0211246461664238, 'lambda_l2': 0.0010646376064612777, 'num_leaves': 237, 'feature_fraction': 0.5495635460369939, 'bagging_fraction': 0.6181231633641157, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5991534922487002, 'neg_bagging_fraction': 0.6584370796795951, 'min_child_samples': 28, 'learning_rate': 0.04925660010679635}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:14,203] Trial 26 finished with value: 0.3791360983402691 and parameters: {'lambda_l1': 0.025012859209327453, 'lambda_l2': 8.432518390829549e-06, 'num_leaves': 239, 'feature_fraction': 0.5526847326067964, 'bagging_fraction': 0.8045259699072969, 'bagging_freq': 5, 'pos_bagging_fraction': 0.6289469356772752, 'neg_bagging_fraction': 0.6557560139051981, 'min_child_samples': 22, 'learning_rate': 0.01579173833545089}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:14,772] Trial 27 finished with value: 0.276437024821326 and parameters: {'lambda_l1': 0.05223318646515932, 'lambda_l2': 6.15451267933524e-05, 'num_leaves': 223, 'feature_fraction': 0.5472098076451519, 'bagging_fraction': 0.6086662004806684, 'bagging_freq': 4, 'pos_bagging_fraction': 0.6895561766776683, 'neg_bagging_fraction': 0.6068871763189548, 'min_child_samples': 27, 'learning_rate': 0.047133269756878364}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:15,275] Trial 28 finished with value: 0.25402642882861204 and parameters: {'lambda_l1': 0.0047777506453616815, 'lambda_l2': 0.0006284166028161541, 'num_leaves': 178, 'feature_fraction': 0.4878139367923305, 'bagging_fraction': 0.708745076188375, 'bagging_freq': 3, 'pos_bagging_fraction': 0.7530033056133155, 'neg_bagging_fraction': 0.6679580333106633, 'min_child_samples': 39, 'learning_rate': 0.04816533121247186}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:15,441] Trial 29 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:15,598] Trial 30 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:16,164] Trial 31 finished with value: 0.25958567336976685 and parameters: {'lambda_l1': 0.0056177127840860005, 'lambda_l2': 0.0007337951070722277, 'num_leaves': 202, 'feature_fraction': 0.4978958431679142, 'bagging_fraction': 0.6328287732971127, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6392742439377342, 'neg_bagging_fraction': 0.665310422942979, 'min_child_samples': 31, 'learning_rate': 0.039460659314846325}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:16,951] Trial 32 finished with value: 0.28330552402820147 and parameters: {'lambda_l1': 0.009767125065658707, 'lambda_l2': 0.00045870843137874826, 'num_leaves': 237, 'feature_fraction': 0.575813932089164, 'bagging_fraction': 0.698665065441649, 'bagging_freq': 4, 'pos_bagging_fraction': 0.6067515341405463, 'neg_bagging_fraction': 0.669064213582626, 'min_child_samples': 18, 'learning_rate': 0.05776479781957963}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:17,519] Trial 33 finished with value: 0.25461081191613416 and parameters: {'lambda_l1': 0.0010485900395509468, 'lambda_l2': 0.006074446130534024, 'num_leaves': 213, 'feature_fraction': 0.40718264965673806, 'bagging_fraction': 0.5391581383931565, 'bagging_freq': 3, 'pos_bagging_fraction': 0.661430373798645, 'neg_bagging_fraction': 0.7380777466577695, 'min_child_samples': 37, 'learning_rate': 0.09985324109221928}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:18,087] Trial 34 finished with value: 0.26629397141212735 and parameters: {'lambda_l1': 0.0009181629375576414, 'lambda_l2': 0.010829516823005729, 'num_leaves': 212, 'feature_fraction': 0.41558068382965346, 'bagging_fraction': 0.5377881765089441, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6655508551564121, 'neg_bagging_fraction': 0.7373740562946868, 'min_child_samples': 36, 'learning_rate': 0.09519060956892188}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:18,381] Trial 35 pruned. Trial was pruned at iteration 40.\n","[I 2023-07-30 19:55:18,814] Trial 36 finished with value: 0.2617412286575437 and parameters: {'lambda_l1': 0.0011629208995974495, 'lambda_l2': 0.00022465726528360903, 'num_leaves': 122, 'feature_fraction': 0.40258396423077963, 'bagging_fraction': 0.499129488295474, 'bagging_freq': 4, 'pos_bagging_fraction': 0.7516892234950129, 'neg_bagging_fraction': 0.7412906199208873, 'min_child_samples': 61, 'learning_rate': 0.053091352724651604}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:19,291] Trial 37 finished with value: 0.254364508009915 and parameters: {'lambda_l1': 0.00013124773662998382, 'lambda_l2': 1.6654001830060778e-06, 'num_leaves': 171, 'feature_fraction': 0.6455997055732429, 'bagging_fraction': 0.4708687602409539, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5658745924762625, 'neg_bagging_fraction': 0.692699093712077, 'min_child_samples': 53, 'learning_rate': 0.061601278484675046}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:19,466] Trial 38 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:19,924] Trial 39 finished with value: 0.23268254825284887 and parameters: {'lambda_l1': 4.532924768415683e-05, 'lambda_l2': 9.930123279161595e-07, 'num_leaves': 166, 'feature_fraction': 0.5948453757460168, 'bagging_fraction': 0.5851087380325477, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5667065140801251, 'neg_bagging_fraction': 0.48666569013201877, 'min_child_samples': 47, 'learning_rate': 0.06355968109141423}. Best is trial 22 with value: 0.22205877825882078.\n","[I 2023-07-30 19:55:20,148] Trial 40 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:20,741] Trial 41 finished with value: 0.22131581194214103 and parameters: {'lambda_l1': 8.252110621112941e-05, 'lambda_l2': 1.2699099626636199e-06, 'num_leaves': 171, 'feature_fraction': 0.6397638535736762, 'bagging_fraction': 0.5822915219597439, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5639584606334906, 'neg_bagging_fraction': 0.4980577145246906, 'min_child_samples': 43, 'learning_rate': 0.06380312001249551}. Best is trial 41 with value: 0.22131581194214103.\n","[I 2023-07-30 19:55:20,979] Trial 42 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:21,467] Trial 43 pruned. Trial was pruned at iteration 73.\n","[I 2023-07-30 19:55:21,678] Trial 44 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:21,920] Trial 45 pruned. Trial was pruned at iteration 33.\n","[I 2023-07-30 19:55:22,103] Trial 46 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:22,271] Trial 47 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:23,064] Trial 48 finished with value: 0.32124649557303536 and parameters: {'lambda_l1': 9.96697372287936e-06, 'lambda_l2': 1.224628617364732e-06, 'num_leaves': 89, 'feature_fraction': 0.762482369013427, 'bagging_fraction': 0.6885455284410017, 'bagging_freq': 3, 'pos_bagging_fraction': 0.4797187976765034, 'neg_bagging_fraction': 0.580230941845125, 'min_child_samples': 17, 'learning_rate': 0.03560048492086198}. Best is trial 41 with value: 0.22131581194214103.\n","[I 2023-07-30 19:55:23,614] Trial 49 finished with value: 0.2528504361997628 and parameters: {'lambda_l1': 6.667154869318347e-05, 'lambda_l2': 4.177035754878363e-05, 'num_leaves': 148, 'feature_fraction': 0.6867344914567003, 'bagging_fraction': 0.7385030476308025, 'bagging_freq': 1, 'pos_bagging_fraction': 0.6470424090922492, 'neg_bagging_fraction': 0.5340162855686099, 'min_child_samples': 30, 'learning_rate': 0.06692570917398116}. Best is trial 41 with value: 0.22131581194214103.\n","[I 2023-07-30 19:55:24,170] Trial 50 finished with value: 0.28488937617871485 and parameters: {'lambda_l1': 5.860967036317944e-05, 'lambda_l2': 5.192757407265225e-06, 'num_leaves': 116, 'feature_fraction': 0.6884098219539397, 'bagging_fraction': 0.799340440950709, 'bagging_freq': 1, 'pos_bagging_fraction': 0.5896959276709165, 'neg_bagging_fraction': 0.5321757838014936, 'min_child_samples': 31, 'learning_rate': 0.07449167017240656}. Best is trial 41 with value: 0.22131581194214103.\n","[I 2023-07-30 19:55:24,421] Trial 51 pruned. Trial was pruned at iteration 30.\n","[I 2023-07-30 19:55:24,592] Trial 52 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:24,789] Trial 53 pruned. Trial was pruned at iteration 17.\n","[I 2023-07-30 19:55:25,340] Trial 54 finished with value: 0.19853937238340558 and parameters: {'lambda_l1': 0.0006615357839140508, 'lambda_l2': 5.444760538433432e-05, 'num_leaves': 164, 'feature_fraction': 0.6734791494978176, 'bagging_fraction': 0.6488310314537731, 'bagging_freq': 1, 'pos_bagging_fraction': 0.653881084845293, 'neg_bagging_fraction': 0.453129351074091, 'min_child_samples': 31, 'learning_rate': 0.09670147199850047}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:26,200] Trial 55 finished with value: 0.2738542328594213 and parameters: {'lambda_l1': 8.258153638873723e-05, 'lambda_l2': 1.079208042356885e-05, 'num_leaves': 163, 'feature_fraction': 0.6570169253885575, 'bagging_fraction': 0.5873407935808495, 'bagging_freq': 1, 'pos_bagging_fraction': 0.6510946140162501, 'neg_bagging_fraction': 0.43822111018390886, 'min_child_samples': 12, 'learning_rate': 0.08894081917622748}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:26,384] Trial 56 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:26,579] Trial 57 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:26,838] Trial 58 pruned. Trial was pruned at iteration 17.\n","[I 2023-07-30 19:55:27,024] Trial 59 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:27,286] Trial 60 pruned. Trial was pruned at iteration 29.\n","[I 2023-07-30 19:55:27,556] Trial 61 pruned. Trial was pruned at iteration 36.\n","[I 2023-07-30 19:55:28,102] Trial 62 finished with value: 0.24327371919096014 and parameters: {'lambda_l1': 0.0017013197686778, 'lambda_l2': 0.00013588393536855537, 'num_leaves': 161, 'feature_fraction': 0.6059815018733001, 'bagging_fraction': 0.7140205159638118, 'bagging_freq': 3, 'pos_bagging_fraction': 0.624398128534629, 'neg_bagging_fraction': 0.5670871925756706, 'min_child_samples': 34, 'learning_rate': 0.04908084420206764}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:28,648] Trial 63 finished with value: 0.2505943630347884 and parameters: {'lambda_l1': 0.00015334022363257697, 'lambda_l2': 1.794022952148146e-05, 'num_leaves': 164, 'feature_fraction': 0.601702239460995, 'bagging_fraction': 0.7738709987191644, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6279703889751528, 'neg_bagging_fraction': 0.5795919479166594, 'min_child_samples': 34, 'learning_rate': 0.07676092039892814}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:29,207] Trial 64 finished with value: 0.23983178428468577 and parameters: {'lambda_l1': 0.000368319893459551, 'lambda_l2': 0.000139239454452448, 'num_leaves': 245, 'feature_fraction': 0.5932543689616924, 'bagging_fraction': 0.7737830865353086, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5857600659609821, 'neg_bagging_fraction': 0.581352771251131, 'min_child_samples': 33, 'learning_rate': 0.09772992979641504}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:29,386] Trial 65 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:29,562] Trial 66 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:30,087] Trial 67 finished with value: 0.24655467450206134 and parameters: {'lambda_l1': 0.0005405853896236566, 'lambda_l2': 5.9521763623785636e-06, 'num_leaves': 248, 'feature_fraction': 0.569533445263792, 'bagging_fraction': 0.7194535448015165, 'bagging_freq': 4, 'pos_bagging_fraction': 0.5490803505164591, 'neg_bagging_fraction': 0.5623416652005762, 'min_child_samples': 36, 'learning_rate': 0.07927245155496762}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:30,754] Trial 68 finished with value: 0.26971968361224463 and parameters: {'lambda_l1': 0.0010726070264481607, 'lambda_l2': 1.0391970686852574e-05, 'num_leaves': 254, 'feature_fraction': 0.6132984203721976, 'bagging_fraction': 0.5999177124810355, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5825847139714048, 'neg_bagging_fraction': 0.6333805748584436, 'min_child_samples': 25, 'learning_rate': 0.05310074416243201}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:31,037] Trial 69 pruned. Trial was pruned at iteration 40.\n","[I 2023-07-30 19:55:31,760] Trial 70 finished with value: 0.255216216804004 and parameters: {'lambda_l1': 0.0003514883290335939, 'lambda_l2': 0.00015596665698567312, 'num_leaves': 206, 'feature_fraction': 0.6040256647832593, 'bagging_fraction': 0.6598566181489357, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6758476515432218, 'neg_bagging_fraction': 0.6428028244583713, 'min_child_samples': 20, 'learning_rate': 0.044644497142517524}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:32,310] Trial 71 finished with value: 0.2520525426807101 and parameters: {'lambda_l1': 0.0006050226888127935, 'lambda_l2': 4.900955991764774e-06, 'num_leaves': 249, 'feature_fraction': 0.568917079116359, 'bagging_fraction': 0.7159375558118011, 'bagging_freq': 4, 'pos_bagging_fraction': 0.5566545917785133, 'neg_bagging_fraction': 0.5658356176600945, 'min_child_samples': 34, 'learning_rate': 0.07752605623848609}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:32,817] Trial 72 finished with value: 0.2568455420815128 and parameters: {'lambda_l1': 0.00014104191771372606, 'lambda_l2': 7.807704689654494e-06, 'num_leaves': 239, 'feature_fraction': 0.632380574104296, 'bagging_fraction': 0.6963833941210701, 'bagging_freq': 4, 'pos_bagging_fraction': 0.5404358008792612, 'neg_bagging_fraction': 0.6093049734226743, 'min_child_samples': 38, 'learning_rate': 0.08110754523173203}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:33,461] Trial 73 finished with value: 0.24672753188464233 and parameters: {'lambda_l1': 0.0006784837636669405, 'lambda_l2': 7.620204725948398e-05, 'num_leaves': 256, 'feature_fraction': 0.5741747011798309, 'bagging_fraction': 0.7099903388909224, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5782200174663454, 'neg_bagging_fraction': 0.5610512816313138, 'min_child_samples': 28, 'learning_rate': 0.058752327243151894}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:33,950] Trial 74 finished with value: 0.27289705092912486 and parameters: {'lambda_l1': 0.0016875055108430844, 'lambda_l2': 8.89909597304805e-07, 'num_leaves': 216, 'feature_fraction': 0.5947972269295232, 'bagging_fraction': 0.6216367374118208, 'bagging_freq': 5, 'pos_bagging_fraction': 0.5263823308606647, 'neg_bagging_fraction': 0.6182717033510999, 'min_child_samples': 42, 'learning_rate': 0.09585608711413035}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:34,140] Trial 75 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:34,329] Trial 76 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:34,554] Trial 77 pruned. Trial was pruned at iteration 24.\n","[I 2023-07-30 19:55:34,754] Trial 78 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:34,944] Trial 79 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:35,136] Trial 80 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:35,721] Trial 81 finished with value: 0.25115865611504357 and parameters: {'lambda_l1': 0.0006803918305476338, 'lambda_l2': 6.657490192942291e-05, 'num_leaves': 255, 'feature_fraction': 0.5792959747205776, 'bagging_fraction': 0.7053151833631989, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5843758509797428, 'neg_bagging_fraction': 0.5687202519022562, 'min_child_samples': 28, 'learning_rate': 0.055539829214677976}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:35,907] Trial 82 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:36,464] Trial 83 finished with value: 0.23851125511013804 and parameters: {'lambda_l1': 0.00020280750588080523, 'lambda_l2': 1.3561735461834587e-05, 'num_leaves': 227, 'feature_fraction': 0.5641710279261903, 'bagging_fraction': 0.7208103387126901, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5431078137717612, 'neg_bagging_fraction': 0.5640850689923123, 'min_child_samples': 33, 'learning_rate': 0.09967004298908112}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:37,094] Trial 84 finished with value: 0.23629793880816094 and parameters: {'lambda_l1': 0.0002002640634377636, 'lambda_l2': 1.4099903003844866e-05, 'num_leaves': 227, 'feature_fraction': 0.6335394119587348, 'bagging_fraction': 0.7824088717415836, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5444886282786374, 'neg_bagging_fraction': 0.5202832114342376, 'min_child_samples': 34, 'learning_rate': 0.09920508253565612}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:37,708] Trial 85 finished with value: 0.2590139286143463 and parameters: {'lambda_l1': 4.860486971875071e-05, 'lambda_l2': 1.892735536501833e-05, 'num_leaves': 230, 'feature_fraction': 0.6361128301217758, 'bagging_fraction': 0.7862292445297685, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5295771346865401, 'neg_bagging_fraction': 0.5194756057287281, 'min_child_samples': 24, 'learning_rate': 0.09922757302340425}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:37,894] Trial 86 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:38,075] Trial 87 pruned. Trial was pruned at iteration 11.\n","[I 2023-07-30 19:55:38,252] Trial 88 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:38,436] Trial 89 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:38,671] Trial 90 pruned. Trial was pruned at iteration 26.\n","[I 2023-07-30 19:55:38,877] Trial 91 pruned. Trial was pruned at iteration 19.\n","[I 2023-07-30 19:55:39,445] Trial 92 finished with value: 0.26873650374452995 and parameters: {'lambda_l1': 0.0008266328355106405, 'lambda_l2': 7.5490897953984195e-06, 'num_leaves': 242, 'feature_fraction': 0.5850404680768105, 'bagging_fraction': 0.7432151704424684, 'bagging_freq': 3, 'pos_bagging_fraction': 0.49847002223471365, 'neg_bagging_fraction': 0.5862649015654081, 'min_child_samples': 31, 'learning_rate': 0.09894906497055041}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:39,625] Trial 93 pruned. Trial was pruned at iteration 11.\n","[I 2023-07-30 19:55:39,803] Trial 94 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:39,983] Trial 95 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:40,162] Trial 96 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:40,848] Trial 97 finished with value: 0.2663533117966728 and parameters: {'lambda_l1': 4.4090875393411066e-05, 'lambda_l2': 0.00011985184805774671, 'num_leaves': 244, 'feature_fraction': 0.5809597085669821, 'bagging_fraction': 0.7713058793170277, 'bagging_freq': 5, 'pos_bagging_fraction': 0.5939717272253874, 'neg_bagging_fraction': 0.6160946607956878, 'min_child_samples': 23, 'learning_rate': 0.07980453403169681}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:41,035] Trial 98 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:41,298] Trial 99 pruned. Trial was pruned at iteration 28.\n","[I 2023-07-30 19:55:41,535] Trial 100 pruned. Trial was pruned at iteration 28.\n","[I 2023-07-30 19:55:42,140] Trial 101 finished with value: 0.2576189780869065 and parameters: {'lambda_l1': 0.0010792835390885183, 'lambda_l2': 8.669005321860022e-05, 'num_leaves': 255, 'feature_fraction': 0.5712546799151157, 'bagging_fraction': 0.7157494302699136, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5722623567592485, 'neg_bagging_fraction': 0.5681485491198598, 'min_child_samples': 28, 'learning_rate': 0.060670542387682255}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:42,339] Trial 102 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:42,882] Trial 103 finished with value: 0.2593750576467469 and parameters: {'lambda_l1': 0.00012653035191247144, 'lambda_l2': 0.00018937901518779635, 'num_leaves': 256, 'feature_fraction': 0.613403628047645, 'bagging_fraction': 0.7557738685967376, 'bagging_freq': 3, 'pos_bagging_fraction': 0.583428312671302, 'neg_bagging_fraction': 0.5458349076395249, 'min_child_samples': 33, 'learning_rate': 0.07854917400533465}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:43,080] Trial 104 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:43,790] Trial 105 finished with value: 0.2445863060478196 and parameters: {'lambda_l1': 0.0003161983378226565, 'lambda_l2': 2.920755780971775e-05, 'num_leaves': 237, 'feature_fraction': 0.5774687297420976, 'bagging_fraction': 0.7361825672473058, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6397800026300243, 'neg_bagging_fraction': 0.5349486213304822, 'min_child_samples': 20, 'learning_rate': 0.07235056305630658}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:44,573] Trial 106 finished with value: 0.24255802084597103 and parameters: {'lambda_l1': 0.0002903795882660135, 'lambda_l2': 5.561488155170853e-06, 'num_leaves': 235, 'feature_fraction': 0.6584557773115006, 'bagging_fraction': 0.7405785447441784, 'bagging_freq': 3, 'pos_bagging_fraction': 0.640366705652065, 'neg_bagging_fraction': 0.5321608974363357, 'min_child_samples': 17, 'learning_rate': 0.06938977027772221}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:44,788] Trial 107 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:45,840] Trial 108 finished with value: 0.306642082201041 and parameters: {'lambda_l1': 8.333851654227755e-05, 'lambda_l2': 3.146894511615901e-05, 'num_leaves': 159, 'feature_fraction': 0.6276936888315633, 'bagging_fraction': 0.8006061995957929, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6517998290176031, 'neg_bagging_fraction': 0.5075890059977467, 'min_child_samples': 9, 'learning_rate': 0.0674371141716615}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:46,064] Trial 109 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:46,288] Trial 110 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:47,220] Trial 111 pruned. Trial was pruned at iteration 61.\n","[I 2023-07-30 19:55:48,075] Trial 112 finished with value: 0.26254297126581627 and parameters: {'lambda_l1': 0.0014591922490576588, 'lambda_l2': 8.821344111802545e-06, 'num_leaves': 241, 'feature_fraction': 0.6762627656915137, 'bagging_fraction': 0.738191945397272, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6783850312017234, 'neg_bagging_fraction': 0.49456813064022304, 'min_child_samples': 13, 'learning_rate': 0.06990929741408225}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:48,805] Trial 113 finished with value: 0.25947328350924737 and parameters: {'lambda_l1': 0.0005188254277172783, 'lambda_l2': 4.496330143104029e-05, 'num_leaves': 237, 'feature_fraction': 0.6345202222514233, 'bagging_fraction': 0.678110494434006, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6681000745942165, 'neg_bagging_fraction': 0.5810697859949092, 'min_child_samples': 20, 'learning_rate': 0.08132351053196409}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:49,000] Trial 114 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:49,213] Trial 115 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:49,601] Trial 116 pruned. Trial was pruned at iteration 59.\n","[I 2023-07-30 19:55:49,806] Trial 117 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:50,036] Trial 118 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:50,242] Trial 119 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:51,230] Trial 120 finished with value: 0.3017456807758508 and parameters: {'lambda_l1': 6.029765678531765e-05, 'lambda_l2': 8.424197597421742e-07, 'num_leaves': 127, 'feature_fraction': 0.6934564000299028, 'bagging_fraction': 0.6677380879341981, 'bagging_freq': 3, 'pos_bagging_fraction': 0.6284454718063592, 'neg_bagging_fraction': 0.5004309073250368, 'min_child_samples': 10, 'learning_rate': 0.07112895971389059}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:51,439] Trial 121 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:52,271] Trial 122 finished with value: 0.26454251063350426 and parameters: {'lambda_l1': 0.0007757442846877181, 'lambda_l2': 7.489579813849046e-05, 'num_leaves': 237, 'feature_fraction': 0.5500034036984237, 'bagging_fraction': 0.6863378654742538, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5675317351634265, 'neg_bagging_fraction': 0.5706333499391748, 'min_child_samples': 28, 'learning_rate': 0.0806702674548531}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:53,278] Trial 123 finished with value: 0.3397708415760523 and parameters: {'lambda_l1': 0.0003666460467036, 'lambda_l2': 0.0002903487187587226, 'num_leaves': 250, 'feature_fraction': 0.5247997898772997, 'bagging_fraction': 0.7010465993966534, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5443073442746648, 'neg_bagging_fraction': 0.6468924456610086, 'min_child_samples': 18, 'learning_rate': 0.06161486625715679}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:53,475] Trial 124 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:53,665] Trial 125 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:54,219] Trial 126 pruned. Trial was pruned at iteration 95.\n","[I 2023-07-30 19:55:54,517] Trial 127 pruned. Trial was pruned at iteration 35.\n","[I 2023-07-30 19:55:54,742] Trial 128 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:54,974] Trial 129 pruned. Trial was pruned at iteration 17.\n","[I 2023-07-30 19:55:55,205] Trial 130 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:55,420] Trial 131 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:55,624] Trial 132 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:55,828] Trial 133 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:56,434] Trial 134 finished with value: 0.21108743268003458 and parameters: {'lambda_l1': 0.00025854649008349995, 'lambda_l2': 5.69137205309992e-05, 'num_leaves': 141, 'feature_fraction': 0.558671478453199, 'bagging_fraction': 0.7781007093838066, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6307658586888953, 'neg_bagging_fraction': 0.5691130821070105, 'min_child_samples': 33, 'learning_rate': 0.08721643773535648}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:56,679] Trial 135 pruned. Trial was pruned at iteration 20.\n","[I 2023-07-30 19:55:56,902] Trial 136 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:57,118] Trial 137 pruned. Trial was pruned at iteration 12.\n","[I 2023-07-30 19:55:57,322] Trial 138 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:57,537] Trial 139 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:57,735] Trial 140 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:57,945] Trial 141 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:55:58,626] Trial 142 finished with value: 0.2509071243038042 and parameters: {'lambda_l1': 0.00034242878288439493, 'lambda_l2': 5.7978901332961304e-05, 'num_leaves': 240, 'feature_fraction': 0.6570457396365196, 'bagging_fraction': 0.776752291588321, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6279129053958008, 'neg_bagging_fraction': 0.677101784359299, 'min_child_samples': 34, 'learning_rate': 0.06908035456264414}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:59,317] Trial 143 finished with value: 0.22862106551522243 and parameters: {'lambda_l1': 5.277483016250377e-05, 'lambda_l2': 3.186745054272004e-06, 'num_leaves': 131, 'feature_fraction': 0.6169257094180534, 'bagging_fraction': 0.7464497096138363, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5891662405736832, 'neg_bagging_fraction': 0.568067053246134, 'min_child_samples': 30, 'learning_rate': 0.0830478094679486}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:55:59,975] Trial 144 finished with value: 0.22980863169863674 and parameters: {'lambda_l1': 8.443323784925694e-05, 'lambda_l2': 2.2701811692999455e-06, 'num_leaves': 126, 'feature_fraction': 0.6219809579701685, 'bagging_fraction': 0.745895019564531, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5893784208274571, 'neg_bagging_fraction': 0.5635107284382505, 'min_child_samples': 30, 'learning_rate': 0.08717366244353365}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:00,638] Trial 145 finished with value: 0.24615099613270197 and parameters: {'lambda_l1': 5.7829351972372293e-05, 'lambda_l2': 2.794171819634488e-06, 'num_leaves': 133, 'feature_fraction': 0.6220541401252782, 'bagging_fraction': 0.7477601557182986, 'bagging_freq': 2, 'pos_bagging_fraction': 0.590752172607289, 'neg_bagging_fraction': 0.5450850380648731, 'min_child_samples': 30, 'learning_rate': 0.08533534375772357}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:01,339] Trial 146 finished with value: 0.2616591148489035 and parameters: {'lambda_l1': 5.31569073811911e-05, 'lambda_l2': 2.4335776056747264e-06, 'num_leaves': 130, 'feature_fraction': 0.6270381930758734, 'bagging_fraction': 0.744459526833894, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5912579585027496, 'neg_bagging_fraction': 0.5457633082168063, 'min_child_samples': 26, 'learning_rate': 0.09990690707987383}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:01,645] Trial 147 pruned. Trial was pruned at iteration 32.\n","[I 2023-07-30 19:56:01,865] Trial 148 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:02,542] Trial 149 finished with value: 0.24614186351263387 and parameters: {'lambda_l1': 3.920106355835131e-05, 'lambda_l2': 2.8972870689424117e-06, 'num_leaves': 135, 'feature_fraction': 0.6725124095322291, 'bagging_fraction': 0.7484016809889549, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6324863522698048, 'neg_bagging_fraction': 0.5891182064122137, 'min_child_samples': 33, 'learning_rate': 0.08360562031279341}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:02,761] Trial 150 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:03,095] Trial 151 pruned. Trial was pruned at iteration 29.\n","[I 2023-07-30 19:56:03,328] Trial 152 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:03,531] Trial 153 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:03,801] Trial 154 pruned. Trial was pruned at iteration 23.\n","[I 2023-07-30 19:56:04,045] Trial 155 pruned. Trial was pruned at iteration 11.\n","[I 2023-07-30 19:56:04,274] Trial 156 pruned. Trial was pruned at iteration 15.\n","[I 2023-07-30 19:56:04,503] Trial 157 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:05,383] Trial 158 finished with value: 0.26764243801865334 and parameters: {'lambda_l1': 3.939360753267213e-05, 'lambda_l2': 1.0717786846440383e-06, 'num_leaves': 147, 'feature_fraction': 0.6101631251642371, 'bagging_fraction': 0.743728326792041, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6282452156851376, 'neg_bagging_fraction': 0.6080306364398275, 'min_child_samples': 18, 'learning_rate': 0.05637730931149665}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:05,703] Trial 159 pruned. Trial was pruned at iteration 36.\n","[I 2023-07-30 19:56:06,428] Trial 160 finished with value: 0.2802538521050497 and parameters: {'lambda_l1': 2.017239186512745e-05, 'lambda_l2': 5.297107114257942e-07, 'num_leaves': 152, 'feature_fraction': 0.683684245304214, 'bagging_fraction': 0.5766924955280603, 'bagging_freq': 1, 'pos_bagging_fraction': 0.5565552619785467, 'neg_bagging_fraction': 0.6550012108840704, 'min_child_samples': 27, 'learning_rate': 0.07160843456607852}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:06,641] Trial 161 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:06,880] Trial 162 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:07,194] Trial 163 pruned. Trial was pruned at iteration 29.\n","[I 2023-07-30 19:56:07,407] Trial 164 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:07,647] Trial 165 pruned. Trial was pruned at iteration 16.\n","[I 2023-07-30 19:56:07,874] Trial 166 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:08,077] Trial 167 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:08,284] Trial 168 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:08,560] Trial 169 pruned. Trial was pruned at iteration 23.\n","[I 2023-07-30 19:56:08,762] Trial 170 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:09,395] Trial 171 finished with value: 0.2711044154759917 and parameters: {'lambda_l1': 0.0003864871720916329, 'lambda_l2': 4.4447475868392464e-05, 'num_leaves': 250, 'feature_fraction': 0.5579046043488441, 'bagging_fraction': 0.6824608867869626, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5839402078100016, 'neg_bagging_fraction': 0.5506484373623498, 'min_child_samples': 27, 'learning_rate': 0.08151042287085376}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:09,600] Trial 172 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:10,266] Trial 173 finished with value: 0.24279803144851783 and parameters: {'lambda_l1': 0.0002281398589548095, 'lambda_l2': 2.069195916571324e-06, 'num_leaves': 241, 'feature_fraction': 0.590104266594553, 'bagging_fraction': 0.7302844078157152, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5702406857207034, 'neg_bagging_fraction': 0.5738509692498359, 'min_child_samples': 25, 'learning_rate': 0.06168782269909787}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:10,973] Trial 174 finished with value: 0.267548935537365 and parameters: {'lambda_l1': 9.83688133090759e-05, 'lambda_l2': 3.0195433551727755e-06, 'num_leaves': 242, 'feature_fraction': 0.5891997239512796, 'bagging_fraction': 0.7345412853799324, 'bagging_freq': 3, 'pos_bagging_fraction': 0.5494279334173919, 'neg_bagging_fraction': 0.5773747125741087, 'min_child_samples': 23, 'learning_rate': 0.06981858713603754}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:11,192] Trial 175 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:11,418] Trial 176 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:12,005] Trial 177 finished with value: 0.231648729845511 and parameters: {'lambda_l1': 0.00013934662298194437, 'lambda_l2': 1.1555424688211507e-06, 'num_leaves': 250, 'feature_fraction': 0.6594164807167159, 'bagging_fraction': 0.591294520161428, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5984534996991309, 'neg_bagging_fraction': 0.6077012886495016, 'min_child_samples': 34, 'learning_rate': 0.0836993996424078}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:12,792] Trial 178 finished with value: 0.30472985302640415 and parameters: {'lambda_l1': 0.00011704379707854595, 'lambda_l2': 6.58228705452974e-07, 'num_leaves': 154, 'feature_fraction': 0.6580056211662908, 'bagging_fraction': 0.5962562207228964, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5966856477660737, 'neg_bagging_fraction': 0.6030908654123285, 'min_child_samples': 19, 'learning_rate': 0.08606894730123313}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:13,012] Trial 179 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:13,851] Trial 180 finished with value: 0.29253231587922435 and parameters: {'lambda_l1': 7.32522606135558e-05, 'lambda_l2': 2.1919703550200333e-06, 'num_leaves': 146, 'feature_fraction': 0.6781918555498443, 'bagging_fraction': 0.6260316871697778, 'bagging_freq': 1, 'pos_bagging_fraction': 0.5886293622328226, 'neg_bagging_fraction': 0.5918850158934821, 'min_child_samples': 16, 'learning_rate': 0.07176972542111933}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:14,425] Trial 181 pruned. Trial was pruned at iteration 93.\n","[I 2023-07-30 19:56:14,642] Trial 182 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:15,126] Trial 183 pruned. Trial was pruned at iteration 67.\n","[I 2023-07-30 19:56:15,427] Trial 184 pruned. Trial was pruned at iteration 27.\n","[I 2023-07-30 19:56:15,651] Trial 185 pruned. Trial was pruned at iteration 12.\n","[I 2023-07-30 19:56:15,850] Trial 186 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:16,066] Trial 187 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:16,289] Trial 188 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:16,497] Trial 189 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:17,216] Trial 190 finished with value: 0.2122918505846047 and parameters: {'lambda_l1': 2.500236620065218e-05, 'lambda_l2': 1.9324968514523768e-07, 'num_leaves': 246, 'feature_fraction': 0.5423585133473448, 'bagging_fraction': 0.7398968582556376, 'bagging_freq': 2, 'pos_bagging_fraction': 0.6125537300944606, 'neg_bagging_fraction': 0.5846883492960266, 'min_child_samples': 29, 'learning_rate': 0.09940531876308839}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:17,431] Trial 191 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:17,648] Trial 192 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:17,873] Trial 193 pruned. Trial was pruned at iteration 15.\n","[I 2023-07-30 19:56:18,103] Trial 194 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:18,396] Trial 195 pruned. Trial was pruned at iteration 25.\n","[I 2023-07-30 19:56:18,610] Trial 196 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:18,834] Trial 197 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:19,440] Trial 198 finished with value: 0.21428807993147758 and parameters: {'lambda_l1': 6.422717271025726e-06, 'lambda_l2': 7.444775418827361e-07, 'num_leaves': 132, 'feature_fraction': 0.5417027293409857, 'bagging_fraction': 0.767163867865725, 'bagging_freq': 2, 'pos_bagging_fraction': 0.556757125708897, 'neg_bagging_fraction': 0.5758897973967146, 'min_child_samples': 32, 'learning_rate': 0.09862276304761018}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:20,051] Trial 199 finished with value: 0.23294775225533632 and parameters: {'lambda_l1': 0.00010819775724479117, 'lambda_l2': 6.870566557467933e-07, 'num_leaves': 139, 'feature_fraction': 0.5368784262952656, 'bagging_fraction': 0.7700003047530828, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5570675064461733, 'neg_bagging_fraction': 0.5837470719128348, 'min_child_samples': 32, 'learning_rate': 0.09745485097808919}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:20,662] Trial 200 finished with value: 0.22320472486937126 and parameters: {'lambda_l1': 8.380219214771685e-06, 'lambda_l2': 4.6606953999554515e-07, 'num_leaves': 138, 'feature_fraction': 0.5468853006393367, 'bagging_fraction': 0.768762865759873, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5599960840755872, 'neg_bagging_fraction': 0.6011808476825028, 'min_child_samples': 32, 'learning_rate': 0.09913833601691534}. Best is trial 54 with value: 0.19853937238340558.\n","[I 2023-07-30 19:56:21,288] Trial 201 finished with value: 0.1667569163206571 and parameters: {'lambda_l1': 2.315160150066382e-06, 'lambda_l2': 5.795473037427011e-07, 'num_leaves': 129, 'feature_fraction': 0.5381606680136374, 'bagging_fraction': 0.7706871849373977, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5569219616410732, 'neg_bagging_fraction': 0.5874589935019283, 'min_child_samples': 32, 'learning_rate': 0.099787461889484}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:21,919] Trial 202 finished with value: 0.23120990086694365 and parameters: {'lambda_l1': 1.0695636169299842e-06, 'lambda_l2': 6.319824688068484e-07, 'num_leaves': 129, 'feature_fraction': 0.5400002586979372, 'bagging_fraction': 0.7750090264158102, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5538062900895794, 'neg_bagging_fraction': 0.602908519949946, 'min_child_samples': 32, 'learning_rate': 0.09515555541963581}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:22,551] Trial 203 finished with value: 0.2702512080139029 and parameters: {'lambda_l1': 1.1965177890217035e-06, 'lambda_l2': 5.988032119617647e-07, 'num_leaves': 129, 'feature_fraction': 0.5136440807723986, 'bagging_fraction': 0.7776917348660973, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5565015336304955, 'neg_bagging_fraction': 0.6049468424857425, 'min_child_samples': 31, 'learning_rate': 0.09902132603947553}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:22,773] Trial 204 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:22,995] Trial 205 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:23,224] Trial 206 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:23,484] Trial 207 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:24,491] Trial 208 finished with value: 0.2923888723115423 and parameters: {'lambda_l1': 1.9576690839048032e-06, 'lambda_l2': 8.496395696246426e-07, 'num_leaves': 140, 'feature_fraction': 0.5548778104846733, 'bagging_fraction': 0.803393769607789, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5295581180139425, 'neg_bagging_fraction': 0.5865504551842837, 'min_child_samples': 27, 'learning_rate': 0.09816736406293546}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:24,810] Trial 209 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:25,122] Trial 210 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:25,798] Trial 211 finished with value: 0.23168055647746877 and parameters: {'lambda_l1': 6.1473780490303815e-06, 'lambda_l2': 1.1354212596010753e-07, 'num_leaves': 126, 'feature_fraction': 0.5507272669632431, 'bagging_fraction': 0.5385359357452777, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5453237989427302, 'neg_bagging_fraction': 0.599820697597317, 'min_child_samples': 29, 'learning_rate': 0.07722766794291251}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:26,032] Trial 212 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:26,258] Trial 213 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:26,994] Trial 214 finished with value: 0.2166498404183064 and parameters: {'lambda_l1': 7.885698581769736e-06, 'lambda_l2': 7.496145138038543e-07, 'num_leaves': 136, 'feature_fraction': 0.5324500852881489, 'bagging_fraction': 0.6073092694651795, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5665568578211871, 'neg_bagging_fraction': 0.6172334150786867, 'min_child_samples': 30, 'learning_rate': 0.08303468750146885}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:27,237] Trial 215 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:27,927] Trial 216 finished with value: 0.21934459186407457 and parameters: {'lambda_l1': 1.2949799050637401e-05, 'lambda_l2': 1.2860246239841338e-06, 'num_leaves': 122, 'feature_fraction': 0.5267256143680706, 'bagging_fraction': 0.5695875307686864, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5235681222614376, 'neg_bagging_fraction': 0.6293161368649218, 'min_child_samples': 30, 'learning_rate': 0.0978280787725282}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:28,590] Trial 217 finished with value: 0.23567694071760395 and parameters: {'lambda_l1': 7.181854668196397e-06, 'lambda_l2': 1.2178622795258898e-06, 'num_leaves': 125, 'feature_fraction': 0.5262770802351636, 'bagging_fraction': 0.5448848545938971, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5174853288979138, 'neg_bagging_fraction': 0.6372471622654272, 'min_child_samples': 30, 'learning_rate': 0.08460433365194504}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:29,298] Trial 218 finished with value: 0.2737837153814546 and parameters: {'lambda_l1': 7.750910035471883e-06, 'lambda_l2': 4.6919027949965514e-07, 'num_leaves': 122, 'feature_fraction': 0.525088365641412, 'bagging_fraction': 0.5436370075878455, 'bagging_freq': 2, 'pos_bagging_fraction': 0.513821741248802, 'neg_bagging_fraction': 0.6616521005991748, 'min_child_samples': 30, 'learning_rate': 0.08431920828580736}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:30,004] Trial 219 finished with value: 0.22174496207284056 and parameters: {'lambda_l1': 8.9253186899712e-06, 'lambda_l2': 1.1362388357261772e-06, 'num_leaves': 118, 'feature_fraction': 0.511742905972084, 'bagging_fraction': 0.5607732102710847, 'bagging_freq': 2, 'pos_bagging_fraction': 0.4997743379526724, 'neg_bagging_fraction': 0.6333251950726811, 'min_child_samples': 28, 'learning_rate': 0.09700301165492696}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:30,727] Trial 220 finished with value: 0.2714936728745087 and parameters: {'lambda_l1': 1.148351493783969e-05, 'lambda_l2': 1.3281482377158547e-06, 'num_leaves': 112, 'feature_fraction': 0.5094016115758713, 'bagging_fraction': 0.5722434290229775, 'bagging_freq': 2, 'pos_bagging_fraction': 0.4963761637687831, 'neg_bagging_fraction': 0.642053865067936, 'min_child_samples': 27, 'learning_rate': 0.08773069286080541}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:31,427] Trial 221 finished with value: 0.238789830605688 and parameters: {'lambda_l1': 8.695155856230642e-06, 'lambda_l2': 1.0152185263594546e-06, 'num_leaves': 115, 'feature_fraction': 0.5244824195507837, 'bagging_fraction': 0.5706033294670331, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5154853962355453, 'neg_bagging_fraction': 0.6315971327507607, 'min_child_samples': 29, 'learning_rate': 0.09513271691300844}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:32,108] Trial 222 finished with value: 0.2716375269431496 and parameters: {'lambda_l1': 1.0534227519898342e-05, 'lambda_l2': 9.123132047037901e-07, 'num_leaves': 106, 'feature_fraction': 0.5279294117066499, 'bagging_fraction': 0.5533541880336854, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5061496724448162, 'neg_bagging_fraction': 0.6299719048456538, 'min_child_samples': 29, 'learning_rate': 0.09921869145256489}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:32,788] Trial 223 finished with value: 0.2507768965832558 and parameters: {'lambda_l1': 9.167916004996242e-06, 'lambda_l2': 1.2927532395771666e-06, 'num_leaves': 115, 'feature_fraction': 0.5069721989257003, 'bagging_fraction': 0.564077785896622, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5270720795706448, 'neg_bagging_fraction': 0.6502879589043679, 'min_child_samples': 28, 'learning_rate': 0.07739025628409081}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:33,124] Trial 224 pruned. Trial was pruned at iteration 33.\n","[I 2023-07-30 19:56:33,361] Trial 225 pruned. Trial was pruned at iteration 11.\n","[I 2023-07-30 19:56:33,581] Trial 226 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:33,820] Trial 227 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:34,066] Trial 228 pruned. Trial was pruned at iteration 11.\n","[I 2023-07-30 19:56:34,299] Trial 229 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:35,015] Trial 230 finished with value: 0.22967162242597527 and parameters: {'lambda_l1': 8.560111543306902e-06, 'lambda_l2': 1.6170887438327362e-06, 'num_leaves': 110, 'feature_fraction': 0.5265511037164313, 'bagging_fraction': 0.5837328054493658, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5074419133113094, 'neg_bagging_fraction': 0.6123363063448716, 'min_child_samples': 27, 'learning_rate': 0.08388016668301067}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:35,635] Trial 231 pruned. Trial was pruned at iteration 85.\n","[I 2023-07-30 19:56:36,344] Trial 232 finished with value: 0.2607237554792845 and parameters: {'lambda_l1': 5.843604457483731e-06, 'lambda_l2': 8.702628481290738e-07, 'num_leaves': 113, 'feature_fraction': 0.5281734012969173, 'bagging_fraction': 0.596575745444395, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5381450162894985, 'neg_bagging_fraction': 0.6369368793599769, 'min_child_samples': 28, 'learning_rate': 0.08695851640421583}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:37,112] Trial 233 pruned. Trial was pruned at iteration 98.\n","[I 2023-07-30 19:56:37,435] Trial 234 pruned. Trial was pruned at iteration 28.\n","[I 2023-07-30 19:56:37,696] Trial 235 pruned. Trial was pruned at iteration 17.\n","[I 2023-07-30 19:56:38,342] Trial 236 finished with value: 0.21026414498090037 and parameters: {'lambda_l1': 1.9767579749201268e-05, 'lambda_l2': 6.773766965879858e-07, 'num_leaves': 126, 'feature_fraction': 0.5067676790006646, 'bagging_fraction': 0.5650912627459452, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5542224501081982, 'neg_bagging_fraction': 0.6151040147895652, 'min_child_samples': 31, 'learning_rate': 0.09953691136425791}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:38,577] Trial 237 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:38,907] Trial 238 pruned. Trial was pruned at iteration 38.\n","[I 2023-07-30 19:56:39,144] Trial 239 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:39,377] Trial 240 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:40,074] Trial 241 finished with value: 0.2536206904998858 and parameters: {'lambda_l1': 7.448250592109843e-06, 'lambda_l2': 9.007200777828576e-07, 'num_leaves': 119, 'feature_fraction': 0.5244348459165634, 'bagging_fraction': 0.5702037697937327, 'bagging_freq': 2, 'pos_bagging_fraction': 0.507139171949239, 'neg_bagging_fraction': 0.6405843900426826, 'min_child_samples': 29, 'learning_rate': 0.0852143548214776}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:40,734] Trial 242 finished with value: 0.25873304812716885 and parameters: {'lambda_l1': 3.1055290072761137e-06, 'lambda_l2': 4.4387327114373924e-07, 'num_leaves': 122, 'feature_fraction': 0.5100705970551492, 'bagging_fraction': 0.5544305870735021, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5276037872525939, 'neg_bagging_fraction': 0.6261347373268582, 'min_child_samples': 30, 'learning_rate': 0.09889906997442076}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:41,207] Trial 243 pruned. Trial was pruned at iteration 62.\n","[I 2023-07-30 19:56:41,442] Trial 244 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:41,658] Trial 245 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:41,877] Trial 246 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:42,147] Trial 247 pruned. Trial was pruned at iteration 19.\n","[I 2023-07-30 19:56:42,372] Trial 248 pruned. Trial was pruned at iteration 12.\n","[I 2023-07-30 19:56:42,584] Trial 249 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:42,791] Trial 250 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:43,082] Trial 251 pruned. Trial was pruned at iteration 30.\n","[I 2023-07-30 19:56:43,298] Trial 252 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:43,528] Trial 253 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:43,759] Trial 254 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:44,008] Trial 255 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:44,690] Trial 256 finished with value: 0.27627411438887345 and parameters: {'lambda_l1': 8.06607330814608e-06, 'lambda_l2': 0.06253164800443294, 'num_leaves': 124, 'feature_fraction': 0.5395733861660763, 'bagging_fraction': 0.6054170764798954, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5464744640771335, 'neg_bagging_fraction': 0.6928032281386, 'min_child_samples': 29, 'learning_rate': 0.08580768325541366}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:44,920] Trial 257 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:45,175] Trial 258 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:45,408] Trial 259 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:45,651] Trial 260 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:45,888] Trial 261 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:46,146] Trial 262 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:46,384] Trial 263 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:46,630] Trial 264 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:46,903] Trial 265 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:47,149] Trial 266 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:47,423] Trial 267 pruned. Trial was pruned at iteration 15.\n","[I 2023-07-30 19:56:48,133] Trial 268 finished with value: 0.2343940232243341 and parameters: {'lambda_l1': 2.74517285847698e-05, 'lambda_l2': 1.344434999314423e-05, 'num_leaves': 119, 'feature_fraction': 0.5286609242767264, 'bagging_fraction': 0.5749366607453782, 'bagging_freq': 2, 'pos_bagging_fraction': 0.594505345015742, 'neg_bagging_fraction': 0.5922677606258283, 'min_child_samples': 29, 'learning_rate': 0.09901042818313276}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:48,381] Trial 269 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:48,618] Trial 270 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:48,843] Trial 271 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:49,083] Trial 272 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:49,331] Trial 273 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:49,574] Trial 274 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:49,827] Trial 275 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:50,177] Trial 276 pruned. Trial was pruned at iteration 30.\n","[I 2023-07-30 19:56:50,818] Trial 277 finished with value: 0.243288942893181 and parameters: {'lambda_l1': 2.1776816580582073e-06, 'lambda_l2': 9.035861943485493e-06, 'num_leaves': 199, 'feature_fraction': 0.5138598918935527, 'bagging_fraction': 0.5992309606986891, 'bagging_freq': 2, 'pos_bagging_fraction': 0.5825722799156424, 'neg_bagging_fraction': 0.5772948839277798, 'min_child_samples': 32, 'learning_rate': 0.09995663738341816}. Best is trial 201 with value: 0.1667569163206571.\n","[I 2023-07-30 19:56:51,063] Trial 278 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:51,310] Trial 279 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:51,556] Trial 280 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:51,792] Trial 281 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:52,037] Trial 282 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:52,285] Trial 283 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:52,524] Trial 284 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:52,768] Trial 285 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:53,014] Trial 286 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:53,317] Trial 287 pruned. Trial was pruned at iteration 24.\n","[I 2023-07-30 19:56:53,572] Trial 288 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:53,821] Trial 289 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:54,113] Trial 290 pruned. Trial was pruned at iteration 17.\n","[I 2023-07-30 19:56:54,364] Trial 291 pruned. Trial was pruned at iteration 12.\n","[I 2023-07-30 19:56:54,616] Trial 292 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:54,869] Trial 293 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:55,113] Trial 294 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:55,418] Trial 295 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:55,717] Trial 296 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:56,110] Trial 297 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:56,474] Trial 298 pruned. Trial was pruned at iteration 10.\n","[I 2023-07-30 19:56:56,739] Trial 299 pruned. Trial was pruned at iteration 10.\n"]},{"name":"stdout","output_type":"stream","text":["Number of finished trials: 300\n","Best trial:\n","  Value: 0.1667569163206571\n","  Params: \n","    lambda_l1: 2.315160150066382e-06\n","    lambda_l2: 5.795473037427011e-07\n","    num_leaves: 129\n","    feature_fraction: 0.5381606680136374\n","    bagging_fraction: 0.7706871849373977\n","    bagging_freq: 2\n","    pos_bagging_fraction: 0.5569219616410732\n","    neg_bagging_fraction: 0.5874589935019283\n","    min_child_samples: 32\n","    learning_rate: 0.099787461889484\n"]}],"source":["from sklearn.metrics import log_loss\n","from sklearn.utils.class_weight import compute_sample_weight\n","\n","def objective(trial):\n","    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n","    scores = []\n","\n","    # https://lightgbm.readthedocs.io/en/latest/Parameters.html#objective-parameters\n","    param = {\"objective\": \"binary\",\n","             \"metric\": \"binary_logloss\",\n","             \"verbosity\": -1,\n","             \"boosting_type\": \"gbdt\",\n","             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n","             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n","             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n","             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n","             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n","             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n","             \"pos_bagging_fraction\": trial.suggest_float(\"pos_bagging_fraction\", 0.4, 1.0),\n","             \"neg_bagging_fraction\": trial.suggest_float(\"neg_bagging_fraction\", 0.4, 1.0),\n","             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n","             \"seed\": 42,\n","             \"learning_rate\":trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n","             \"is_unbalance\":True,\n","            }\n","\n","    for train_index, valid_index in skf.split(X, y):\n","        train_x, valid_x = X[train_index], X[valid_index]\n","        train_y, valid_y = y[train_index], y[valid_index]\n","        \n","        # Fit the preprocessor on the training data\n","        preprocessor.fit(train_x)\n","        \n","        # Transform the training and validation data\n","        train_x = preprocessor.transform(train_x)\n","        valid_x = preprocessor.transform(valid_x)\n","    \n","        dtrain = lgb.Dataset(train_x,label=train_y)\n","        dvalid = lgb.Dataset(valid_x,label=valid_y)\n","\n","        # Add a callback for pruning.\n","        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"binary_logloss\") \n","\n","        gbm = lgb.train(param, \n","                        dtrain, valid_sets=[dvalid],\n","                        callbacks=[pruning_callback])\n","\n","        preds = gbm.predict(valid_x)\n","        \n","        # https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_sample_weight.html#sklearn.utils.class_weight.compute_sample_weight\n","        # Calculate sample weights for an imbalanced dataset\n","        sample_weight = compute_sample_weight('balanced', valid_y)\n","\n","        # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html#sklearn.metrics.log_loss\n","        # Calculate log loss with sample weights\n","        log_loss_weighted = log_loss(valid_y, preds,  \n","                                     eps=1e-15,\n","                                     sample_weight=sample_weight)\n","        \n","        return log_loss_weighted\n","\n","if __name__ == \"__main__\":\n","    # https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\n","    # Make the sampler behave in a deterministic way\n","    sampler = TPESampler(seed=42)  \n","    study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\",sampler=sampler)\n","    study.optimize(objective, n_trials=300)\n","\n","    print(\"Number of finished trials: {}\".format(len(study.trials)))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: {}\".format(trial.value))\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))"]},{"cell_type":"markdown","id":"f082aed9","metadata":{"papermill":{"duration":0.071108,"end_time":"2023-07-30T19:56:57.041056","exception":false,"start_time":"2023-07-30T19:56:56.969948","status":"completed"},"tags":[]},"source":["### Submission"]},{"cell_type":"code","execution_count":43,"id":"e6f85b7f","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:56:57.184979Z","iopub.status.busy":"2023-07-30T19:56:57.184223Z","iopub.status.idle":"2023-07-30T19:56:57.192608Z","shell.execute_reply":"2023-07-30T19:56:57.191646Z"},"papermill":{"duration":0.08343,"end_time":"2023-07-30T19:56:57.195011","exception":false,"start_time":"2023-07-30T19:56:57.111581","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nNumber of finished trials: 200\\nBest trial:\\n  Value: 0.19853937238340558\\n  Params: \\n    lambda_l1: 0.0006615357839140508\\n    lambda_l2: 5.444760538433432e-05\\n    num_leaves: 164\\n    feature_fraction: 0.6734791494978176\\n    bagging_fraction: 0.6488310314537731\\n    bagging_freq: 1\\n    pos_bagging_fraction: 0.653881084845293\\n    neg_bagging_fraction: 0.453129351074091\\n    min_child_samples: 31\\n    learning_rate: 0.09670147199850047\\n\\nNumber of finished trials: 300\\nBest trial:\\n  Value: 0.1667569163206571\\n  Params: \\n    lambda_l1: 2.315160150066382e-06\\n    lambda_l2: 5.795473037427011e-07\\n    num_leaves: 129\\n    feature_fraction: 0.5381606680136374\\n    bagging_fraction: 0.7706871849373977\\n    bagging_freq: 2\\n    pos_bagging_fraction: 0.5569219616410732\\n    neg_bagging_fraction: 0.5874589935019283\\n    min_child_samples: 32\\n    learning_rate: 0.099787461889484\\n    \\nNumber of finished trials: 400\\nBest trial:\\n  Value: 0.1667569163206571\\n  Params: \\n    lambda_l1: 2.315160150066382e-06\\n    lambda_l2: 5.795473037427011e-07\\n    num_leaves: 129\\n    feature_fraction: 0.5381606680136374\\n    bagging_fraction: 0.7706871849373977\\n    bagging_freq: 2\\n    pos_bagging_fraction: 0.5569219616410732\\n    neg_bagging_fraction: 0.5874589935019283\\n    min_child_samples: 32\\n    learning_rate: 0.099787461889484\\n'"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Number of finished trials: 200\n","Best trial:\n","  Value: 0.19853937238340558\n","  Params: \n","    lambda_l1: 0.0006615357839140508\n","    lambda_l2: 5.444760538433432e-05\n","    num_leaves: 164\n","    feature_fraction: 0.6734791494978176\n","    bagging_fraction: 0.6488310314537731\n","    bagging_freq: 1\n","    pos_bagging_fraction: 0.653881084845293\n","    neg_bagging_fraction: 0.453129351074091\n","    min_child_samples: 31\n","    learning_rate: 0.09670147199850047\n","\n","Number of finished trials: 300\n","Best trial:\n","  Value: 0.1667569163206571\n","  Params: \n","    lambda_l1: 2.315160150066382e-06\n","    lambda_l2: 5.795473037427011e-07\n","    num_leaves: 129\n","    feature_fraction: 0.5381606680136374\n","    bagging_fraction: 0.7706871849373977\n","    bagging_freq: 2\n","    pos_bagging_fraction: 0.5569219616410732\n","    neg_bagging_fraction: 0.5874589935019283\n","    min_child_samples: 32\n","    learning_rate: 0.099787461889484\n","    \n","Number of finished trials: 400\n","Best trial:\n","  Value: 0.1667569163206571\n","  Params: \n","    lambda_l1: 2.315160150066382e-06\n","    lambda_l2: 5.795473037427011e-07\n","    num_leaves: 129\n","    feature_fraction: 0.5381606680136374\n","    bagging_fraction: 0.7706871849373977\n","    bagging_freq: 2\n","    pos_bagging_fraction: 0.5569219616410732\n","    neg_bagging_fraction: 0.5874589935019283\n","    min_child_samples: 32\n","    learning_rate: 0.099787461889484\n","'''"]},{"cell_type":"code","execution_count":44,"id":"0edd7b51","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-07-30T19:56:57.340632Z","iopub.status.busy":"2023-07-30T19:56:57.339805Z","iopub.status.idle":"2023-07-30T19:56:57.830611Z","shell.execute_reply":"2023-07-30T19:56:57.829126Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":0.568391,"end_time":"2023-07-30T19:56:57.83373","exception":false,"start_time":"2023-07-30T19:56:57.265339","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n","                  transformers=[(&#x27;cat&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                 (&#x27;encoder&#x27;,\n","                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n","                                                                sparse_output=False))]),\n","                                 [39]),\n","                                (&#x27;num&#x27;, SimpleImputer(strategy=&#x27;median&#x27;),\n","                                 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n","                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n","                                  25, 26, 27, 28, 29, ...])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;, sparse_threshold=0,\n","                  transformers=[(&#x27;cat&#x27;,\n","                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n","                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n","                                                 (&#x27;encoder&#x27;,\n","                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n","                                                                sparse_output=False))]),\n","                                 [39]),\n","                                (&#x27;num&#x27;, SimpleImputer(strategy=&#x27;median&#x27;),\n","                                 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n","                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n","                                  25, 26, 27, 28, 29, ...])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[39]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["ColumnTransformer(remainder='passthrough', sparse_threshold=0,\n","                  transformers=[('cat',\n","                                 Pipeline(steps=[('imputer',\n","                                                  SimpleImputer(strategy='most_frequent')),\n","                                                 ('encoder',\n","                                                  OneHotEncoder(handle_unknown='ignore',\n","                                                                sparse_output=False))]),\n","                                 [39]),\n","                                ('num', SimpleImputer(strategy='median'),\n","                                 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n","                                  14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n","                                  25, 26, 27, 28, 29, ...])])"]},"execution_count":44,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Total Bins 9469\n","[LightGBM] [Info] Number of data points in the train set: 617, number of used features: 57\n","[LightGBM] [Info] Start training from score 0.175041\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>class_0</th>\n","      <th>class_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00eed32682bb</td>\n","      <td>0.525404</td>\n","      <td>0.474596</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>010ebe33f668</td>\n","      <td>0.525404</td>\n","      <td>0.474596</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>02fa521e1838</td>\n","      <td>0.525404</td>\n","      <td>0.474596</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>040e15f562a2</td>\n","      <td>0.525404</td>\n","      <td>0.474596</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>046e85c7cc7f</td>\n","      <td>0.525404</td>\n","      <td>0.474596</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Id   class_0   class_1\n","0  00eed32682bb  0.525404  0.474596\n","1  010ebe33f668  0.525404  0.474596\n","2  02fa521e1838  0.525404  0.474596\n","3  040e15f562a2  0.525404  0.474596\n","4  046e85c7cc7f  0.525404  0.474596"]},"metadata":{},"output_type":"display_data"}],"source":["# Get the best hyperparameters from the optimization process\n","best_params = study.best_params\n","\n","# Fit the preprocessor on the entire training data\n","preprocessor.fit(X_df)\n","\n","# Transform the training data\n","X_transformed = preprocessor.transform(X_df)\n","\n","# Create a LightGBM dataset from the transformed training data\n","dtrain = lgb.Dataset(X_transformed, label=y_df)\n","\n","# Merge the best_params dictionary with the force_col_wise parameter\n","params = {**best_params, **{'force_col_wise': True}}\n","\n","# Train a LightGBM model using the best hyperparameters\n","gbm = lgb.train(params, dtrain)\n","\n","#submission_df=test_df.drop([\"Id\"], axis=1)\n","\n","# Preprocess the test data using the preprocessor fit on the training data\n","test_df_transformed = preprocessor.transform(test_df)\n","\n","# Make predictions on the unseen data using the trained LightGBM model\n","preds = gbm.predict(test_df_transformed)\n","\n","# The predictions are probabilities for class 1\n","prob_class_1 = preds\n","\n","# To get probabilities for class 0, subtract from 1\n","prob_class_0 = 1 - prob_class_1\n","\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\n","submission = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n","submission['class_1'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\n","submission['class_0'] = prob_class_0\n","submission.to_csv('submission.csv', index = False)\n","\n","# Display the contents of the submission.csv\n","display(pd.read_csv('submission.csv'))"]},{"cell_type":"code","execution_count":45,"id":"8506497e","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:56:57.983301Z","iopub.status.busy":"2023-07-30T19:56:57.982798Z","iopub.status.idle":"2023-07-30T19:56:57.994042Z","shell.execute_reply":"2023-07-30T19:56:57.992868Z"},"papermill":{"duration":0.090093,"end_time":"2023-07-30T19:56:57.996833","exception":false,"start_time":"2023-07-30T19:56:57.90674","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\nId\\tclass_0\\tclass_1\\n0\\t00eed32682bb\\t0.525404\\t0.474596\\n1\\t010ebe33f668\\t0.525404\\t0.474596\\n2\\t02fa521e1838\\t0.525404\\t0.474596\\n3\\t040e15f562a2\\t0.525404\\t0.474596\\n4\\t046e85c7cc7f\\t0.525404\\t0.474596\\n'"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Id\tclass_0\tclass_1\n","0\t00eed32682bb\t0.525404\t0.474596\n","1\t010ebe33f668\t0.525404\t0.474596\n","2\t02fa521e1838\t0.525404\t0.474596\n","3\t040e15f562a2\t0.525404\t0.474596\n","4\t046e85c7cc7f\t0.525404\t0.474596\n","'''"]},{"cell_type":"code","execution_count":46,"id":"5b5ffaee","metadata":{"execution":{"iopub.execute_input":"2023-07-30T19:56:58.153524Z","iopub.status.busy":"2023-07-30T19:56:58.153147Z","iopub.status.idle":"2023-07-30T19:56:58.163359Z","shell.execute_reply":"2023-07-30T19:56:58.161775Z"},"jupyter":{"source_hidden":true},"papermill":{"duration":0.089934,"end_time":"2023-07-30T19:56:58.166255","exception":false,"start_time":"2023-07-30T19:56:58.076321","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'\\n# Get the best hyperparameters from the Optuna study\\nbest_params = study.best_params\\n\\n# Create an instance of the label encoder\\nle = LabelEncoder()\\n\\n# Fit the label encoder on the training data\\nle.fit(X_df[\\'EJ\\'])\\n\\n# Transform the categorical feature in both the training and validation data\\nX_df[\\'EJ\\'] = le.transform(X_df[\\'EJ\\'])\\n\\n# Create a LightGBM dataset from the entire training data\\ndtrain = lgb.Dataset(X_df, label=y_df,params={\\'force_col_wise\\': True})\\n\\n# Merge the best_params dictionary with the force_col_wise parameter\\nparams = {**best_params, **{\\'force_col_wise\\': True}}\\n\\n# Train a LightGBM model using the merged parameters\\ngbm = lgb.train(params, dtrain)\\n\\nsubmission_df=test_df.drop([\"Id\"], axis=1)\\nsubmission_df[\\'EJ\\'] = le.transform(submission_df[\\'EJ\\']) # Replaces the original categorical values with their corresponding integer encodings.\\n\\n# Make predictions on unseen data\\npreds = gbm.predict(submission_df)\\n\\n# The predictions are probabilities for class 1\\nprob_class_1 = preds\\n\\n# To get probabilities for class 0, subtract from 1\\nprob_class_0 = 1 - prob_class_1\\n\\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\\nsample = pd.read_csv(\\'/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\\')\\nsample[\\'class_1\\'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\\nsample[\\'class_0\\'] = prob_class_0\\nsample.to_csv(\\'submission.csv\\', index = False)\\n\\n# Display the contents of the submission.csv\\ndisplay(pd.read_csv(\\'submission.csv\\'))\\n'"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","# Get the best hyperparameters from the Optuna study\n","best_params = study.best_params\n","\n","# Create an instance of the label encoder\n","le = LabelEncoder()\n","\n","# Fit the label encoder on the training data\n","le.fit(X_df['EJ'])\n","\n","# Transform the categorical feature in both the training and validation data\n","X_df['EJ'] = le.transform(X_df['EJ'])\n","\n","# Create a LightGBM dataset from the entire training data\n","dtrain = lgb.Dataset(X_df, label=y_df,params={'force_col_wise': True})\n","\n","# Merge the best_params dictionary with the force_col_wise parameter\n","params = {**best_params, **{'force_col_wise': True}}\n","\n","# Train a LightGBM model using the merged parameters\n","gbm = lgb.train(params, dtrain)\n","\n","submission_df=test_df.drop([\"Id\"], axis=1)\n","submission_df['EJ'] = le.transform(submission_df['EJ']) # Replaces the original categorical values with their corresponding integer encodings.\n","\n","# Make predictions on unseen data\n","preds = gbm.predict(submission_df)\n","\n","# The predictions are probabilities for class 1\n","prob_class_1 = preds\n","\n","# To get probabilities for class 0, subtract from 1\n","prob_class_0 = 1 - prob_class_1\n","\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n","# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\n","sample = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\n","sample['class_1'] = np.clip(prob_class_1,1e-15,1 - 1e-15)\n","sample['class_0'] = prob_class_0\n","sample.to_csv('submission.csv', index = False)\n","\n","# Display the contents of the submission.csv\n","display(pd.read_csv('submission.csv'))\n","'''"]},{"cell_type":"markdown","id":"41b6abb5","metadata":{"papermill":{"duration":0.079565,"end_time":"2023-07-30T19:56:58.321784","exception":false,"start_time":"2023-07-30T19:56:58.242219","status":"completed"},"tags":[]},"source":["# References/Resources\n","- https://www.kaggle.com/competitions/icr-identify-age-related-conditions/overview\n","- https://optuna.readthedocs.io/en/stable/index.html\n","- https://lightgbm.readthedocs.io/en/latest/index.html\n","- https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n","- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_simple.py\n","- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_tuner_simple.py\n","- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_tuner_cv.py\n","- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_integration.py\n","- https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/422442\n","- https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/422194\n","- https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n","- https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\n","- https://chat.openai.com/\n","- https://bard.google.com/\n","- https://www.bing.com/search?q=Bing+AI&showconv=1&FORM=hpcodx&sydconv=1"]},{"cell_type":"code","execution_count":null,"id":"f0110a9a","metadata":{"papermill":{"duration":0.073426,"end_time":"2023-07-30T19:56:58.469099","exception":false,"start_time":"2023-07-30T19:56:58.395673","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":143.124542,"end_time":"2023-07-30T19:57:01.092934","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-30T19:54:37.968392","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}