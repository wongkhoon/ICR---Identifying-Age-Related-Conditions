{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"#!pip install lightgbm --upgrade ","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:08.492745Z","iopub.execute_input":"2023-08-06T12:56:08.493154Z","iopub.status.idle":"2023-08-06T12:56:08.497665Z","shell.execute_reply.started":"2023-08-06T12:56:08.493124Z","shell.execute_reply":"2023-08-06T12:56:08.496667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\n\nimport time\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom matplotlib.ticker import MaxNLocator\nimport plotly.express as px\nimport seaborn as sns\nimport plotly.graph_objects as go\n\nimport optuna\nfrom optuna.samplers import TPESampler\nimport lightgbm as lgb\nimport optuna.integration.lightgbm as lgb\nfrom lightgbm import early_stopping\nfrom lightgbm import log_evaluation\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport sklearn.datasets\nimport sklearn.metrics\n\nfrom sklearn.metrics import log_loss\nfrom sklearn.utils.class_weight import compute_sample_weight","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:08.51076Z","iopub.execute_input":"2023-08-06T12:56:08.511036Z","iopub.status.idle":"2023-08-06T12:56:08.520062Z","shell.execute_reply.started":"2023-08-06T12:56:08.511004Z","shell.execute_reply":"2023-08-06T12:56:08.519215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set notebook environment","metadata":{}},{"cell_type":"code","source":"# Change notebook environment\n\n# https://ipython.readthedocs.io/en/stable/api/generated/IPython.core.interactiveshell.html\n# https://stackoverflow.com/questions/36786722/how-to-display-full-output-in-jupyter-not-only-last-result\n# Display full output in output cell, not only last result\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n# https://www.kaggle.com/questions-and-answers/118932\n# Max rows and columns of pandas dataframe \npd.options.display.max_rows,pd.options.display.max_columns\n\n# https://thispointer.com/python-pandas-how-to-display-full-dataframe-i-e-print-all-rows-columns-without-truncation/\n# Print all the contents of a pandas dataframe\npd.set_option('display.max_rows', None) # Print unlimited number of rows by setting to None, default is 10\npd.set_option('display.max_columns', None) # Do not truncate columns to display all of them by setting to None\npd.set_option('display.width', None) # Auto-detect the width of dataframe to display all columns in single line by setting to None\npd.set_option('display.max_colwidth', None) # Auto detect the max size of column and print contents of that column without truncation\n\n# https://stackoverflow.com/questions/8924173/how-to-print-bold-text-in-python\nstart = \"\\033[1m\" # Bold text\nend = \"\\033[0;0m\" # Reset \n\nimport gc","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:08.534658Z","iopub.execute_input":"2023-08-06T12:56:08.535569Z","iopub.status.idle":"2023-08-06T12:56:08.545207Z","shell.execute_reply.started":"2023-08-06T12:56:08.535501Z","shell.execute_reply":"2023-08-06T12:56:08.544242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Free up memory that is no longer being used\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:08.579611Z","iopub.execute_input":"2023-08-06T12:56:08.579888Z","iopub.status.idle":"2023-08-06T12:56:08.938599Z","shell.execute_reply.started":"2023-08-06T12:56:08.579864Z","shell.execute_reply":"2023-08-06T12:56:08.937602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load datasets","metadata":{}},{"cell_type":"code","source":"train_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/train.csv\")\ngreeks_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/greeks.csv\")\ntest_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/test.csv\")\nsample_submission_df=pd.read_csv(\"/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:08.940241Z","iopub.execute_input":"2023-08-06T12:56:08.940601Z","iopub.status.idle":"2023-08-06T12:56:08.967462Z","shell.execute_reply.started":"2023-08-06T12:56:08.940577Z","shell.execute_reply":"2023-08-06T12:56:08.966723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data glance","metadata":{}},{"cell_type":"code","source":"print(start+\"train.csv:\"+end)\ntrain_df.head()\nprint(start+\"\\ngreeks.csv:\"+end)\ngreeks_df.head()\nprint(start+\"\\ntest.csv:\"+end)\ntest_df.head()\nprint(start+\"\\nsample_submission_df.csv:\"+end)\nsample_submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:08.968382Z","iopub.execute_input":"2023-08-06T12:56:08.968633Z","iopub.status.idle":"2023-08-06T12:56:09.106431Z","shell.execute_reply.started":"2023-08-06T12:56:08.968611Z","shell.execute_reply":"2023-08-06T12:56:09.105406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check column names","metadata":{}},{"cell_type":"code","source":"print(start+\"train.csv:\"+end)\ntrain_df.columns\nprint(start+\"\\ngreeks.csv:\"+end)\ngreeks_df.columns\nprint(start+\"\\ntest.csv:\"+end)\ntest_df.columns\nprint(start+\"\\nsample_submission_df.csv:\"+end)\nsample_submission_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.108428Z","iopub.execute_input":"2023-08-06T12:56:09.108742Z","iopub.status.idle":"2023-08-06T12:56:09.126232Z","shell.execute_reply.started":"2023-08-06T12:56:09.108716Z","shell.execute_reply":"2023-08-06T12:56:09.125166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Assess data\n- Attribute\n- Summary statistics","metadata":{}},{"cell_type":"code","source":"print(start+\"train:\", train_df.shape,end)\nprint(start+\"greeks:\", greeks_df.shape,end)\nprint(start+\"test:\", test_df.shape,end)\nprint(start+\"sample submission:\", sample_submission_df.shape,end)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.127443Z","iopub.execute_input":"2023-08-06T12:56:09.127681Z","iopub.status.idle":"2023-08-06T12:56:09.133434Z","shell.execute_reply.started":"2023-08-06T12:56:09.127659Z","shell.execute_reply":"2023-08-06T12:56:09.132426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(start+\"train.csv:\"+end)\ntrain_df.info()\nprint(start+\"\\ngreeks_df:\"+end)\ngreeks_df.info()\nprint(start+\"\\ntest_df:\"+end)\ntest_df.info()\nprint(start+\"\\nsample_submission_df:\"+end)\nsample_submission_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.134691Z","iopub.execute_input":"2023-08-06T12:56:09.13499Z","iopub.status.idle":"2023-08-06T12:56:09.173463Z","shell.execute_reply.started":"2023-08-06T12:56:09.134953Z","shell.execute_reply":"2023-08-06T12:56:09.172495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(start+\"train_df:\"+end)\ntrain_df.describe()\nprint(start+\"\\ngreeks_df:\"+end)\ngreeks_df.describe()\nprint(start+\"\\ntest_df:\"+end)\ntest_df.describe()\nprint(start+\"\\nsample_submission_df:\"+end)\nsample_submission_df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.174503Z","iopub.execute_input":"2023-08-06T12:56:09.174829Z","iopub.status.idle":"2023-08-06T12:56:09.605539Z","shell.execute_reply.started":"2023-08-06T12:56:09.174804Z","shell.execute_reply":"2023-08-06T12:56:09.604477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check missing data","metadata":{}},{"cell_type":"code","source":"# Check for missing values\n\nprint(start+'Check missing values:'+end)\n\nprint(start+\"\\ngreeks_df:\"+end)\nprint(greeks_df.isnull().sum())\nprint(start+\"\\ntrain_df:\"+end)\nprint(train_df.isnull().sum())\nprint(start+\"\\ntest_df:\"+end)\nprint(test_df.isnull().sum())\nprint(start+\"\\nsample_submission_df:\"+end)\nprint(sample_submission_df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.606922Z","iopub.execute_input":"2023-08-06T12:56:09.60759Z","iopub.status.idle":"2023-08-06T12:56:09.622357Z","shell.execute_reply.started":"2023-08-06T12:56:09.607556Z","shell.execute_reply":"2023-08-06T12:56:09.621303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keep all rows with at least one missing data\ntrain_df[train_df.isna().any(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.623946Z","iopub.execute_input":"2023-08-06T12:56:09.624343Z","iopub.status.idle":"2023-08-06T12:56:09.822584Z","shell.execute_reply.started":"2023-08-06T12:56:09.624308Z","shell.execute_reply":"2023-08-06T12:56:09.821886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check duplication","metadata":{}},{"cell_type":"code","source":"# Check for duplicates\n\nprint(start+'Train set: There are a total of', start+str(train_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)\nprint(start+'Greeks: There are a total of', start+str(greeks_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)\nprint(start+'Test set: There are a total of', start+str(test_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)\nprint(start+'Submission: There are a total of', start+str(sample_submission_df.duplicated().sum())+end, start+'duplicate rows.\\n'+end)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.826317Z","iopub.execute_input":"2023-08-06T12:56:09.826853Z","iopub.status.idle":"2023-08-06T12:56:09.848364Z","shell.execute_reply.started":"2023-08-06T12:56:09.826826Z","shell.execute_reply":"2023-08-06T12:56:09.847508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check duplication by Id\ntrain_df[train_df.Id.duplicated(keep=False)].sort_values(\"Id\")\ngreeks_df[greeks_df.Id.duplicated(keep=False)].sort_values(\"Id\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-08-06T12:56:09.849755Z","iopub.execute_input":"2023-08-06T12:56:09.85005Z","iopub.status.idle":"2023-08-06T12:56:09.877091Z","shell.execute_reply.started":"2023-08-06T12:56:09.850027Z","shell.execute_reply":"2023-08-06T12:56:09.876178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class imbalance","metadata":{}},{"cell_type":"code","source":"piefreq=train_df.Class.value_counts()\n\nprint('Class imbalance (counts): Class 1, Class 0')\nprint(piefreq,'\\n')\n\n# Imbalance class\nprint('Normalized class: Class 1, Class 0')\nprint(train_df.Class.value_counts(normalize=True))\n\n# Pie chart of class imbalance\nfig=go.Figure(data=[go.Pie(labels=['Class 0    (n=' + str(piefreq[0]) +')',\n                                   'Class 1    (n=' + str(piefreq[1]) +')'],\n                           values=train_df.Class.value_counts())])\nfig.update_layout(title=dict(text=\"<b>Pie chart of 'Class'</b>\",\n                             y=0.85,x=0.4,\n                             xanchor='center',\n                             yanchor='top',\n                             font=dict(size=14)\n                            )\n                  ,width=600\n                  ,height=600)\n\n# Delete piefreq dataframe to release memory\ndel piefreq, fig","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.878553Z","iopub.execute_input":"2023-08-06T12:56:09.8789Z","iopub.status.idle":"2023-08-06T12:56:09.904126Z","shell.execute_reply.started":"2023-08-06T12:56:09.878868Z","shell.execute_reply":"2023-08-06T12:56:09.903234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merge datasets by Id\n- Train and Greek ","metadata":{}},{"cell_type":"code","source":"# Merge train and greeks dataframe by Id\nmerged_df = pd.merge(train_df, greeks_df, on=\"Id\")","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.907152Z","iopub.execute_input":"2023-08-06T12:56:09.907392Z","iopub.status.idle":"2023-08-06T12:56:09.917373Z","shell.execute_reply.started":"2023-08-06T12:56:09.90737Z","shell.execute_reply":"2023-08-06T12:56:09.916417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.92005Z","iopub.execute_input":"2023-08-06T12:56:09.920293Z","iopub.status.idle":"2023-08-06T12:56:09.972781Z","shell.execute_reply.started":"2023-08-06T12:56:09.920271Z","shell.execute_reply":"2023-08-06T12:56:09.971862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical feature\nmerged_df.EJ.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.97569Z","iopub.execute_input":"2023-08-06T12:56:09.975986Z","iopub.status.idle":"2023-08-06T12:56:09.985992Z","shell.execute_reply.started":"2023-08-06T12:56:09.975943Z","shell.execute_reply":"2023-08-06T12:56:09.985001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Categorical feature\nprint(start+\"Alpha:\"+end)\ngreeks_df[~greeks_df[\"Alpha\"].str.isnumeric()][\"Alpha\"].value_counts()\nprint(\"\\n\"+start+\"Beta:\"+end)\ngreeks_df[~greeks_df[\"Beta\"].str.isnumeric()][\"Beta\"].value_counts()\nprint(\"\\n\"+start+\"Gamma:\"+end)\ngreeks_df[~greeks_df[\"Gamma\"].str.isnumeric()][\"Gamma\"].value_counts()\nprint(\"\\n\"+start+\"Delta:\"+end)\ngreeks_df[~greeks_df[\"Delta\"].str.isnumeric()][\"Delta\"].value_counts()\nprint(\"\\n\"+start+\"Epsilon:\"+end)\ngreeks_df[~greeks_df[\"Epsilon\"].str.isnumeric()][\"Epsilon\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:09.987231Z","iopub.execute_input":"2023-08-06T12:56:09.987553Z","iopub.status.idle":"2023-08-06T12:56:10.039266Z","shell.execute_reply.started":"2023-08-06T12:56:09.987512Z","shell.execute_reply":"2023-08-06T12:56:10.038304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print counts of 'Unknown' Epsilon\nunknown_df=greeks_df.query(\"Epsilon=='Unknown'\")\nunknown_df.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:10.040983Z","iopub.execute_input":"2023-08-06T12:56:10.041382Z","iopub.status.idle":"2023-08-06T12:56:10.069875Z","shell.execute_reply.started":"2023-08-06T12:56:10.041346Z","shell.execute_reply":"2023-08-06T12:56:10.068715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pearson Correlation  ","metadata":{}},{"cell_type":"code","source":"# Heatmap\n\nplt.figure(figsize=(30, 10))\n\n# Compute correlation matrix\ncorr_matrix = merged_df.select_dtypes(include=np.number).corr()\n\n# Mask off-diagonal values\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\ncorr_matrix = corr_matrix.mask(mask)\n\n# Create heatmap\nax = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', annot_kws={\"size\": 8}, fmt=\".2f\")\n\n# Update axis labels\nlabels = corr_matrix.columns\nax.set_xticklabels(labels, rotation=290, ha='center', fontsize=8)\nax.set_yticks(np.arange(len(labels)))\nax.set_yticklabels(labels, rotation=0, va='center', fontsize=8)\n\nax.xaxis.set_ticks_position('bottom')\nax.yaxis.set_ticks_position('left')\nax.xaxis.set_label_coords(0.5, 1.05)\nax.yaxis.set_label_coords(-0.05, 0.5)\n\nplt.title(\"Pearson Correlation Matrix\", fontsize=12)\nplt.tight_layout()\nplt.show();\n\ndel mask, ax, labels, corr_matrix","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:10.074538Z","iopub.execute_input":"2023-08-06T12:56:10.074947Z","iopub.status.idle":"2023-08-06T12:56:14.371481Z","shell.execute_reply.started":"2023-08-06T12:56:10.074903Z","shell.execute_reply":"2023-08-06T12:56:14.370562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute the correlation matrix\ncorr_matrix = merged_df.select_dtypes(include=np.number).corr()\n\n# Sort the correlation values in descending order\ncorr_sorted = corr_matrix['Class'].sort_values(ascending=False)\n\n# Create the heatmap\nplt.figure(figsize=(5,10))\nsns.heatmap(pd.DataFrame(corr_sorted), annot=True, cmap='coolwarm',annot_kws={\"size\": 10},fmt=\".2f\")\n\nax = plt.gca()\nax.set_xticklabels(['Class 0 / Class 1'], ha='center',fontsize=10)\n#ax.set_yticklabels(rotation=0,fontsize=10)\n\n# Add a title\nplt.title('Pearson Correlation Matrix with \"Class\"',fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show();\n\ndel corr_matrix,ax","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:14.373243Z","iopub.execute_input":"2023-08-06T12:56:14.373685Z","iopub.status.idle":"2023-08-06T12:56:15.107866Z","shell.execute_reply.started":"2023-08-06T12:56:14.373647Z","shell.execute_reply":"2023-08-06T12:56:15.106872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bar Charts \n- Categorical features by Class","metadata":{}},{"cell_type":"code","source":"# Define the list of categorical features\ncategorical_lst = ['EJ','Alpha','Beta', 'Gamma', 'Delta']\n\nfor var in categorical_lst:\n    # Grouping by the variable and 'Class' column\n    var_class = merged_df.groupby([var, 'Class']).size().unstack()\n \n    # Replace any empty cells with 0\n    var_class = var_class.fillna(0)\n\n    # Calculate the proportion of Class 0 and Class 1 for each value of the variable\n    var_class['Class 0'] = var_class[0] / (var_class[0] + var_class[1])\n    var_class['Class 1'] = var_class[1] / (var_class[0] + var_class[1])\n    print(var_class)\n        \n    # Plotting the stacked bar chart\n    ax = var_class[['Class 0', 'Class 1']].plot(kind='bar', stacked=True, figsize=(15, 3))\n\n    # Adding labels and titles\n    ax.set_xlabel(var)\n    ax.set_ylabel('Proportion')\n    ax.set_title('Class 0 / Class 1 by '+var)\n    \n    # Rotating x-axis labels by 45 degrees\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=360, ha='right')\n    \n    # Adding proportion values within each bar\n    for p in ax.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy()\n        if height > 0:\n            ax.annotate(f'{height:.2%}', (x + width / 2, y + height / 2), ha='center', va='center',fontsize=10)\n\n    # Moving the legend outside the plot area to the top right\n    ax.legend(['Class 0', 'Class 1'], loc='best', bbox_to_anchor=(1, 1.02))\n\n    # Adjusting the plot margins\n    plt.subplots_adjust(right=0.8)\n\n    # Displaying the chart\n    plt.show();\n","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:15.109211Z","iopub.execute_input":"2023-08-06T12:56:15.109482Z","iopub.status.idle":"2023-08-06T12:56:16.816904Z","shell.execute_reply.started":"2023-08-06T12:56:15.109451Z","shell.execute_reply":"2023-08-06T12:56:16.81614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Quick check\n# #len(merged_df[(merged_df['Alpha'] == 'A') & (merged_df['Class'] == 1)])","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:16.818062Z","iopub.execute_input":"2023-08-06T12:56:16.81851Z","iopub.status.idle":"2023-08-06T12:56:16.822234Z","shell.execute_reply.started":"2023-08-06T12:56:16.818485Z","shell.execute_reply":"2023-08-06T12:56:16.821322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Box-whisker plot\n- Numerical features by 'Class'","metadata":{}},{"cell_type":"code","source":"# Define the list of numeric features\nnumeric_lst = merged_df.select_dtypes(include=np.number).columns.tolist()\ny_axis = numeric_lst\n\n# Compute the number of rows and columns for subplot\nnrows = len(numeric_lst) // 3 + 1\nncols = 3\n\n# Create the figure and axes for subplot\nfig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 200))\n\nfor idx, feature in enumerate(numeric_lst):\n    lst0 = merged_df[merged_df['Class'] == 0][feature].tolist()\n    #print(f\"Feature: {feature}, Length of lst0: {len(lst0)}\")\n    lst1 = merged_df[merged_df['Class'] == 1][feature].tolist()\n    columns = [lst0, lst1]\n    \n    # Compute the subplot indices\n    row_idx = idx // ncols\n    col_idx = idx % ncols\n    \n    # Create the box plot with mean markers\n    box = ax[row_idx, col_idx].boxplot(columns, notch=True, patch_artist=True, showmeans=True,\n                                       meanprops={\"marker\": \"s\", \"markerfacecolor\": \"white\", \"markeredgecolor\": \"Cyan\"})\n    \n    ax[row_idx, col_idx].yaxis.set_major_locator(MaxNLocator(integer=True))\n    ax[row_idx, col_idx].set_xticklabels([\"Class 0\", \"Class 1\"], size=10)\n    ax[row_idx, col_idx].set_ylabel(y_axis[idx], size=10)\n    \n    colors = ['lightblue', 'lightgreen']\n    for patch, color in zip(box['boxes'], colors):\n        patch.set_facecolor(color)\n    \n    # Add legend for median and mean markers\n    ax[row_idx, col_idx].legend([box[\"medians\"][0], box[\"means\"][0]], ['Median', 'Mean'], loc='upper right')\n\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:16.823349Z","iopub.execute_input":"2023-08-06T12:56:16.823593Z","iopub.status.idle":"2023-08-06T12:56:27.137741Z","shell.execute_reply.started":"2023-08-06T12:56:16.823572Z","shell.execute_reply":"2023-08-06T12:56:27.136774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"X_df = merged_df.drop([\"Id\", \"Alpha\", \"Beta\", \"Gamma\", \"Delta\",\"Epsilon\",\"Class\"], axis=1)\ny_df = merged_df['Class']","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:27.139225Z","iopub.execute_input":"2023-08-06T12:56:27.139511Z","iopub.status.idle":"2023-08-06T12:56:27.145722Z","shell.execute_reply.started":"2023-08-06T12:56:27.139487Z","shell.execute_reply":"2023-08-06T12:56:27.144606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = X_df.to_numpy()\ny = y_df.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:27.147129Z","iopub.execute_input":"2023-08-06T12:56:27.147409Z","iopub.status.idle":"2023-08-06T12:56:27.171549Z","shell.execute_reply.started":"2023-08-06T12:56:27.147385Z","shell.execute_reply":"2023-08-06T12:56:27.17066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the column transformer to perform encoding and imputation\npreprocessor = ColumnTransformer(transformers=[('cat', \n                                                Pipeline(steps=[('imputer', \n                                                                 SimpleImputer(strategy='most_frequent')\n                                                                ),\n                                                                ('encoder', \n                                                                 OneHotEncoder(handle_unknown='ignore',\n                                                                               sparse_output=False)\n                                                                )\n                                                               ]\n                                                        ),\n                                                [39]),  # Use integer column index instead of string column name\n                                               ('num', \n                                                SimpleImputer(strategy='median'), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n                                                                                   11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n                                                                                   21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n                                                                                   31, 32, 33, 34, 35, 36, 37, 38, 40,\n                                                                                   41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n                                                                                   51, 52, 53, 54, 55]\n                                               )  \n                                              ],\n                                 remainder='passthrough', sparse_threshold=0) # https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:27.172937Z","iopub.execute_input":"2023-08-06T12:56:27.173206Z","iopub.status.idle":"2023-08-06T12:56:27.182216Z","shell.execute_reply.started":"2023-08-06T12:56:27.173183Z","shell.execute_reply":"2023-08-06T12:56:27.181328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBMTunerCV","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    param = {\"objective\": \"binary\",\n             \"metric\": \"binary_logloss\",\n             \"verbosity\": -1,\n             'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'rf', 'dart']),\n             \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n             \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n             \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n             \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n             \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n             \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n             \"pos_bagging_fraction\": trial.suggest_float(\"pos_bagging_fraction\", 0.4, 1.0),\n             \"neg_bagging_fraction\": trial.suggest_float(\"neg_bagging_fraction\", 0.4, 1.0),\n             \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n             \"seed\": 42,\n             \"learning_rate\":trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True),\n             \"is_unbalance\":True,\n             \"num_threads\": multiprocessing.cpu_count()\n            }\n    \n    tuner = lgb.LightGBMTunerCV(param,\n                                dtrain,\n                                folds=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n                                nfold=5, stratified=True,\n                                callbacks=[early_stopping(100), log_evaluation(100)],\n                                seed=42,\n                                #return_cvbooster=True,\n                                optuna_seed=42\n                               )\n\n    tuner.run()\n    \n    return tuner.best_score\n\nif __name__ == \"__main__\":\n    start_time = time.time()\n    \n    preprocessor.fit(X)\n\n    # Transform the training and validation data\n    X = preprocessor.transform(X)\n\n    dtrain = lgb.Dataset(X,label=y)    \n\n    # https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-obtain-reproducible-optimization-results\n    # Make the sampler behave in a deterministic way\n    sampler = TPESampler(seed=42)  \n    study = optuna.create_study(direction=\"minimize\",sampler=sampler)\n    \n    # Set the number of threads to the maximum number of available CPU cores\n    #lgb.params[\"num_threads\"] = multiprocessing.cpu_count()\n    \n    study.optimize(objective, \n                   n_trials=25) \n\n    end_time = time.time()\n    total_training_time = end_time - start_time\n    \n    print(\"Total training time: {:.4f} seconds\".format(total_training_time))\n    \n    print(\"Best score:\", study.best_value)\n    best_params = study.best_params\n    print(\"Best params:\", best_params)\n    print(\"Params: \")\n    for key, value in best_params.items():\n        print(\" {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:56:27.187869Z","iopub.execute_input":"2023-08-06T12:56:27.188143Z","iopub.status.idle":"2023-08-06T12:56:50.879018Z","shell.execute_reply.started":"2023-08-06T12:56:27.188119Z","shell.execute_reply":"2023-08-06T12:56:50.878134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"# Retrieve the best hyperparameters\nbest_params = study.best_params\n\n# Fit the preprocessor on the entire training data\npreprocessor.fit(X_df)\n\n# Transform the training data\nX_transformed = preprocessor.transform(X_df)\n\n# Create a LightGBM dataset from the transformed training data\n#dtrain = lgb.Dataset(X_transformed, label=y_df)\n\n# Preprocess the test data using the preprocessor fit on the training data\ntest_df_transformed = preprocessor.transform(test_df)\n\n# Create a LightGBM dataset for the test data\n#dtest = lgb.Dataset(test_df_transformed,reference=dtrain)\n\n# Merge the best_params dictionary with the force_col_wise parameter\nparams = {**best_params, \n          **{'force_col_wise': True}}\n\ngbm = LGBMClassifier(**params)\ngbm = gbm.fit(X_transformed, y_df)","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:58:39.683544Z","iopub.execute_input":"2023-08-06T12:58:39.684029Z","iopub.status.idle":"2023-08-06T12:58:39.803558Z","shell.execute_reply.started":"2023-08-06T12:58:39.68399Z","shell.execute_reply":"2023-08-06T12:58:39.802762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train a LightGBM model using the best hyperparameters\n#gbm = lgb.train(params, dtrain, valid_sets=[dtrain, dtest])","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:58:40.589917Z","iopub.execute_input":"2023-08-06T12:58:40.590324Z","iopub.status.idle":"2023-08-06T12:58:40.597134Z","shell.execute_reply.started":"2023-08-06T12:58:40.590298Z","shell.execute_reply":"2023-08-06T12:58:40.596219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the unseen data using the trained LightGBM model\npreds = gbm.predict_proba(test_df_transformed)[:,1]\n\n# The predictions are probabilities for class 1\nprob_class_1 = np.clip(preds,1e-15,1 - 1e-15)\n\n# To get probabilities for class 0, subtract from 1\nprob_class_0 = 1 - prob_class_1\n\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\nsubmission = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\nsubmission['class_1'] = prob_class_1\nsubmission['class_0'] = prob_class_0\nsubmission.to_csv('submission.csv', index = False)\n\n# Display the contents of the submission.csv\ndisplay(pd.read_csv('submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-08-06T12:58:41.782451Z","iopub.execute_input":"2023-08-06T12:58:41.782836Z","iopub.status.idle":"2023-08-06T12:58:41.803269Z","shell.execute_reply.started":"2023-08-06T12:58:41.782806Z","shell.execute_reply":"2023-08-06T12:58:41.80214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References/Resources\n- https://www.kaggle.com/competitions/icr-identify-age-related-conditions\n- https://optuna.readthedocs.io/en/stable/index.html\n- https://lightgbm.readthedocs.io/en/latest/index.html\n- https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html\n- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_simple.py\n- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_tuner_simple.py\n- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_tuner_cv.py\n- https://github.com/optuna/optuna-examples/blob/main/lightgbm/lightgbm_integration.py\n- Balanced Log Loss Explained:\n<br>https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/422442\n- Code to validate submission / help solve submission errors:\n<br>https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/422194\n- Keep getting scoring error even though my csv is identical to sample submission:\n<br>https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412946\n- Submission error counts as 1 submission ?:\n<br>https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/409801\n- https://chat.openai.com/\n- https://bard.google.com/\n- https://www.bing.com/search?q=Bing+AI&showconv=1&FORM=hpcodx&sydconv=1","metadata":{}}]}